Ripgrep filtered Lines: [0, 28]
File: criterion.rs/macro/benches/test_macro_bench.rs
Start Line: 0
End Line: 27
Chunks:
#![feature(custom_test_frameworks)]
#![test_runner(criterion::runner)]

use criterion::{Criterion, black_box};
use criterion_macro::criterion;

fn fibonacci(n: u64) -> u64 {
    match n {
        0 | 1 => 1,
        n => fibonacci(n - 1) + fibonacci(n - 2),
    }
}

fn custom_criterion() -> Criterion {
    Criterion::default()
        .sample_size(50)
}

#[criterion]
fn bench_simple(c: &mut Criterion) {
    c.bench_function("Fibonacci-Simple", |b| b.iter(|| fibonacci(black_box(10))));
}

#[criterion(custom_criterion())]
fn bench_custom(c: &mut Criterion) {
    c.bench_function("Fibonacci-Custom", |b| b.iter(|| fibonacci(black_box(20))));
}

Ripgrep filtered Lines: [0, 39, 57]
File: criterion.rs/macro/src/lib.rs
Start Line: 0
End Line: 38
Chunks:
extern crate proc_macro;
use proc_macro::TokenStream;
use proc_macro2::{Ident, TokenTree};
use quote::quote_spanned;

#[proc_macro_attribute]
pub fn criterion(attr: TokenStream, item: TokenStream) -> TokenStream {
    let attr = proc_macro2::TokenStream::from(attr);
    let item = proc_macro2::TokenStream::from(item);

    let span = proc_macro2::Span::call_site();

    let init = if stream_length(attr.clone()) != 0 {
        attr
    }
    else {
        quote_spanned!(span=> criterion::Criterion::default())
    };

    let function_name = find_name(item.clone());
    let wrapped_name = Ident::new(&format!("criterion_wrapped_{}", function_name.to_string()), span);

    let output = quote_spanned!(span=>
        #[test_case]
        pub fn #wrapped_name() {
            #item

            let mut c = #init.configure_from_args();
            #function_name(&mut c);
        }
    );

    output.into()
}

fn stream_length(stream: proc_macro2::TokenStream) -> usize {
    stream.into_iter().count()
}

File: criterion.rs/macro/src/lib.rs
Start Line: 38
End Line: 56
Chunks:

fn find_name(stream: proc_macro2::TokenStream) -> Ident {
    let mut iter = stream.into_iter();
    while let Some(tok) = iter.next() {
        if let TokenTree::Ident(ident) = tok {
            if ident == "fn" {
                break;
            }
        }
    }
    
    if let Some(TokenTree::Ident(name)) = iter.next() {
        name
    }
    else {
        panic!("Unable to find function name")
    }
}

Ripgrep filtered Lines: [0, 47]
File: criterion.rs/benches/benchmarks/async_measurement_overhead.rs
Start Line: 0
End Line: 46
Chunks:
use criterion::{async_executor::FuturesExecutor, criterion_group, BatchSize, Criterion};

fn some_benchmark(c: &mut Criterion) {
    let mut group = c.benchmark_group("async overhead");
    group.bench_function("iter", |b| b.to_async(FuturesExecutor).iter(|| async { 1 }));
    group.bench_function("iter_with_setup", |b| {
        b.to_async(FuturesExecutor)
            .iter_with_setup(|| (), |_| async { 1 })
    });
    group.bench_function("iter_with_large_setup", |b| {
        b.to_async(FuturesExecutor)
            .iter_with_large_setup(|| (), |_| async { 1 })
    });
    group.bench_function("iter_with_large_drop", |b| {
        b.to_async(FuturesExecutor)
            .iter_with_large_drop(|| async { 1 })
    });
    group.bench_function("iter_batched_small_input", |b| {
        b.to_async(FuturesExecutor)
            .iter_batched(|| (), |_| async { 1 }, BatchSize::SmallInput)
    });
    group.bench_function("iter_batched_large_input", |b| {
        b.to_async(FuturesExecutor)
            .iter_batched(|| (), |_| async { 1 }, BatchSize::LargeInput)
    });
    group.bench_function("iter_batched_per_iteration", |b| {
        b.to_async(FuturesExecutor)
            .iter_batched(|| (), |_| async { 1 }, BatchSize::PerIteration)
    });
    group.bench_function("iter_batched_ref_small_input", |b| {
        b.to_async(FuturesExecutor)
            .iter_batched_ref(|| (), |_| async { 1 }, BatchSize::SmallInput)
    });
    group.bench_function("iter_batched_ref_large_input", |b| {
        b.to_async(FuturesExecutor)
            .iter_batched_ref(|| (), |_| async { 1 }, BatchSize::LargeInput)
    });
    group.bench_function("iter_batched_ref_per_iteration", |b| {
        b.to_async(FuturesExecutor).iter_batched_ref(
            || (),
            |_| async { 1 },
            BatchSize::PerIteration,
        )
    });
    group.finish();
}

Ripgrep filtered Lines: [0, 34]
File: criterion.rs/benches/benchmarks/iter_with_large_setup.rs
Start Line: 0
End Line: 33
Chunks:
use criterion::{criterion_group, BatchSize, Criterion, Throughput};
use std::time::Duration;

const SIZE: usize = 1024 * 1024;

fn large_setup(c: &mut Criterion) {
    let mut group = c.benchmark_group("iter_with_large_setup");
    group.throughput(Throughput::Bytes(SIZE as u64));
    group.bench_function("large_setup", |b| {
        b.iter_batched(
            || (0..SIZE).map(|i| i as u8).collect::<Vec<_>>(),
            |v| v,
            BatchSize::NumBatches(1),
        )
    });
}

fn small_setup(c: &mut Criterion) {
    let mut group = c.benchmark_group("iter_with_large_setup");
    group.bench_function("small_setup", |b| {
        b.iter_batched(|| SIZE, |size| size, BatchSize::NumBatches(1))
    });
}

fn short_warmup() -> Criterion {
    Criterion::default().warm_up_time(Duration::new(1, 0))
}

criterion_group! {
    name = benches;
    config = short_warmup();
    targets = large_setup, small_setup
}

Ripgrep filtered Lines: [0, 16, 56]
File: criterion.rs/benches/benchmarks/external_process.rs
Start Line: 0
End Line: 15
Chunks:
use criterion::{criterion_group, Criterion};
use std::{
    io::{BufRead, BufReader, Write},
    process::{Command, Stdio},
    str::FromStr,
    time::Duration,
};

fn create_command() -> Command {
    let mut command = Command::new("python3");
    command
        .arg("benches/benchmarks/external_process.py")
        .arg("10");
    command
}

File: criterion.rs/benches/benchmarks/external_process.rs
Start Line: 15
End Line: 55
Chunks:

fn python_fibonacci(c: &mut Criterion) {
    let has_python3 = Command::new("python3")
        .arg("--version")
        .stdout(Stdio::null())
        .stderr(Stdio::null())
        .output()
        .is_ok();

    if has_python3 {
        let process = create_command()
            .stdin(Stdio::piped())
            .stdout(Stdio::piped())
            .spawn()
            .expect("Unable to start python process");

        let mut stdin = process
            .stdin
            .expect("Unable to get stdin for child process");
        let stdout = process
            .stdout
            .expect("Unable to get stdout for child process");
        let mut stdout = BufReader::new(stdout);
        c.bench_function("fibonacci-python", |b| {
            b.iter_custom(|iters| {
                writeln!(stdin, "{}", iters)
                    .expect("Unable to send iteration count to child process");
                let mut line = String::new();
                stdout
                    .read_line(&mut line)
                    .expect("Unable to read time from child process");
                let nanoseconds: u64 =
                    u64::from_str(line.trim()).expect("Unable to parse time from child process");
                Duration::from_nanos(nanoseconds)
            })
        });

        // Ensure that your child process terminates itself gracefully!
    }
}

Ripgrep filtered Lines: [0, 14, 58, 67, 113, 119]
File: criterion.rs/benches/benchmarks/custom_measurement.rs
Start Line: 0
End Line: 13
Chunks:
use criterion::{
    black_box, criterion_group,
    measurement::{Measurement, ValueFormatter},
    Criterion, Throughput,
};
use std::time::{Duration, Instant};

struct HalfSecFormatter;
impl ValueFormatter for HalfSecFormatter {
    fn format_value(&self, value: f64) -> String {
        // The value will be in nanoseconds so we have to convert to half-seconds.
        format!("{} s/2", value * 2f64 * 10f64.powi(-9))
    }

File: criterion.rs/benches/benchmarks/custom_measurement.rs
Start Line: 13
End Line: 57
Chunks:

    fn format_throughput(&self, throughput: &Throughput, value: f64) -> String {
        match *throughput {
            Throughput::Bytes(bytes) | Throughput::BytesDecimal(bytes) => {
                format!("{} b/s/2", (bytes as f64) / (value * 2f64 * 10f64.powi(-9)))
            }
            Throughput::Elements(elems) => format!(
                "{} elem/s/2",
                (elems as f64) / (value * 2f64 * 10f64.powi(-9))
            ),
        }
    }

    fn scale_values(&self, _typical: f64, values: &mut [f64]) -> &'static str {
        for val in values {
            *val *= 2f64 * 10f64.powi(-9);
        }

        "s/2"
    }

    fn scale_throughputs(
        &self,
        _typical: f64,
        throughput: &Throughput,
        values: &mut [f64],
    ) -> &'static str {
        match *throughput {
            Throughput::Bytes(bytes) | Throughput::BytesDecimal(bytes) => {
                for val in values {
                    *val = (bytes as f64) / (*val * 2f64 * 10f64.powi(-9))
                }

                "b/s/2"
            }
            Throughput::Elements(elems) => {
                for val in values {
                    *val = (elems as f64) / (*val * 2f64 * 10f64.powi(-9))
                }

                "elem/s/2"
            }
        }
    }

File: criterion.rs/benches/benchmarks/custom_measurement.rs
Start Line: 57
End Line: 66
Chunks:

    fn scale_for_machines(&self, values: &mut [f64]) -> &'static str {
        for val in values {
            *val *= 2f64 * 10f64.powi(-9);
        }

        "s/2"
    }
}

File: criterion.rs/benches/benchmarks/custom_measurement.rs
Start Line: 66
End Line: 112
Chunks:

const NANOS_PER_SEC: u64 = 1_000_000_000;

/// Silly "measurement" that is really just wall-clock time reported in half-seconds.
struct HalfSeconds;
impl Measurement for HalfSeconds {
    type Intermediate = Instant;
    type Value = Duration;

    fn start(&self) -> Self::Intermediate {
        Instant::now()
    }
    fn end(&self, i: Self::Intermediate) -> Self::Value {
        i.elapsed()
    }
    fn add(&self, v1: &Self::Value, v2: &Self::Value) -> Self::Value {
        *v1 + *v2
    }
    fn zero(&self) -> Self::Value {
        Duration::from_secs(0)
    }
    fn to_f64(&self, val: &Self::Value) -> f64 {
        let nanos = val.as_secs() * NANOS_PER_SEC + u64::from(val.subsec_nanos());
        nanos as f64
    }
    fn formatter(&self) -> &dyn ValueFormatter {
        &HalfSecFormatter
    }
}

fn fibonacci_slow(n: u64) -> u64 {
    match n {
        0 | 1 => 1,
        n => fibonacci_slow(n - 1) + fibonacci_slow(n - 2),
    }
}

fn fibonacci_cycles(criterion: &mut Criterion<HalfSeconds>) {
    criterion.bench_function("fibonacci_custom_measurement", |bencher| {
        bencher.iter(|| fibonacci_slow(black_box(10)))
    });
}

fn alternate_measurement() -> Criterion<HalfSeconds> {
    Criterion::default().with_measurement(HalfSeconds)
}

File: criterion.rs/benches/benchmarks/custom_measurement.rs
Start Line: 112
End Line: 118
Chunks:

criterion_group! {
    name = benches;
    config = alternate_measurement();
    targets = fibonacci_cycles
}

Ripgrep filtered Lines: [0, 25]
File: criterion.rs/benches/benchmarks/sampling_mode.rs
Start Line: 0
End Line: 24
Chunks:
use criterion::{criterion_group, Criterion, SamplingMode};
use std::thread::sleep;
use std::time::Duration;

fn sampling_mode_tests(c: &mut Criterion) {
    let mut group = c.benchmark_group("sampling_mode");

    group.sampling_mode(SamplingMode::Auto);
    group.bench_function("Auto", |bencher| {
        bencher.iter(|| sleep(Duration::from_millis(0)))
    });

    group.sampling_mode(SamplingMode::Linear);
    group.bench_function("Linear", |bencher| {
        bencher.iter(|| sleep(Duration::from_millis(0)))
    });

    group.sampling_mode(SamplingMode::Flat);
    group.bench_function("Flat", |bencher| {
        bencher.iter(|| sleep(Duration::from_millis(10)))
    });

    group.finish();
}

Ripgrep filtered Lines: [0, 26]
File: criterion.rs/benches/benchmarks/with_inputs.rs
Start Line: 0
End Line: 25
Chunks:
use std::iter;

use criterion::{criterion_group, BenchmarkId, Criterion, Throughput};

fn from_elem(c: &mut Criterion) {
    static KB: usize = 1024;

    let mut group = c.benchmark_group("from_elem");
    for size in [KB, 2 * KB, 4 * KB, 8 * KB, 16 * KB].iter() {
        group.throughput(Throughput::Bytes(*size as u64));
        group.bench_with_input(BenchmarkId::from_parameter(size), size, |b, &size| {
            b.iter(|| iter::repeat(0u8).take(size).collect::<Vec<_>>());
        });
    }
    group.finish();

    let mut group = c.benchmark_group("from_elem_decimal");
    for size in [KB, 2 * KB].iter() {
        group.throughput(Throughput::BytesDecimal(*size as u64));
        group.bench_with_input(BenchmarkId::from_parameter(size), size, |b, &size| {
            b.iter(|| iter::repeat(0u8).take(size).collect::<Vec<_>>());
        });
    }
    group.finish();
}

Ripgrep filtered Lines: [0, 10]
File: criterion.rs/benches/benchmarks/iter_with_setup.rs
Start Line: 0
End Line: 9
Chunks:
use criterion::{criterion_group, Criterion};

const SIZE: usize = 1024 * 1024;

fn setup(c: &mut Criterion) {
    c.bench_function("iter_with_setup", |b| {
        b.iter_with_setup(|| (0..SIZE).map(|i| i as u8).collect::<Vec<_>>(), |v| v)
    });
}

Ripgrep filtered Lines: [0, 31]
File: criterion.rs/benches/benchmarks/iter_with_large_drop.rs
Start Line: 0
End Line: 30
Chunks:
use criterion::{criterion_group, Criterion, Throughput};
use std::time::Duration;

const SIZE: usize = 1024 * 1024;

fn large_drop(c: &mut Criterion) {
    let mut group = c.benchmark_group("iter_with_large_drop");
    group.throughput(Throughput::Bytes(SIZE as u64));
    group.bench_function("large_drop", |b| {
        let v: Vec<_> = (0..SIZE).map(|i| i as u8).collect();
        b.iter_with_large_drop(|| v.clone());
    });
}

fn small_drop(c: &mut Criterion) {
    let mut group = c.benchmark_group("iter_with_large_drop");
    group.bench_function("small_drop", |b| {
        b.iter_with_large_drop(|| SIZE);
    });
}

fn short_warmup() -> Criterion {
    Criterion::default().warm_up_time(Duration::new(1, 0))
}

criterion_group! {
    name = benches;
    config = short_warmup();
    targets = large_drop, small_drop
}

Ripgrep filtered Lines: [0, 45]
File: criterion.rs/benches/benchmarks/compare_functions.rs
Start Line: 0
End Line: 44
Chunks:
use criterion::{criterion_group, BenchmarkId, Criterion};

fn fibonacci_slow(n: u64) -> u64 {
    match n {
        0 | 1 => 1,
        n => fibonacci_slow(n - 1) + fibonacci_slow(n - 2),
    }
}

fn fibonacci_fast(n: u64) -> u64 {
    let mut a = 0;
    let mut b = 1;

    match n {
        0 => b,
        _ => {
            for _ in 0..n {
                let c = a + b;
                a = b;
                b = c;
            }
            b
        }
    }
}

fn compare_fibonaccis(c: &mut Criterion) {
    let mut group = c.benchmark_group("Fibonacci");

    group.bench_with_input("Recursive", &20, |b, i| b.iter(|| fibonacci_slow(*i)));
    group.bench_with_input("Iterative", &20, |b, i| b.iter(|| fibonacci_fast(*i)));
}
fn compare_fibonaccis_group(c: &mut Criterion) {
    let mut group = c.benchmark_group("Fibonacci3");
    for i in 20..=21 {
        group.bench_with_input(BenchmarkId::new("Recursive", i), &i, |b, i| {
            b.iter(|| fibonacci_slow(*i))
        });
        group.bench_with_input(BenchmarkId::new("Iterative", i), &i, |b, i| {
            b.iter(|| fibonacci_fast(*i))
        });
    }
    group.finish()
}

Ripgrep filtered Lines: [0, 31]
File: criterion.rs/benches/benchmarks/measurement_overhead.rs
Start Line: 0
End Line: 30
Chunks:
use criterion::{criterion_group, BatchSize, Criterion};

fn some_benchmark(c: &mut Criterion) {
    let mut group = c.benchmark_group("overhead");
    group.bench_function("iter", |b| b.iter(|| 1));
    group.bench_function("iter_with_setup", |b| b.iter_with_setup(|| (), |_| 1));
    group.bench_function("iter_with_large_setup", |b| {
        b.iter_batched(|| (), |_| 1, BatchSize::NumBatches(1))
    });
    group.bench_function("iter_with_large_drop", |b| b.iter_with_large_drop(|| 1));
    group.bench_function("iter_batched_small_input", |b| {
        b.iter_batched(|| (), |_| 1, BatchSize::SmallInput)
    });
    group.bench_function("iter_batched_large_input", |b| {
        b.iter_batched(|| (), |_| 1, BatchSize::LargeInput)
    });
    group.bench_function("iter_batched_per_iteration", |b| {
        b.iter_batched(|| (), |_| 1, BatchSize::PerIteration)
    });
    group.bench_function("iter_batched_ref_small_input", |b| {
        b.iter_batched_ref(|| (), |_| 1, BatchSize::SmallInput)
    });
    group.bench_function("iter_batched_ref_large_input", |b| {
        b.iter_batched_ref(|| (), |_| 1, BatchSize::LargeInput)
    });
    group.bench_function("iter_batched_ref_per_iteration", |b| {
        b.iter_batched_ref(|| (), |_| 1, BatchSize::PerIteration)
    });
    group.finish();
}

Ripgrep filtered Lines: [0, 22]
File: criterion.rs/benches/benchmarks/mod.rs
Start Line: 0
End Line: 21
Chunks:
pub mod compare_functions;
pub mod custom_measurement;
pub mod external_process;
pub mod iter_with_large_drop;
pub mod iter_with_large_setup;
pub mod iter_with_setup;
pub mod measurement_overhead;
pub mod sampling_mode;
pub mod special_characters;
pub mod with_inputs;

#[cfg(feature = "async_futures")]
pub mod async_measurement_overhead;

#[cfg(not(feature = "async_futures"))]
pub mod async_measurement_overhead {
    use criterion::{criterion_group, Criterion};
    fn some_benchmark(_c: &mut Criterion) {}

    criterion_group!(benches, some_benchmark);
}

Ripgrep filtered Lines: [0, 8]
File: criterion.rs/benches/benchmarks/special_characters.rs
Start Line: 0
End Line: 7
Chunks:
use criterion::{criterion_group, Criterion};

fn some_benchmark(c: &mut Criterion) {
    let mut group = c.benchmark_group("\"*group/\"");
    group.bench_function("\"*benchmark/\" '", |b| b.iter(|| 1 + 1));
    group.finish();
}

Ripgrep filtered Lines: [0, 18]
File: criterion.rs/benches/bench_main.rs
Start Line: 0
End Line: 17
Chunks:
use criterion::criterion_main;

mod benchmarks;

criterion_main! {
    benchmarks::compare_functions::fibonaccis,
    benchmarks::external_process::benches,
    benchmarks::iter_with_large_drop::benches,
    benchmarks::iter_with_large_setup::benches,
    benchmarks::iter_with_setup::benches,
    benchmarks::with_inputs::benches,
    benchmarks::special_characters::benches,
    benchmarks::measurement_overhead::benches,
    benchmarks::custom_measurement::benches,
    benchmarks::sampling_mode::benches,
    benchmarks::async_measurement_overhead::benches,
}

Ripgrep filtered Lines: [0, 20]
File: criterion.rs/bencher_compat/benches/bencher_example.rs
Start Line: 0
End Line: 19
Chunks:
#[macro_use]
extern crate criterion_bencher_compat;

use criterion_bencher_compat::Bencher;

fn a(bench: &mut Bencher) {
    bench.iter(|| {
        (0..1000).fold(0, |x, y| x + y)
    })
}

fn b(bench: &mut Bencher) {
    const N: usize = 1024;
    bench.iter(|| {
        vec![0u8; N]
    });

    bench.bytes = N as u64;
}

Ripgrep filtered Lines: [0, 45, 64]
File: criterion.rs/bencher_compat/src/lib.rs
Start Line: 0
End Line: 44
Chunks:
extern crate criterion;

pub use criterion::Criterion;
pub use criterion::black_box;
use criterion::measurement::WallTime;

/// Stand-in for `bencher::Bencher` which uses Criterion.rs to perform the benchmark instead.
pub struct Bencher<'a, 'b> {
    pub bytes: u64,
    pub bencher: &'a mut ::criterion::Bencher<'b, WallTime>,
}
impl<'a, 'b> Bencher<'a, 'b> {
    /// Callback for benchmark functions to run to perform the benchmark
    pub fn iter<T, F>(&mut self, inner: F)
        where F: FnMut() -> T
    {
        self.bencher.iter(inner);
    }
}

/// Stand-in for `bencher::benchmark_group!` which performs benchmarks using Criterion.rs instead.
#[macro_export]
macro_rules! benchmark_group {
    ($group_name:ident, $($function:path),+) => {
        pub fn $group_name() {
            use $crate::Criterion;
            let mut criterion: Criterion = Criterion::default().configure_from_args();

            $(
                criterion.bench_function(stringify!($function), |b| {
                    let mut wrapped = $crate::Bencher {
                        bytes: 0,
                        bencher: b,
                    };

                    $function(&mut wrapped);
                });
            )+
        }
    };
    ($group_name:ident, $($function:path,)+) => {
        benchmark_group!($group_name, $($function),+);
    };
}

File: criterion.rs/bencher_compat/src/lib.rs
Start Line: 44
End Line: 63
Chunks:

/// Stand-in for `bencher::benchmark_main!` which performs benchmarks using Criterion.rs instead.
#[macro_export]
macro_rules! benchmark_main {
    ($($group_name:path),+) => {
        fn main() {
            $(
                $group_name();
            )+

            $crate::Criterion::default()
                .configure_from_args()
                .final_summary();
        }
    };
    ($($group_name:path,)+) => {
        benchmark_main!($($group_name),+);
    };
}

Ripgrep filtered Lines: [0, 49, 98, 142, 184, 222]
File: criterion.rs/plot/src/key.rs
Start Line: 0
End Line: 48
Chunks:
//! Key (or legend)

use std::borrow::Cow;

use crate::traits::Set;
use crate::{Default, Display, Script, Title};

/// Properties of the key
#[derive(Clone)]
pub struct Properties {
    boxed: bool,
    hidden: bool,
    justification: Option<Justification>,
    order: Option<Order>,
    position: Option<Position>,
    stacked: Option<Stacked>,
    title: Option<Cow<'static, str>>,
}

impl Default for Properties {
    fn default() -> Properties {
        Properties {
            boxed: false,
            hidden: false,
            justification: None,
            order: None,
            position: None,
            stacked: None,
            title: None,
        }
    }
}

impl Properties {
    /// Hides the key
    pub fn hide(&mut self) -> &mut Properties {
        self.hidden = true;
        self
    }

    /// Shows the key
    ///
    /// **Note** The key is shown by default
    pub fn show(&mut self) -> &mut Properties {
        self.hidden = false;
        self
    }
}

File: criterion.rs/plot/src/key.rs
Start Line: 48
End Line: 97
Chunks:

impl Script for Properties {
    // Allow clippy::format_push_string even with older versions of rust (<1.62) which
    // don't have it defined.
    #[allow(clippy::all)]
    fn script(&self) -> String {
        let mut script = if self.hidden {
            return String::from("set key off\n");
        } else {
            String::from("set key on ")
        };

        match self.position {
            None => {}
            Some(Position::Inside(v, h)) => {
                script.push_str(&format!("inside {} {} ", v.display(), h.display()))
            }
            Some(Position::Outside(v, h)) => {
                script.push_str(&format!("outside {} {} ", v.display(), h.display()))
            }
        }

        if let Some(stacked) = self.stacked {
            script.push_str(stacked.display());
            script.push(' ');
        }

        if let Some(justification) = self.justification {
            script.push_str(justification.display());
            script.push(' ');
        }

        if let Some(order) = self.order {
            script.push_str(order.display());
            script.push(' ');
        }

        if let Some(ref title) = self.title {
            script.push_str(&format!("title '{}' ", title))
        }

        if self.boxed {
            script.push_str("box ")
        }

        script.push('\n');
        script
    }
}

File: criterion.rs/plot/src/key.rs
Start Line: 97
End Line: 141
Chunks:

impl Set<Boxed> for Properties {
    /// Select if the key will be surrounded with a box or not
    ///
    /// **Note** The key is not boxed by default
    fn set(&mut self, boxed: Boxed) -> &mut Properties {
        match boxed {
            Boxed::No => self.boxed = false,
            Boxed::Yes => self.boxed = true,
        }

        self
    }
}

impl Set<Justification> for Properties {
    /// Changes the justification of the text of each entry
    ///
    /// **Note** The text is `RightJustified` by default
    fn set(&mut self, justification: Justification) -> &mut Properties {
        self.justification = Some(justification);
        self
    }
}

impl Set<Order> for Properties {
    /// How to order each entry
    ///
    /// **Note** The default order is `TextSample`
    fn set(&mut self, order: Order) -> &mut Properties {
        self.order = Some(order);
        self
    }
}

impl Set<Position> for Properties {
    /// Selects where to place the key
    ///
    /// **Note** By default, the key is placed `Inside(Vertical::Top, Horizontal::Right)`
    fn set(&mut self, position: Position) -> &mut Properties {
        self.position = Some(position);
        self
    }
}

File: criterion.rs/plot/src/key.rs
Start Line: 141
End Line: 183
Chunks:

impl Set<Stacked> for Properties {
    /// Changes how the entries of the key are stacked
    fn set(&mut self, stacked: Stacked) -> &mut Properties {
        self.stacked = Some(stacked);
        self
    }
}

impl Set<Title> for Properties {
    fn set(&mut self, title: Title) -> &mut Properties {
        self.title = Some(title.0);
        self
    }
}

/// Whether the key is surrounded by a box or not
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub enum Boxed {
    No,
    Yes,
}

/// Horizontal position of the key
#[derive(Clone, Copy)]
pub enum Horizontal {
    /// Center of the figure
    Center,
    /// Left border of the figure
    Left,
    /// Right border of the figure
    Right,
}

/// Text justification of the key
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub enum Justification {
    Left,
    Right,
}

File: criterion.rs/plot/src/key.rs
Start Line: 183
End Line: 221
Chunks:

/// Order of the elements of the key
#[derive(Clone, Copy)]
pub enum Order {
    /// Sample first, then text
    SampleText,
    /// Text first, then sample
    TextSample,
}

/// Position of the key
// TODO XY position
#[derive(Clone, Copy)]
pub enum Position {
    /// Inside the area surrounded by the four (BottomX, TopX, LeftY and RightY) axes
    Inside(Vertical, Horizontal),
    /// Outside of that area
    Outside(Vertical, Horizontal),
}

/// How the entries of the key are stacked
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub enum Stacked {
    Horizontally,
    Vertically,
}

/// Vertical position of the key
#[derive(Clone, Copy)]
pub enum Vertical {
    /// Bottom border of the figure
    Bottom,
    /// Center of the figure
    Center,
    /// Top border of the figure
    Top,
}

Ripgrep filtered Lines: [0, 28, 75, 115, 144]
File: criterion.rs/plot/src/filledcurve.rs
Start Line: 0
End Line: 27
Chunks:
//! Filled curve plots

use std::borrow::Cow;
use std::iter::IntoIterator;

use crate::data::Matrix;
use crate::traits::{self, Data, Set};
use crate::{Axes, Color, Default, Display, Figure, Label, Opacity, Plot, Script};

/// Properties common to filled curve plots
pub struct Properties {
    axes: Option<Axes>,
    color: Option<Color>,
    label: Option<Cow<'static, str>>,
    opacity: Option<f64>,
}

impl Default for Properties {
    fn default() -> Properties {
        Properties {
            axes: None,
            color: None,
            label: None,
            opacity: None,
        }
    }
}

File: criterion.rs/plot/src/filledcurve.rs
Start Line: 27
End Line: 74
Chunks:

impl Script for Properties {
    // Allow clippy::format_push_string even with older versions of rust (<1.62) which
    // don't have it defined.
    #[allow(clippy::all)]
    fn script(&self) -> String {
        let mut script = if let Some(axes) = self.axes {
            format!("axes {} ", axes.display())
        } else {
            String::new()
        };
        script.push_str("with filledcurves ");

        script.push_str("fillstyle ");

        if let Some(opacity) = self.opacity {
            script.push_str(&format!("solid {} ", opacity))
        }

        // TODO border shoulde be configurable
        script.push_str("noborder ");

        if let Some(color) = self.color {
            script.push_str(&format!("lc rgb '{}' ", color.display()));
        }

        if let Some(ref label) = self.label {
            script.push_str("title '");
            script.push_str(label);
            script.push('\'')
        } else {
            script.push_str("notitle")
        }

        script
    }
}

impl Set<Axes> for Properties {
    /// Select axes to plot against
    ///
    /// **Note** By default, the `BottomXLeftY` axes are used
    fn set(&mut self, axes: Axes) -> &mut Properties {
        self.axes = Some(axes);
        self
    }
}

File: criterion.rs/plot/src/filledcurve.rs
Start Line: 74
End Line: 114
Chunks:

impl Set<Color> for Properties {
    /// Sets the fill color
    fn set(&mut self, color: Color) -> &mut Properties {
        self.color = Some(color);
        self
    }
}

impl Set<Label> for Properties {
    /// Sets the legend label
    fn set(&mut self, label: Label) -> &mut Properties {
        self.label = Some(label.0);
        self
    }
}

impl Set<Opacity> for Properties {
    /// Changes the opacity of the fill color
    ///
    /// **Note** By default, the fill color is totally opaque (`opacity = 1.0`)
    ///
    /// # Panics
    ///
    /// Panics if `opacity` is outside the range `[0, 1]`
    fn set(&mut self, opacity: Opacity) -> &mut Properties {
        self.opacity = Some(opacity.0);
        self
    }
}

/// Fills the area between two curves
pub struct FilledCurve<X, Y1, Y2> {
    /// X coordinate of the data points of both curves
    pub x: X,
    /// Y coordinate of the data points of the first curve
    pub y1: Y1,
    /// Y coordinate of the data points of the second curve
    pub y2: Y2,
}

File: criterion.rs/plot/src/filledcurve.rs
Start Line: 114
End Line: 143
Chunks:

impl<X, Y1, Y2> traits::Plot<FilledCurve<X, Y1, Y2>> for Figure
where
    X: IntoIterator,
    X::Item: Data,
    Y1: IntoIterator,
    Y1::Item: Data,
    Y2: IntoIterator,
    Y2::Item: Data,
{
    type Properties = Properties;

    fn plot<F>(&mut self, fc: FilledCurve<X, Y1, Y2>, configure: F) -> &mut Figure
    where
        F: FnOnce(&mut Properties) -> &mut Properties,
    {
        let FilledCurve { x, y1, y2 } = fc;

        let mut props = Default::default();
        configure(&mut props);

        let (x_factor, y_factor) =
            crate::scale_factor(&self.axes, props.axes.unwrap_or(crate::Axes::BottomXLeftY));

        let data = Matrix::new(izip!(x, y1, y2), (x_factor, y_factor, y_factor));
        self.plots.push(Plot::new(data, &props));
        self
    }
}

Ripgrep filtered Lines: [0, 39, 81, 117, 157, 203, 239, 274]
File: criterion.rs/plot/src/curve.rs
Start Line: 0
End Line: 38
Chunks:
//! Simple "curve" like plots

use std::borrow::Cow;
use std::iter::IntoIterator;

use crate::data::Matrix;
use crate::traits::{self, Data, Set};
use crate::{
    Axes, Color, CurveDefault, Display, Figure, Label, LineType, LineWidth, Plot, PointSize,
    PointType, Script,
};

/// Properties common to simple "curve" like plots
pub struct Properties {
    axes: Option<Axes>,
    color: Option<Color>,
    label: Option<Cow<'static, str>>,
    line_type: LineType,
    linewidth: Option<f64>,
    point_type: Option<PointType>,
    point_size: Option<f64>,
    style: Style,
}

impl CurveDefault<Style> for Properties {
    fn default(style: Style) -> Properties {
        Properties {
            axes: None,
            color: None,
            label: None,
            line_type: LineType::Solid,
            linewidth: None,
            point_size: None,
            point_type: None,
            style,
        }
    }
}

File: criterion.rs/plot/src/curve.rs
Start Line: 38
End Line: 80
Chunks:

impl Script for Properties {
    // Allow clippy::format_push_string even with older versions of rust (<1.62) which
    // don't have it defined.
    #[allow(clippy::all)]
    fn script(&self) -> String {
        let mut script = if let Some(axes) = self.axes {
            format!("axes {} ", axes.display())
        } else {
            String::new()
        };

        script.push_str(&format!("with {} ", self.style.display()));
        script.push_str(&format!("lt {} ", self.line_type.display()));

        if let Some(lw) = self.linewidth {
            script.push_str(&format!("lw {} ", lw))
        }

        if let Some(color) = self.color {
            script.push_str(&format!("lc rgb '{}' ", color.display()))
        }

        if let Some(pt) = self.point_type {
            script.push_str(&format!("pt {} ", pt.display()))
        }

        if let Some(ps) = self.point_size {
            script.push_str(&format!("ps {} ", ps))
        }

        if let Some(ref label) = self.label {
            script.push_str("title '");
            script.push_str(label);
            script.push('\'')
        } else {
            script.push_str("notitle")
        }

        script
    }
}

File: criterion.rs/plot/src/curve.rs
Start Line: 80
End Line: 116
Chunks:

impl Set<Axes> for Properties {
    /// Select the axes to plot against
    ///
    /// **Note** By default, the `BottomXLeftY` axes are used
    fn set(&mut self, axes: Axes) -> &mut Properties {
        self.axes = Some(axes);
        self
    }
}

impl Set<Color> for Properties {
    /// Sets the line color
    fn set(&mut self, color: Color) -> &mut Properties {
        self.color = Some(color);
        self
    }
}

impl Set<Label> for Properties {
    /// Sets the legend label
    fn set(&mut self, label: Label) -> &mut Properties {
        self.label = Some(label.0);
        self
    }
}

impl Set<LineType> for Properties {
    /// Changes the line type
    ///
    /// **Note** By default `Solid` lines are used
    fn set(&mut self, lt: LineType) -> &mut Properties {
        self.line_type = lt;
        self
    }
}

File: criterion.rs/plot/src/curve.rs
Start Line: 116
End Line: 156
Chunks:

impl Set<LineWidth> for Properties {
    /// Changes the width of the line
    ///
    /// # Panics
    ///
    /// Panics if `width` is a non-positive value
    fn set(&mut self, lw: LineWidth) -> &mut Properties {
        let lw = lw.0;

        assert!(lw > 0.);

        self.linewidth = Some(lw);
        self
    }
}

impl Set<PointSize> for Properties {
    /// Changes the size of the points
    ///
    /// # Panics
    ///
    /// Panics if `size` is a non-positive value
    fn set(&mut self, ps: PointSize) -> &mut Properties {
        let ps = ps.0;

        assert!(ps > 0.);

        self.point_size = Some(ps);
        self
    }
}

impl Set<PointType> for Properties {
    /// Changes the point type
    fn set(&mut self, pt: PointType) -> &mut Properties {
        self.point_type = Some(pt);
        self
    }
}

File: criterion.rs/plot/src/curve.rs
Start Line: 156
End Line: 202
Chunks:

/// Types of "curve" plots
pub enum Curve<X, Y> {
    /// A minimally sized dot on each data point
    Dots {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
    },
    /// A vertical "impulse" on each data point
    Impulses {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
    },
    /// Line that joins the data points
    Lines {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
    },
    /// Line with a point on each data point
    LinesPoints {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
    },
    /// A point on each data point
    Points {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
    },
    /// An step `_|` between each data point
    Steps {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
    },
}

File: criterion.rs/plot/src/curve.rs
Start Line: 202
End Line: 238
Chunks:

impl<X, Y> Curve<X, Y> {
    fn style(&self) -> Style {
        match *self {
            Curve::Dots { .. } => Style::Dots,
            Curve::Impulses { .. } => Style::Impulses,
            Curve::Lines { .. } => Style::Lines,
            Curve::LinesPoints { .. } => Style::LinesPoints,
            Curve::Points { .. } => Style::Points,
            Curve::Steps { .. } => Style::Steps,
        }
    }
}

#[derive(Clone, Copy)]
enum Style {
    Dots,
    Impulses,
    Lines,
    LinesPoints,
    Points,
    Steps,
}

impl Display<&'static str> for Style {
    fn display(&self) -> &'static str {
        match *self {
            Style::Dots => "dots",
            Style::Impulses => "impulses",
            Style::Lines => "lines",
            Style::LinesPoints => "linespoints",
            Style::Points => "points",
            Style::Steps => "steps",
        }
    }
}

File: criterion.rs/plot/src/curve.rs
Start Line: 238
End Line: 273
Chunks:

impl<X, Y> traits::Plot<Curve<X, Y>> for Figure
where
    X: IntoIterator,
    X::Item: Data,
    Y: IntoIterator,
    Y::Item: Data,
{
    type Properties = Properties;

    fn plot<F>(&mut self, curve: Curve<X, Y>, configure: F) -> &mut Figure
    where
        F: FnOnce(&mut Properties) -> &mut Properties,
    {
        let style = curve.style();
        let (x, y) = match curve {
            Curve::Dots { x, y }
            | Curve::Impulses { x, y }
            | Curve::Lines { x, y }
            | Curve::LinesPoints { x, y }
            | Curve::Points { x, y }
            | Curve::Steps { x, y } => (x, y),
        };

        let mut props = CurveDefault::default(style);
        configure(&mut props);

        let (x_factor, y_factor) =
            crate::scale_factor(&self.axes, props.axes.unwrap_or(crate::Axes::BottomXLeftY));

        let data = Matrix::new(izip!(x, y), (x_factor, y_factor));
        self.plots.push(Plot::new(data, &props));
        self
    }
}

Ripgrep filtered Lines: [0, 37, 82, 132, 159, 207, 238, 276]
File: criterion.rs/plot/src/errorbar.rs
Start Line: 0
End Line: 36
Chunks:
//! Error bar plots

use std::borrow::Cow;
use std::iter::IntoIterator;

use crate::data::Matrix;
use crate::traits::{self, Data, Set};
use crate::{
    Color, Display, ErrorBarDefault, Figure, Label, LineType, LineWidth, Plot, PointSize,
    PointType, Script,
};

/// Properties common to error bar plots
pub struct Properties {
    color: Option<Color>,
    label: Option<Cow<'static, str>>,
    line_type: LineType,
    linewidth: Option<f64>,
    point_size: Option<f64>,
    point_type: Option<PointType>,
    style: Style,
}

impl ErrorBarDefault<Style> for Properties {
    fn default(style: Style) -> Properties {
        Properties {
            color: None,
            label: None,
            line_type: LineType::Solid,
            linewidth: None,
            point_type: None,
            point_size: None,
            style,
        }
    }
}

File: criterion.rs/plot/src/errorbar.rs
Start Line: 36
End Line: 81
Chunks:

impl Script for Properties {
    // Allow clippy::format_push_string even with older versions of rust (<1.62) which
    // don't have it defined.
    #[allow(clippy::all)]
    fn script(&self) -> String {
        let mut script = format!("with {} ", self.style.display());

        script.push_str(&format!("lt {} ", self.line_type.display()));

        if let Some(lw) = self.linewidth {
            script.push_str(&format!("lw {} ", lw))
        }

        if let Some(color) = self.color {
            script.push_str(&format!("lc rgb '{}' ", color.display()))
        }

        if let Some(pt) = self.point_type {
            script.push_str(&format!("pt {} ", pt.display()))
        }

        if let Some(ps) = self.point_size {
            script.push_str(&format!("ps {} ", ps))
        }

        if let Some(ref label) = self.label {
            script.push_str("title '");
            script.push_str(label);
            script.push('\'')
        } else {
            script.push_str("notitle")
        }

        script
    }
}

impl Set<Color> for Properties {
    /// Changes the color of the error bars
    fn set(&mut self, color: Color) -> &mut Properties {
        self.color = Some(color);
        self
    }
}

File: criterion.rs/plot/src/errorbar.rs
Start Line: 81
End Line: 131
Chunks:

impl Set<Label> for Properties {
    /// Sets the legend label
    fn set(&mut self, label: Label) -> &mut Properties {
        self.label = Some(label.0);
        self
    }
}

impl Set<LineType> for Properties {
    /// Change the line type
    ///
    /// **Note** By default `Solid` lines are used
    fn set(&mut self, lt: LineType) -> &mut Properties {
        self.line_type = lt;
        self
    }
}

impl Set<LineWidth> for Properties {
    /// Changes the linewidth
    ///
    /// # Panics
    ///
    /// Panics if `lw` is a non-positive value
    fn set(&mut self, lw: LineWidth) -> &mut Properties {
        let lw = lw.0;

        assert!(lw > 0.);

        self.linewidth = Some(lw);
        self
    }
}

impl Set<PointSize> for Properties {
    /// Changes the size of the points
    ///
    /// # Panics
    ///
    /// Panics if `size` is a non-positive value
    fn set(&mut self, ps: PointSize) -> &mut Properties {
        let ps = ps.0;

        assert!(ps > 0.);

        self.point_size = Some(ps);
        self
    }
}

File: criterion.rs/plot/src/errorbar.rs
Start Line: 131
End Line: 158
Chunks:

impl Set<PointType> for Properties {
    /// Changes the point type
    fn set(&mut self, pt: PointType) -> &mut Properties {
        self.point_type = Some(pt);
        self
    }
}

#[derive(Clone, Copy)]
enum Style {
    XErrorBars,
    XErrorLines,
    YErrorBars,
    YErrorLines,
}

impl Display<&'static str> for Style {
    fn display(&self) -> &'static str {
        match *self {
            Style::XErrorBars => "xerrorbars",
            Style::XErrorLines => "xerrorlines",
            Style::YErrorBars => "yerrorbars",
            Style::YErrorLines => "yerrorlines",
        }
    }
}

File: criterion.rs/plot/src/errorbar.rs
Start Line: 158
End Line: 206
Chunks:

/// Asymmetric error bar plots
pub enum ErrorBar<X, Y, L, H> {
    /// Horizontal error bars
    XErrorBars {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
        /// X coordinate of the left end of the error bar
        x_low: L,
        /// Y coordinate of the right end of the error bar
        x_high: H,
    },
    /// Horizontal error bars, where each point is joined by a line
    XErrorLines {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
        /// X coordinate of the left end of the error bar
        x_low: L,
        /// Y coordinate of the right end of the error bar
        x_high: H,
    },
    /// Vertical error bars
    YErrorBars {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
        /// Y coordinate of the bottom of the error bar
        y_low: L,
        /// Y coordinate of the top of the error bar
        y_high: H,
    },
    /// Vertical error bars, where each point is joined by a line
    YErrorLines {
        /// X coordinate of the data points
        x: X,
        /// Y coordinate of the data points
        y: Y,
        /// Y coordinate of the bottom of the error bar
        y_low: L,
        /// Y coordinate of the top of the error bar
        y_high: H,
    },
}

File: criterion.rs/plot/src/errorbar.rs
Start Line: 206
End Line: 237
Chunks:

impl<X, Y, L, H> ErrorBar<X, Y, L, H> {
    fn style(&self) -> Style {
        match *self {
            ErrorBar::XErrorBars { .. } => Style::XErrorBars,
            ErrorBar::XErrorLines { .. } => Style::XErrorLines,
            ErrorBar::YErrorBars { .. } => Style::YErrorBars,
            ErrorBar::YErrorLines { .. } => Style::YErrorLines,
        }
    }
}

impl<X, Y, L, H> traits::Plot<ErrorBar<X, Y, L, H>> for Figure
where
    H: IntoIterator,
    H::Item: Data,
    L: IntoIterator,
    L::Item: Data,
    X: IntoIterator,
    X::Item: Data,
    Y: IntoIterator,
    Y::Item: Data,
{
    type Properties = Properties;

    fn plot<F>(&mut self, e: ErrorBar<X, Y, L, H>, configure: F) -> &mut Figure
    where
        F: FnOnce(&mut Properties) -> &mut Properties,
    {
        let (x_factor, y_factor) = crate::scale_factor(&self.axes, crate::Axes::BottomXLeftY);


File: criterion.rs/plot/src/errorbar.rs
Start Line: 237
End Line: 275
Chunks:
        let style = e.style();
        let (x, y, length, height, e_factor) = match e {
            ErrorBar::XErrorBars {
                x,
                y,
                x_low,
                x_high,
            }
            | ErrorBar::XErrorLines {
                x,
                y,
                x_low,
                x_high,
            } => (x, y, x_low, x_high, x_factor),
            ErrorBar::YErrorBars {
                x,
                y,
                y_low,
                y_high,
            }
            | ErrorBar::YErrorLines {
                x,
                y,
                y_low,
                y_high,
            } => (x, y, y_low, y_high, y_factor),
        };
        let data = Matrix::new(
            izip!(x, y, length, height),
            (x_factor, y_factor, e_factor, e_factor),
        );
        self.plots.push(Plot::new(
            data,
            configure(&mut ErrorBarDefault::default(style)),
        ));
        self
    }
}

Ripgrep filtered Lines: [0, 14]
File: criterion.rs/plot/src/prelude.rs
Start Line: 0
End Line: 13
Chunks:
//! A collection of the most used traits, structs and enums

pub use crate::candlestick::Candlesticks;
pub use crate::curve::Curve::{Dots, Impulses, Lines, LinesPoints, Points, Steps};
pub use crate::errorbar::ErrorBar::{XErrorBars, XErrorLines, YErrorBars, YErrorLines};
pub use crate::filledcurve::FilledCurve;
pub use crate::key::{Boxed, Horizontal, Justification, Order, Position, Stacked, Vertical};
pub use crate::proxy::{Font, Label, Output, Title};
pub use crate::traits::{Configure, Plot, Set};
pub use crate::{
    Axes, Axis, BoxWidth, Color, Figure, FontSize, Grid, Key, LineType, LineWidth, Opacity,
    PointSize, PointType, Range, Scale, ScaleFactor, Size, Terminal, TicLabels,
};

Ripgrep filtered Lines: [0, 36]
File: criterion.rs/plot/src/traits.rs
Start Line: 0
End Line: 35
Chunks:
//! Traits

/// Overloaded `configure` method
pub trait Configure<This> {
    /// The properties of what's being configured
    type Properties;

    /// Configure some set of properties
    fn configure<F>(&mut self, this: This, function: F) -> &mut Self
    where
        F: FnOnce(&mut Self::Properties) -> &mut Self::Properties;
}

/// Types that can be plotted
pub trait Data {
    /// Convert the type into a double precision float
    fn f64(self) -> f64;
}

/// Overloaded `plot` method
pub trait Plot<This> {
    /// The properties associated to the plot
    type Properties;

    /// Plots some `data` with some `configuration`
    fn plot<F>(&mut self, this: This, function: F) -> &mut Self
    where
        F: FnOnce(&mut Self::Properties) -> &mut Self::Properties;
}

/// Overloaded `set` method
pub trait Set<T> {
    /// Sets some property
    fn set(&mut self, value: T) -> &mut Self;
}

Ripgrep filtered Lines: [0, 37, 83, 129, 156, 202]
File: criterion.rs/plot/src/axis.rs
Start Line: 0
End Line: 36
Chunks:
//! Coordinate axis

use std::borrow::Cow;
use std::iter::IntoIterator;

use crate::map;
use crate::traits::{Configure, Data, Set};
use crate::{
    grid, Axis, Default, Display, Grid, Label, Range, Scale, ScaleFactor, Script, TicLabels,
};

/// Properties of the coordinate axes
#[derive(Clone)]
pub struct Properties {
    grids: map::grid::Map<grid::Properties>,
    hidden: bool,
    label: Option<Cow<'static, str>>,
    logarithmic: bool,
    range: Option<(f64, f64)>,
    scale_factor: f64,
    tics: Option<String>,
}

impl Default for Properties {
    fn default() -> Properties {
        Properties {
            grids: map::grid::Map::new(),
            hidden: false,
            label: None,
            logarithmic: false,
            range: None,
            scale_factor: 1.,
            tics: None,
        }
    }
}

File: criterion.rs/plot/src/axis.rs
Start Line: 36
End Line: 82
Chunks:

impl Properties {
    /// Hides the axis
    ///
    /// **Note** The `TopX` and `RightY` axes are hidden by default
    pub fn hide(&mut self) -> &mut Properties {
        self.hidden = true;
        self
    }

    /// Makes the axis visible
    ///
    /// **Note** The `BottomX` and `LeftY` axes are visible by default
    pub fn show(&mut self) -> &mut Properties {
        self.hidden = false;
        self
    }
}

impl Configure<Grid> for Properties {
    type Properties = grid::Properties;

    /// Configures the gridlines
    fn configure<F>(&mut self, grid: Grid, configure: F) -> &mut Properties
    where
        F: FnOnce(&mut grid::Properties) -> &mut grid::Properties,
    {
        if self.grids.contains_key(grid) {
            configure(self.grids.get_mut(grid).unwrap());
        } else {
            let mut properties = Default::default();
            configure(&mut properties);
            self.grids.insert(grid, properties);
        }

        self
    }
}

impl Set<Label> for Properties {
    /// Attaches a label to the axis
    fn set(&mut self, label: Label) -> &mut Properties {
        self.label = Some(label.0);
        self
    }
}

File: criterion.rs/plot/src/axis.rs
Start Line: 82
End Line: 128
Chunks:

impl Set<Range> for Properties {
    /// Changes the range of the axis that will be shown
    ///
    /// **Note** All axes are auto-scaled by default
    fn set(&mut self, range: Range) -> &mut Properties {
        self.hidden = false;

        match range {
            Range::Auto => self.range = None,
            Range::Limits(low, high) => self.range = Some((low, high)),
        }

        self
    }
}

impl Set<Scale> for Properties {
    /// Sets the scale of the axis
    ///
    /// **Note** All axes use a linear scale by default
    fn set(&mut self, scale: Scale) -> &mut Properties {
        self.hidden = false;

        match scale {
            Scale::Linear => self.logarithmic = false,
            Scale::Logarithmic => self.logarithmic = true,
        }

        self
    }
}

impl Set<ScaleFactor> for Properties {
    /// Changes the *scale factor* of the axis.
    ///
    /// All the data plotted against this axis will have its corresponding coordinate scaled with
    /// this factor before being plotted.
    ///
    /// **Note** The default scale factor is `1`.
    fn set(&mut self, factor: ScaleFactor) -> &mut Properties {
        self.scale_factor = factor.0;

        self
    }
}

File: criterion.rs/plot/src/axis.rs
Start Line: 128
End Line: 155
Chunks:

impl<P, L> Set<TicLabels<P, L>> for Properties
where
    L: IntoIterator,
    L::Item: AsRef<str>,
    P: IntoIterator,
    P::Item: Data,
{
    /// Attaches labels to the tics of an axis
    fn set(&mut self, tics: TicLabels<P, L>) -> &mut Properties {
        let TicLabels { positions, labels } = tics;

        let pairs = positions
            .into_iter()
            .zip(labels)
            .map(|(pos, label)| format!("'{}' {}", label.as_ref(), pos.f64()))
            .collect::<Vec<_>>();

        if pairs.is_empty() {
            self.tics = None
        } else {
            self.tics = Some(pairs.join(", "));
        }

        self
    }
}

File: criterion.rs/plot/src/axis.rs
Start Line: 155
End Line: 201
Chunks:

impl<'a> Script for (Axis, &'a Properties) {
    // Allow clippy::format_push_string even with older versions of rust (<1.62) which
    // don't have it defined.
    #[allow(clippy::all)]
    fn script(&self) -> String {
        let &(axis, properties) = self;
        let axis_ = axis.display();

        let mut script = if properties.hidden {
            return format!("unset {}tics\n", axis_);
        } else {
            format!("set {}tics nomirror ", axis_)
        };

        if let Some(ref tics) = properties.tics {
            script.push_str(&format!("({})", tics))
        }

        script.push('\n');

        if let Some(ref label) = properties.label {
            script.push_str(&format!("set {}label '{}'\n", axis_, label))
        }

        if let Some((low, high)) = properties.range {
            script.push_str(&format!("set {}range [{}:{}]\n", axis_, low, high))
        }

        if properties.logarithmic {
            script.push_str(&format!("set logscale {}\n", axis_));
        }

        for (grid, properties) in properties.grids.iter() {
            script.push_str(&(axis, grid, properties).script());
        }

        script
    }
}

impl crate::ScaleFactorTrait for Properties {
    fn scale_factor(&self) -> f64 {
        self.scale_factor
    }
}

Ripgrep filtered Lines: [0, 47, 97, 140]
File: criterion.rs/plot/src/display.rs
Start Line: 0
End Line: 46
Chunks:
use std::borrow::Cow;

use crate::key::{Horizontal, Justification, Order, Stacked, Vertical};
use crate::{Axes, Axis, Color, Display, Grid, LineType, PointType, Terminal};

impl Display<&'static str> for Axis {
    fn display(&self) -> &'static str {
        match *self {
            Axis::BottomX => "x",
            Axis::LeftY => "y",
            Axis::RightY => "y2",
            Axis::TopX => "x2",
        }
    }
}

impl Display<&'static str> for Axes {
    fn display(&self) -> &'static str {
        match *self {
            Axes::BottomXLeftY => "x1y1",
            Axes::BottomXRightY => "x1y2",
            Axes::TopXLeftY => "x2y1",
            Axes::TopXRightY => "x2y2",
        }
    }
}

impl Display<Cow<'static, str>> for Color {
    fn display(&self) -> Cow<'static, str> {
        match *self {
            Color::Black => Cow::from("black"),
            Color::Blue => Cow::from("blue"),
            Color::Cyan => Cow::from("cyan"),
            Color::DarkViolet => Cow::from("dark-violet"),
            Color::ForestGreen => Cow::from("forest-green"),
            Color::Gold => Cow::from("gold"),
            Color::Gray => Cow::from("gray"),
            Color::Green => Cow::from("green"),
            Color::Magenta => Cow::from("magenta"),
            Color::Red => Cow::from("red"),
            Color::Rgb(r, g, b) => Cow::from(format!("#{:02x}{:02x}{:02x}", r, g, b)),
            Color::White => Cow::from("white"),
            Color::Yellow => Cow::from("yellow"),
        }
    }
}

File: criterion.rs/plot/src/display.rs
Start Line: 46
End Line: 96
Chunks:

impl Display<&'static str> for Grid {
    fn display(&self) -> &'static str {
        match *self {
            Grid::Major => "",
            Grid::Minor => "m",
        }
    }
}

impl Display<&'static str> for Horizontal {
    fn display(&self) -> &'static str {
        match *self {
            Horizontal::Center => "center",
            Horizontal::Left => "left",
            Horizontal::Right => "right",
        }
    }
}

impl Display<&'static str> for Justification {
    fn display(&self) -> &'static str {
        match *self {
            Justification::Left => "Left",
            Justification::Right => "Right",
        }
    }
}

impl Display<&'static str> for LineType {
    fn display(&self) -> &'static str {
        match *self {
            LineType::Dash => "2",
            LineType::Dot => "3",
            LineType::DotDash => "4",
            LineType::DotDotDash => "5",
            LineType::SmallDot => "0",
            LineType::Solid => "1",
        }
    }
}

impl Display<&'static str> for Order {
    fn display(&self) -> &'static str {
        match *self {
            Order::TextSample => "noreverse",
            Order::SampleText => "reverse",
        }
    }
}

File: criterion.rs/plot/src/display.rs
Start Line: 96
End Line: 139
Chunks:

impl Display<&'static str> for PointType {
    fn display(&self) -> &'static str {
        match *self {
            PointType::Circle => "6",
            PointType::FilledCircle => "7",
            PointType::FilledSquare => "5",
            PointType::FilledTriangle => "9",
            PointType::Plus => "1",
            PointType::Square => "4",
            PointType::Star => "3",
            PointType::Triangle => "8",
            PointType::X => "2",
        }
    }
}

impl Display<&'static str> for Stacked {
    fn display(&self) -> &'static str {
        match *self {
            Stacked::Horizontally => "horizontal",
            Stacked::Vertically => "vertical",
        }
    }
}

impl Display<&'static str> for Terminal {
    fn display(&self) -> &'static str {
        match *self {
            Terminal::Svg => "svg dynamic",
        }
    }
}

impl Display<&'static str> for Vertical {
    fn display(&self) -> &'static str {
        match *self {
            Vertical::Bottom => "bottom",
            Vertical::Center => "center",
            Vertical::Top => "top",
        }
    }
}

Ripgrep filtered Lines: [0, 39, 88, 117, 162, 169]
File: criterion.rs/plot/src/map.rs
Start Line: 0
End Line: 38
Chunks:
//! Enum Maps

pub mod axis {
    use crate::Axis;

    const LENGTH: usize = 4;

    pub struct Items<'a, T>
    where
        T: 'a,
    {
        map: &'a Map<T>,
        state: Option<Axis>,
    }

    impl<'a, T> Iterator for Items<'a, T> {
        type Item = (Axis, &'a T);

        fn next(&mut self) -> Option<(Axis, &'a T)> {
            while let Some(key) = self.state {
                self.state = key.next();

                if let Some(value) = self.map.get(key) {
                    return Some((key, value));
                }
            }

            None
        }
    }

    pub struct Map<T>([Option<T>; LENGTH]);

    impl<T> Default for Map<T> {
        fn default() -> Self {
            Self::new()
        }
    }

File: criterion.rs/plot/src/map.rs
Start Line: 38
End Line: 87
Chunks:

    impl<T> Map<T> {
        pub fn new() -> Map<T> {
            Map([None, None, None, None])
        }

        pub fn contains_key(&self, key: Axis) -> bool {
            self.0[key as usize].is_some()
        }

        pub fn get(&self, key: Axis) -> Option<&T> {
            self.0[key as usize].as_ref()
        }

        pub fn get_mut(&mut self, key: Axis) -> Option<&mut T> {
            self.0[key as usize].as_mut()
        }

        pub fn insert(&mut self, key: Axis, value: T) -> Option<T> {
            let key = key as usize;
            let old = self.0[key].take();

            self.0[key] = Some(value);

            old
        }

        pub fn iter(&self) -> Items<T> {
            Items {
                map: self,
                state: Some(Axis::BottomX),
            }
        }
    }

    impl<T> Clone for Map<T>
    where
        T: Clone,
    {
        fn clone(&self) -> Map<T> {
            Map([
                self.0[0].clone(),
                self.0[1].clone(),
                self.0[2].clone(),
                self.0[3].clone(),
            ])
        }
    }
}

File: criterion.rs/plot/src/map.rs
Start Line: 87
End Line: 116
Chunks:

pub mod grid {
    use crate::Grid;

    const LENGTH: usize = 2;

    pub struct Items<'a, T>
    where
        T: 'a,
    {
        map: &'a Map<T>,
        state: Option<Grid>,
    }

    impl<'a, T> Iterator for Items<'a, T> {
        type Item = (Grid, &'a T);

        fn next(&mut self) -> Option<(Grid, &'a T)> {
            while let Some(key) = self.state {
                self.state = key.next();

                if let Some(value) = self.map.get(key) {
                    return Some((key, value));
                }
            }

            None
        }
    }

File: criterion.rs/plot/src/map.rs
Start Line: 116
End Line: 161
Chunks:

    pub struct Map<T>([Option<T>; LENGTH]);

    impl<T> Map<T> {
        pub fn new() -> Map<T> {
            Map([None, None])
        }

        pub fn contains_key(&self, key: Grid) -> bool {
            self.0[key as usize].is_some()
        }

        pub fn get(&self, key: Grid) -> Option<&T> {
            self.0[key as usize].as_ref()
        }

        pub fn get_mut(&mut self, key: Grid) -> Option<&mut T> {
            self.0[key as usize].as_mut()
        }

        pub fn insert(&mut self, key: Grid, value: T) -> Option<T> {
            let key = key as usize;
            let old = self.0[key].take();

            self.0[key] = Some(value);

            old
        }

        pub fn iter(&self) -> Items<T> {
            Items {
                map: self,
                state: Some(Grid::Major),
            }
        }
    }

    impl<T> Clone for Map<T>
    where
        T: Clone,
    {
        fn clone(&self) -> Map<T> {
            Map([self.0[0].clone(), self.0[1].clone()])
        }
    }

File: criterion.rs/plot/src/map.rs
Start Line: 161
End Line: 168
Chunks:

    impl<T> Default for Map<T> {
        fn default() -> Self {
            Self::new()
        }
    }
}

Ripgrep filtered Lines: [0, 33, 80, 124, 173]
File: criterion.rs/plot/src/data.rs
Start Line: 0
End Line: 32
Chunks:
use std::mem;

use cast::From as _0;

use crate::traits::Data;

macro_rules! impl_data {
    ($($ty:ty),+) => {
        $(
            impl Data for $ty {
                fn f64(self) -> f64 {
                    f64::cast(self)
                }
            }

            impl<'a> Data for &'a $ty {
                fn f64(self) -> f64 {
                    f64::cast(*self)
                }
            }
        )+
    }
}

impl_data!(f32, f64, i16, i32, i64, i8, isize, u16, u32, u64, u8, usize);

#[derive(Clone)]
pub struct Matrix {
    bytes: Vec<u8>,
    ncols: usize,
    nrows: usize,
}

File: criterion.rs/plot/src/data.rs
Start Line: 32
End Line: 79
Chunks:

impl Matrix {
    pub fn new<I>(rows: I, scale: <I::Item as Row>::Scale) -> Matrix
    where
        I: Iterator,
        I::Item: Row,
    {
        let ncols = I::Item::ncols();
        let bytes_per_row = ncols * mem::size_of::<f64>();
        let mut bytes = Vec::with_capacity(rows.size_hint().0 * bytes_per_row);

        let mut nrows = 0;
        for row in rows {
            nrows += 1;
            row.append_to(&mut bytes, scale);
        }

        Matrix {
            bytes,
            ncols,
            nrows,
        }
    }

    pub fn bytes(&self) -> &[u8] {
        &self.bytes
    }

    pub fn ncols(&self) -> usize {
        self.ncols
    }

    pub fn nrows(&self) -> usize {
        self.nrows
    }
}

/// Data that can serve as a row of the data matrix
pub trait Row {
    /// Private
    type Scale: Copy;

    /// Append this row to a buffer
    fn append_to(self, buffer: &mut Vec<u8>, scale: Self::Scale);
    /// Number of columns of the row
    fn ncols() -> usize;
}

File: criterion.rs/plot/src/data.rs
Start Line: 79
End Line: 123
Chunks:

fn write_f64(w: &mut impl std::io::Write, f: f64) -> std::io::Result<()> {
    w.write_all(&f.to_bits().to_le_bytes())
}

impl<A, B> Row for (A, B)
where
    A: Data,
    B: Data,
{
    type Scale = (f64, f64);

    fn append_to(self, buffer: &mut Vec<u8>, scale: (f64, f64)) {
        let (a, b) = self;

        write_f64(buffer, a.f64() * scale.0).unwrap();
        write_f64(buffer, b.f64() * scale.1).unwrap();
    }

    fn ncols() -> usize {
        2
    }
}

impl<A, B, C> Row for (A, B, C)
where
    A: Data,
    B: Data,
    C: Data,
{
    type Scale = (f64, f64, f64);

    fn append_to(self, buffer: &mut Vec<u8>, scale: (f64, f64, f64)) {
        let (a, b, c) = self;

        write_f64(buffer, a.f64() * scale.0).unwrap();
        write_f64(buffer, b.f64() * scale.1).unwrap();
        write_f64(buffer, c.f64() * scale.2).unwrap();
    }

    fn ncols() -> usize {
        3
    }
}

File: criterion.rs/plot/src/data.rs
Start Line: 123
End Line: 172
Chunks:

impl<A, B, C, D> Row for (A, B, C, D)
where
    A: Data,
    B: Data,
    C: Data,
    D: Data,
{
    type Scale = (f64, f64, f64, f64);

    fn append_to(self, buffer: &mut Vec<u8>, scale: (f64, f64, f64, f64)) {
        let (a, b, c, d) = self;

        write_f64(buffer, a.f64() * scale.0).unwrap();
        write_f64(buffer, b.f64() * scale.1).unwrap();
        write_f64(buffer, c.f64() * scale.2).unwrap();
        write_f64(buffer, d.f64() * scale.3).unwrap();
    }

    fn ncols() -> usize {
        4
    }
}

impl<A, B, C, D, E> Row for (A, B, C, D, E)
where
    A: Data,
    B: Data,
    C: Data,
    D: Data,
    E: Data,
{
    type Scale = (f64, f64, f64, f64, f64);

    #[cfg_attr(feature = "cargo-clippy", allow(clippy::many_single_char_names))]
    fn append_to(self, buffer: &mut Vec<u8>, scale: (f64, f64, f64, f64, f64)) {
        let (a, b, c, d, e) = self;

        write_f64(buffer, a.f64() * scale.0).unwrap();
        write_f64(buffer, b.f64() * scale.1).unwrap();
        write_f64(buffer, c.f64() * scale.2).unwrap();
        write_f64(buffer, d.f64() * scale.3).unwrap();
        write_f64(buffer, e.f64() * scale.4).unwrap();
    }

    fn ncols() -> usize {
        5
    }
}

Ripgrep filtered Lines: [0, 48]
File: criterion.rs/plot/src/proxy.rs
Start Line: 0
End Line: 47
Chunks:
//! Generic constructors for newtypes

#![allow(non_snake_case)]

use crate::{Font as FontType, Label as LabelType, Output as OutputType, Title as TitleType};
use std::borrow::Cow;
use std::path::Path;

/// Generic constructor for `Font`
#[cfg_attr(feature = "cargo-clippy", allow(clippy::inline_always))]
#[inline(always)]
pub fn Font<S>(string: S) -> FontType
where
    S: Into<Cow<'static, str>>,
{
    FontType(string.into())
}

/// Generic constructor for `Label`
#[cfg_attr(feature = "cargo-clippy", allow(clippy::inline_always))]
#[inline(always)]
pub fn Label<S>(string: S) -> LabelType
where
    S: Into<Cow<'static, str>>,
{
    LabelType(string.into())
}

/// Generic constructor for `Title`
#[cfg_attr(feature = "cargo-clippy", allow(clippy::inline_always))]
#[inline(always)]
pub fn Title<S>(string: S) -> TitleType
where
    S: Into<Cow<'static, str>>,
{
    TitleType(string.into())
}

/// Generic constructor for `Output`
#[cfg_attr(feature = "cargo-clippy", allow(clippy::inline_always))]
#[inline(always)]
pub fn Output<P>(path: P) -> OutputType
where
    P: Into<Cow<'static, Path>>,
{
    OutputType(path.into())
}

Ripgrep filtered Lines: [0, 47]
File: criterion.rs/plot/src/grid.rs
Start Line: 0
End Line: 46
Chunks:
//! Gridline

use crate::{Axis, Default, Display, Grid, Script};

/// Gridline properties
#[derive(Clone, Copy)]
pub struct Properties {
    hidden: bool,
}

impl Default for Properties {
    fn default() -> Properties {
        Properties { hidden: true }
    }
}

// TODO Lots of configuration pending: linetype, linewidth, etc
impl Properties {
    /// Hides the gridlines
    ///
    /// **Note** Both `Major` and `Minor` gridlines are hidden by default
    pub fn hide(&mut self) -> &mut Properties {
        self.hidden = true;
        self
    }

    /// Shows the gridlines
    pub fn show(&mut self) -> &mut Properties {
        self.hidden = false;
        self
    }
}

impl<'a> Script for (Axis, Grid, &'a Properties) {
    fn script(&self) -> String {
        let &(axis, grid, properties) = self;
        let axis = axis.display();
        let grid = grid.display();

        if properties.hidden {
            String::new()
        } else {
            format!("set grid {}{}tics\n", grid, axis)
        }
    }
}

Ripgrep filtered Lines: [0, 45, 91, 136, 182, 227, 273, 318, 364, 405, 440, 489, 539, 572, 610, 652, 694, 736, 774, 816, 863, 912, 961, 1005, 1050, 1094]
File: criterion.rs/plot/src/lib.rs
Start Line: 0
End Line: 44
Chunks:
//! [Criterion]'s plotting library.
//!
//! [Criterion]: https://github.com/bheisler/criterion.rs
//!
//! **WARNING** This library is criterion's implementation detail and there no plans to stabilize
//! it. In other words, the API may break at any time without notice.
//!
//! # Examples
//!
//! - Simple "curves" (based on [`simple.dem`](http://gnuplot.sourceforge.net/demo/simple.html))
//!
//! ![Plot](curve.svg)
//!
//! ```
//! # use std::fs;
//! # use std::path::Path;
//! use itertools_num::linspace;
//! use criterion_plot::prelude::*;
//!
//! # if let Err(_) = criterion_plot::version() {
//! #     return;
//! # }
//! let ref xs = linspace::<f64>(-10., 10., 51).collect::<Vec<_>>();
//!
//! # fs::create_dir_all(Path::new("target/doc/criterion_plot")).unwrap();
//! # assert_eq!(Some(String::new()),
//! Figure::new()
//! #   .set(Font("Helvetica"))
//! #   .set(FontSize(12.))
//! #   .set(Output(Path::new("target/doc/criterion_plot/curve.svg")))
//! #   .set(Size(1280, 720))
//!     .configure(Key, |k| {
//!         k.set(Boxed::Yes)
//!          .set(Position::Inside(Vertical::Top, Horizontal::Left))
//!     })
//!     .plot(LinesPoints {
//!               x: xs,
//!               y: xs.iter().map(|x| x.sin()),
//!           },
//!           |lp| {
//!               lp.set(Color::DarkViolet)
//!                 .set(Label("sin(x)"))
//!                 .set(LineType::Dash)
//!                 .set(PointSize(1.5))

File: criterion.rs/plot/src/lib.rs
Start Line: 44
End Line: 90
Chunks:
//!                 .set(PointType::Circle)
//!           })
//!     .plot(Steps {
//!               x: xs,
//!               y: xs.iter().map(|x| x.atan()),
//!           },
//!           |s| {
//!               s.set(Color::Rgb(0, 158, 115))
//!                .set(Label("atan(x)"))
//!                .set(LineWidth(2.))
//!           })
//!     .plot(Impulses {
//!               x: xs,
//!               y: xs.iter().map(|x| x.atan().cos()),
//!           },
//!           |i| {
//!               i.set(Color::Rgb(86, 180, 233))
//!                .set(Label("cos(atan(x))"))
//!           })
//!     .draw()  // (rest of the chain has been omitted)
//! #   .ok()
//! #   .and_then(|gnuplot| {
//! #       gnuplot.wait_with_output().ok().and_then(|p| String::from_utf8(p.stderr).ok())
//! #   }));
//! ```
//!
//! - error bars (based on
//! [Julia plotting tutorial](https://plot.ly/julia/error-bars/#Colored-and-Styled-Error-Bars))
//!
//! ![Plot](error_bar.svg)
//!
//! ```
//! # use std::fs;
//! # use std::path::Path;
//! use std::f64::consts::PI;
//!
//! use itertools_num::linspace;
//! use rand::Rng;
//! use criterion_plot::prelude::*;
//!
//! fn sinc(mut x: f64) -> f64 {
//!     if x == 0. {
//!         1.
//!     } else {
//!         x *= PI;
//!         x.sin() / x

File: criterion.rs/plot/src/lib.rs
Start Line: 90
End Line: 135
Chunks:
//!     }
//! }
//!
//! # if let Err(_) = criterion_plot::version() {
//! #     return;
//! # }
//! let ref xs_ = linspace::<f64>(-4., 4., 101).collect::<Vec<_>>();
//!
//! // Fake some data
//! let ref mut rng = rand::thread_rng();
//! let xs = linspace::<f64>(-4., 4., 13).skip(1).take(11);
//! let ys = xs.map(|x| sinc(x) + 0.05 * rng.gen::<f64>() - 0.025).collect::<Vec<_>>();
//! let y_low = ys.iter().map(|&y| y - 0.025 - 0.075 * rng.gen::<f64>()).collect::<Vec<_>>();
//! let y_high = ys.iter().map(|&y| y + 0.025 + 0.075 * rng.gen::<f64>()).collect::<Vec<_>>();
//! let xs = linspace::<f64>(-4., 4., 13).skip(1).take(11);
//! let xs = xs.map(|x| x + 0.2 * rng.gen::<f64>() - 0.1);
//!
//! # fs::create_dir_all(Path::new("target/doc/criterion_plot")).unwrap();
//! # assert_eq!(Some(String::new()),
//! Figure::new()
//! #   .set(Font("Helvetica"))
//! #   .set(FontSize(12.))
//! #   .set(Output(Path::new("target/doc/criterion_plot/error_bar.svg")))
//! #   .set(Size(1280, 720))
//!     .configure(Axis::BottomX, |a| {
//!         a.set(TicLabels {
//!             labels: &["-", "0", ""],
//!             positions: &[-PI, 0., PI],
//!         })
//!     })
//!     .configure(Key,
//!                |k| k.set(Position::Outside(Vertical::Top, Horizontal::Right)))
//!     .plot(Lines {
//!               x: xs_,
//!               y: xs_.iter().cloned().map(sinc),
//!           },
//!           |l| {
//!               l.set(Color::Rgb(0, 158, 115))
//!                .set(Label("sinc(x)"))
//!                .set(LineWidth(2.))
//!           })
//!     .plot(YErrorBars {
//!               x: xs,
//!               y: &ys,
//!               y_low: &y_low,

File: criterion.rs/plot/src/lib.rs
Start Line: 135
End Line: 181
Chunks:
//!               y_high: &y_high,
//!           },
//!           |eb| {
//!               eb.set(Color::DarkViolet)
//!                 .set(LineWidth(2.))
//!                 .set(PointType::FilledCircle)
//!                 .set(Label("measured"))
//!           })
//!     .draw()  // (rest of the chain has been omitted)
//! #   .ok()
//! #   .and_then(|gnuplot| {
//! #       gnuplot.wait_with_output().ok().and_then(|p| String::from_utf8(p.stderr).ok())
//! #   }));
//! ```
//!
//! - Candlesticks (based on
//! [`candlesticks.dem`](http://gnuplot.sourceforge.net/demo/candlesticks.html))
//!
//! ![Plot](candlesticks.svg)
//!
//! ```
//! # use std::fs;
//! # use std::path::Path;
//! use criterion_plot::prelude::*;
//! use rand::Rng;
//!
//! # if let Err(_) = criterion_plot::version() {
//! #     return;
//! # }
//! let xs = 1..11;
//!
//! // Fake some data
//! let mut rng = rand::thread_rng();
//! let bh = xs.clone().map(|_| 5f64 + 2.5 * rng.gen::<f64>()).collect::<Vec<_>>();
//! let bm = xs.clone().map(|_| 2.5f64 + 2.5 * rng.gen::<f64>()).collect::<Vec<_>>();
//! let wh = bh.iter().map(|&y| y + (10. - y) * rng.gen::<f64>()).collect::<Vec<_>>();
//! let wm = bm.iter().map(|&y| y * rng.gen::<f64>()).collect::<Vec<_>>();
//! let m = bm.iter().zip(bh.iter()).map(|(&l, &h)| (h - l) * rng.gen::<f64>() + l)
//!     .collect::<Vec<_>>();
//!
//! # fs::create_dir_all(Path::new("target/doc/criterion_plot")).unwrap();
//! # assert_eq!(Some(String::new()),
//! Figure::new()
//! #   .set(Font("Helvetica"))
//! #   .set(FontSize(12.))
//! #   .set(Output(Path::new("target/doc/criterion_plot/candlesticks.svg")))

File: criterion.rs/plot/src/lib.rs
Start Line: 181
End Line: 226
Chunks:
//! #   .set(Size(1280, 720))
//!     .set(BoxWidth(0.2))
//!     .configure(Axis::BottomX, |a| a.set(Range::Limits(0., 11.)))
//!     .plot(Candlesticks {
//!               x: xs.clone(),
//!               whisker_min: &wm,
//!               box_min: &bm,
//!               box_high: &bh,
//!               whisker_high: &wh,
//!           },
//!           |cs| {
//!               cs.set(Color::Rgb(86, 180, 233))
//!                 .set(Label("Quartiles"))
//!                 .set(LineWidth(2.))
//!           })
//!     // trick to plot the median
//!     .plot(Candlesticks {
//!               x: xs,
//!               whisker_min: &m,
//!               box_min: &m,
//!               box_high: &m,
//!               whisker_high: &m,
//!           },
//!           |cs| {
//!               cs.set(Color::Black)
//!                 .set(LineWidth(2.))
//!           })
//!     .draw()  // (rest of the chain has been omitted)
//! #   .ok()
//! #   .and_then(|gnuplot| {
//! #       gnuplot.wait_with_output().ok().and_then(|p| String::from_utf8(p.stderr).ok())
//! #   }));
//! ```
//!
//! - Multiaxis (based on [`multiaxis.dem`](http://gnuplot.sourceforge.net/demo/multiaxis.html))
//!
//! ![Plot](multiaxis.svg)
//!
//! ```
//! # use std::fs;
//! # use std::path::Path;
//! use std::f64::consts::PI;
//!
//! use itertools_num::linspace;
//! use num_complex::Complex;

File: criterion.rs/plot/src/lib.rs
Start Line: 226
End Line: 272
Chunks:
//! use criterion_plot::prelude::*;
//!
//! fn tf(x: f64) -> Complex<f64> {
//!     Complex::new(0., x) / Complex::new(10., x) / Complex::new(1., x / 10_000.)
//! }
//!
//! # if let Err(_) = criterion_plot::version() {
//! #     return;
//! # }
//! let (start, end): (f64, f64) = (1.1, 90_000.);
//! let ref xs = linspace(start.ln(), end.ln(), 101).map(|x| x.exp()).collect::<Vec<_>>();
//! let phase = xs.iter().map(|&x| tf(x).arg() * 180. / PI);
//! let magnitude = xs.iter().map(|&x| tf(x).norm());
//!
//! # fs::create_dir_all(Path::new("target/doc/criterion_plot")).unwrap();
//! # assert_eq!(Some(String::new()),
//! Figure::new().
//! #   set(Font("Helvetica")).
//! #   set(FontSize(12.)).
//! #   set(Output(Path::new("target/doc/criterion_plot/multiaxis.svg"))).
//! #   set(Size(1280, 720)).
//!     set(Title("Frequency response")).
//!     configure(Axis::BottomX, |a| a.
//!         configure(Grid::Major, |g| g.
//!             show()).
//!         set(Label("Angular frequency (rad/s)")).
//!         set(Range::Limits(start, end)).
//!         set(Scale::Logarithmic)).
//!     configure(Axis::LeftY, |a| a.
//!         set(Label("Gain")).
//!         set(Scale::Logarithmic)).
//!     configure(Axis::RightY, |a| a.
//!         configure(Grid::Major, |g| g.
//!             show()).
//!         set(Label("Phase shift ()"))).
//!     configure(Key, |k| k.
//!         set(Position::Inside(Vertical::Top, Horizontal::Center)).
//!         set(Title(" "))).
//!     plot(Lines {
//!         x: xs,
//!         y: magnitude,
//!     }, |l| l.
//!         set(Color::DarkViolet).
//!         set(Label("Magnitude")).
//!         set(LineWidth(2.))).
//!     plot(Lines {

File: criterion.rs/plot/src/lib.rs
Start Line: 272
End Line: 317
Chunks:
//!         x: xs,
//!         y: phase,
//!     }, |l| l.
//!         set(Axes::BottomXRightY).
//!         set(Color::Rgb(0, 158, 115)).
//!         set(Label("Phase")).
//!         set(LineWidth(2.))).
//!     draw().  // (rest of the chain has been omitted)
//! #   ok().and_then(|gnuplot| {
//! #       gnuplot.wait_with_output().ok().and_then(|p| {
//! #           String::from_utf8(p.stderr).ok()
//! #       })
//! #   }));
//! ```
//! - Filled curves (based on
//! [`transparent.dem`](http://gnuplot.sourceforge.net/demo/transparent.html))
//!
//! ![Plot](filled_curve.svg)
//!
//! ```
//! # use std::fs;
//! # use std::path::Path;
//! use std::f64::consts::PI;
//! use std::iter;
//!
//! use itertools_num::linspace;
//! use criterion_plot::prelude::*;
//!
//! # if let Err(_) = criterion_plot::version() {
//! #     return;
//! # }
//! let (start, end) = (-5., 5.);
//! let ref xs = linspace(start, end, 101).collect::<Vec<_>>();
//! let zeros = iter::repeat(0);
//!
//! fn gaussian(x: f64, mu: f64, sigma: f64) -> f64 {
//!     1. / (((x - mu).powi(2) / 2. / sigma.powi(2)).exp() * sigma * (2. * PI).sqrt())
//! }
//!
//! # fs::create_dir_all(Path::new("target/doc/criterion_plot")).unwrap();
//! # assert_eq!(Some(String::new()),
//! Figure::new()
//! #   .set(Font("Helvetica"))
//! #   .set(FontSize(12.))
//! #   .set(Output(Path::new("target/doc/criterion_plot/filled_curve.svg")))

File: criterion.rs/plot/src/lib.rs
Start Line: 317
End Line: 363
Chunks:
//! #   .set(Size(1280, 720))
//!     .set(Title("Transparent filled curve"))
//!     .configure(Axis::BottomX, |a| a.set(Range::Limits(start, end)))
//!     .configure(Axis::LeftY, |a| a.set(Range::Limits(0., 1.)))
//!     .configure(Key, |k| {
//!         k.set(Justification::Left)
//!          .set(Order::SampleText)
//!          .set(Position::Inside(Vertical::Top, Horizontal::Left))
//!          .set(Title("Gaussian Distribution"))
//!     })
//!     .plot(FilledCurve {
//!               x: xs,
//!               y1: xs.iter().map(|&x| gaussian(x, 0.5, 0.5)),
//!               y2: zeros.clone(),
//!           },
//!           |fc| {
//!               fc.set(Color::ForestGreen)
//!                 .set(Label(" = 0.5  = 0.5"))
//!           })
//!     .plot(FilledCurve {
//!               x: xs,
//!               y1: xs.iter().map(|&x| gaussian(x, 2.0, 1.0)),
//!               y2: zeros.clone(),
//!           },
//!           |fc| {
//!               fc.set(Color::Gold)
//!                 .set(Label(" = 2.0  = 1.0"))
//!                 .set(Opacity(0.5))
//!           })
//!     .plot(FilledCurve {
//!               x: xs,
//!               y1: xs.iter().map(|&x| gaussian(x, -1.0, 2.0)),
//!               y2: zeros,
//!           },
//!           |fc| {
//!               fc.set(Color::Red)
//!                 .set(Label(" = -1.0  = 2.0"))
//!                 .set(Opacity(0.5))
//!           })
//!     .draw()
//!     .ok()
//!     .and_then(|gnuplot| {
//!         gnuplot.wait_with_output().ok().and_then(|p| String::from_utf8(p.stderr).ok())
//!     }));
//! ```


File: criterion.rs/plot/src/lib.rs
Start Line: 363
End Line: 404
Chunks:
#![deny(missing_docs)]
#![deny(warnings)]
#![deny(bare_trait_objects)]
// This lint has lots of false positives ATM, see
// https://github.com/Manishearth/rust-clippy/issues/761
#![cfg_attr(feature = "cargo-clippy", allow(clippy::new_without_default))]
// False positives with images
#![cfg_attr(feature = "cargo-clippy", allow(clippy::doc_markdown))]
#![cfg_attr(feature = "cargo-clippy", allow(clippy::many_single_char_names))]

extern crate cast;
#[macro_use]
extern crate itertools;

use std::borrow::Cow;
use std::fmt;
use std::fs::File;
use std::io;
use std::num::ParseIntError;
use std::path::Path;
use std::process::{Child, Command};
use std::str;

use crate::data::Matrix;
use crate::traits::{Configure, Set};

mod data;
mod display;
mod map;

pub mod axis;
pub mod candlestick;
pub mod curve;
pub mod errorbar;
pub mod filledcurve;
pub mod grid;
pub mod key;
pub mod prelude;
pub mod proxy;
pub mod traits;


File: criterion.rs/plot/src/lib.rs
Start Line: 404
End Line: 439
Chunks:
/// Plot container
#[derive(Clone)]
pub struct Figure {
    alpha: Option<f64>,
    axes: map::axis::Map<axis::Properties>,
    box_width: Option<f64>,
    font: Option<Cow<'static, str>>,
    font_size: Option<f64>,
    key: Option<key::Properties>,
    output: Cow<'static, Path>,
    plots: Vec<Plot>,
    size: Option<(usize, usize)>,
    terminal: Terminal,
    tics: map::axis::Map<String>,
    title: Option<Cow<'static, str>>,
}

impl Figure {
    /// Creates an empty figure
    pub fn new() -> Figure {
        Figure {
            alpha: None,
            axes: map::axis::Map::new(),
            box_width: None,
            font: None,
            font_size: None,
            key: None,
            output: Cow::Borrowed(Path::new("output.plot")),
            plots: Vec::new(),
            size: None,
            terminal: Terminal::Svg,
            tics: map::axis::Map::new(),
            title: None,
        }
    }

File: criterion.rs/plot/src/lib.rs
Start Line: 439
End Line: 488
Chunks:

    // Allow clippy::format_push_string even with older versions of rust (<1.62) which
    // don't have it defined.
    #[allow(clippy::all)]
    fn script(&self) -> Vec<u8> {
        let mut s = String::new();

        s.push_str(&format!(
            "set output '{}'\n",
            self.output.display().to_string().replace('\'', "''")
        ));

        if let Some(width) = self.box_width {
            s.push_str(&format!("set boxwidth {}\n", width))
        }

        if let Some(ref title) = self.title {
            s.push_str(&format!("set title '{}'\n", title))
        }

        for axis in self.axes.iter() {
            s.push_str(&axis.script());
        }

        for (_, script) in self.tics.iter() {
            s.push_str(script);
        }

        if let Some(ref key) = self.key {
            s.push_str(&key.script())
        }

        if let Some(alpha) = self.alpha {
            s.push_str(&format!("set style fill transparent solid {}\n", alpha))
        }

        s.push_str(&format!("set terminal {} dashed", self.terminal.display()));

        if let Some((width, height)) = self.size {
            s.push_str(&format!(" size {}, {}", width, height))
        }

        if let Some(ref name) = self.font {
            if let Some(size) = self.font_size {
                s.push_str(&format!(" font '{},{}'", name, size))
            } else {
                s.push_str(&format!(" font '{}'", name))
            }
        }

File: criterion.rs/plot/src/lib.rs
Start Line: 488
End Line: 538
Chunks:

        // TODO This removes the crossbars from the ends of error bars, but should be configurable
        s.push_str("\nunset bars\n");

        let mut is_first_plot = true;
        for plot in &self.plots {
            let data = plot.data();

            if data.bytes().is_empty() {
                continue;
            }

            if is_first_plot {
                s.push_str("plot ");
                is_first_plot = false;
            } else {
                s.push_str(", ");
            }

            s.push_str(&format!(
                "'-' binary endian=little record={} format='%float64' using ",
                data.nrows()
            ));

            let mut is_first_col = true;
            for col in 0..data.ncols() {
                if is_first_col {
                    is_first_col = false;
                } else {
                    s.push(':');
                }
                s.push_str(&(col + 1).to_string());
            }
            s.push(' ');

            s.push_str(plot.script());
        }

        let mut buffer = s.into_bytes();
        let mut is_first = true;
        for plot in &self.plots {
            if is_first {
                is_first = false;
                buffer.push(b'\n');
            }
            buffer.extend_from_slice(plot.data().bytes());
        }

        buffer
    }

File: criterion.rs/plot/src/lib.rs
Start Line: 538
End Line: 571
Chunks:

    /// Spawns a drawing child process
    ///
    /// NOTE: stderr, stdin, and stdout are piped
    pub fn draw(&mut self) -> io::Result<Child> {
        use std::process::Stdio;

        let mut gnuplot = Command::new("gnuplot")
            .stderr(Stdio::piped())
            .stdin(Stdio::piped())
            .stdout(Stdio::piped())
            .spawn()?;
        self.dump(gnuplot.stdin.as_mut().unwrap())?;
        Ok(gnuplot)
    }

    /// Dumps the script required to produce the figure into `sink`
    pub fn dump<W>(&mut self, sink: &mut W) -> io::Result<&mut Figure>
    where
        W: io::Write,
    {
        sink.write_all(&self.script())?;
        Ok(self)
    }

    /// Saves the script required to produce the figure to `path`
    pub fn save(&self, path: &Path) -> io::Result<&Figure> {
        use std::io::Write;

        File::create(path)?.write_all(&self.script())?;
        Ok(self)
    }
}

File: criterion.rs/plot/src/lib.rs
Start Line: 571
End Line: 609
Chunks:

impl Configure<Axis> for Figure {
    type Properties = axis::Properties;

    /// Configures an axis
    fn configure<F>(&mut self, axis: Axis, configure: F) -> &mut Figure
    where
        F: FnOnce(&mut axis::Properties) -> &mut axis::Properties,
    {
        if self.axes.contains_key(axis) {
            configure(self.axes.get_mut(axis).unwrap());
        } else {
            let mut properties = Default::default();
            configure(&mut properties);
            self.axes.insert(axis, properties);
        }
        self
    }
}

impl Configure<Key> for Figure {
    type Properties = key::Properties;

    /// Configures the key (legend)
    fn configure<F>(&mut self, _: Key, configure: F) -> &mut Figure
    where
        F: FnOnce(&mut key::Properties) -> &mut key::Properties,
    {
        if self.key.is_some() {
            configure(self.key.as_mut().unwrap());
        } else {
            let mut key = Default::default();
            configure(&mut key);
            self.key = Some(key);
        }
        self
    }
}

File: criterion.rs/plot/src/lib.rs
Start Line: 609
End Line: 651
Chunks:

impl Set<BoxWidth> for Figure {
    /// Changes the box width of all the box related plots (bars, candlesticks, etc)
    ///
    /// **Note** The default value is 0
    ///
    /// # Panics
    ///
    /// Panics if `width` is a negative value
    fn set(&mut self, width: BoxWidth) -> &mut Figure {
        let width = width.0;

        assert!(width >= 0.);

        self.box_width = Some(width);
        self
    }
}

impl Set<Font> for Figure {
    /// Changes the font
    fn set(&mut self, font: Font) -> &mut Figure {
        self.font = Some(font.0);
        self
    }
}

impl Set<FontSize> for Figure {
    /// Changes the size of the font
    ///
    /// # Panics
    ///
    /// Panics if `size` is a non-positive value
    fn set(&mut self, size: FontSize) -> &mut Figure {
        let size = size.0;

        assert!(size >= 0.);

        self.font_size = Some(size);
        self
    }
}

File: criterion.rs/plot/src/lib.rs
Start Line: 651
End Line: 693
Chunks:

impl Set<Output> for Figure {
    /// Changes the output file
    ///
    /// **Note** The default output file is `output.plot`
    fn set(&mut self, output: Output) -> &mut Figure {
        self.output = output.0;
        self
    }
}

impl Set<Size> for Figure {
    /// Changes the figure size
    fn set(&mut self, size: Size) -> &mut Figure {
        self.size = Some((size.0, size.1));
        self
    }
}

impl Set<Terminal> for Figure {
    /// Changes the output terminal
    ///
    /// **Note** By default, the terminal is set to `Svg`
    fn set(&mut self, terminal: Terminal) -> &mut Figure {
        self.terminal = terminal;
        self
    }
}

impl Set<Title> for Figure {
    /// Sets the title
    fn set(&mut self, title: Title) -> &mut Figure {
        self.title = Some(title.0);
        self
    }
}

impl Default for Figure {
    fn default() -> Self {
        Self::new()
    }
}

File: criterion.rs/plot/src/lib.rs
Start Line: 693
End Line: 735
Chunks:

/// Box width for box-related plots: bars, candlesticks, etc
#[derive(Clone, Copy)]
pub struct BoxWidth(pub f64);

/// A font name
pub struct Font(Cow<'static, str>);

/// The size of a font
#[derive(Clone, Copy)]
pub struct FontSize(pub f64);

/// The key or legend
#[derive(Clone, Copy)]
pub struct Key;

/// Plot label
pub struct Label(Cow<'static, str>);

/// Width of the lines
#[derive(Clone, Copy)]
pub struct LineWidth(pub f64);

/// Fill color opacity
#[derive(Clone, Copy)]
pub struct Opacity(pub f64);

/// Output file path
pub struct Output(Cow<'static, Path>);

/// Size of the points
#[derive(Clone, Copy)]
pub struct PointSize(pub f64);

/// Axis range
#[derive(Clone, Copy)]
pub enum Range {
    /// Autoscale the axis
    Auto,
    /// Set the limits of the axis
    Limits(f64, f64),
}

File: criterion.rs/plot/src/lib.rs
Start Line: 735
End Line: 773
Chunks:

/// Figure size
#[derive(Clone, Copy)]
pub struct Size(pub usize, pub usize);

/// Labels attached to the tics of an axis
pub struct TicLabels<P, L> {
    /// Labels to attach to the tics
    pub labels: L,
    /// Position of the tics on the axis
    pub positions: P,
}

/// Figure title
pub struct Title(Cow<'static, str>);

/// A pair of axes that define a coordinate system
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub enum Axes {
    BottomXLeftY,
    BottomXRightY,
    TopXLeftY,
    TopXRightY,
}

/// A coordinate axis
#[derive(Clone, Copy)]
pub enum Axis {
    /// X axis on the bottom side of the figure
    BottomX,
    /// Y axis on the left side of the figure
    LeftY,
    /// Y axis on the right side of the figure
    RightY,
    /// X axis on the top side of the figure
    TopX,
}

File: criterion.rs/plot/src/lib.rs
Start Line: 773
End Line: 815
Chunks:

impl Axis {
    fn next(self) -> Option<Axis> {
        use crate::Axis::*;

        match self {
            BottomX => Some(LeftY),
            LeftY => Some(RightY),
            RightY => Some(TopX),
            TopX => None,
        }
    }
}

/// Color
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub enum Color {
    Black,
    Blue,
    Cyan,
    DarkViolet,
    ForestGreen,
    Gold,
    Gray,
    Green,
    Magenta,
    Red,
    /// Custom RGB color
    Rgb(u8, u8, u8),
    White,
    Yellow,
}

/// Grid line
#[derive(Clone, Copy)]
pub enum Grid {
    /// Major gridlines
    Major,
    /// Minor gridlines
    Minor,
}

File: criterion.rs/plot/src/lib.rs
Start Line: 815
End Line: 862
Chunks:

impl Grid {
    fn next(self) -> Option<Grid> {
        use crate::Grid::*;

        match self {
            Major => Some(Minor),
            Minor => None,
        }
    }
}

/// Line type
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub enum LineType {
    Dash,
    Dot,
    DotDash,
    DotDotDash,
    /// Line made of minimally sized dots
    SmallDot,
    Solid,
}

/// Point type
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub enum PointType {
    Circle,
    FilledCircle,
    FilledSquare,
    FilledTriangle,
    Plus,
    Square,
    Star,
    Triangle,
    X,
}

/// Axis scale
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub enum Scale {
    Linear,
    Logarithmic,
}

File: criterion.rs/plot/src/lib.rs
Start Line: 862
End Line: 911
Chunks:

/// Axis scale factor
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub struct ScaleFactor(pub f64);

/// Output terminal
#[allow(missing_docs)]
#[derive(Clone, Copy)]
pub enum Terminal {
    Svg,
}

/// Not public version of `std::default::Default`, used to not leak default constructors into the
/// public API
trait Default {
    /// Creates `Properties` with default configuration
    fn default() -> Self;
}

/// Enums that can produce gnuplot code
trait Display<S> {
    /// Translates the enum in gnuplot code
    fn display(&self) -> S;
}

/// Curve variant of Default
trait CurveDefault<S> {
    /// Creates `curve::Properties` with default configuration
    fn default(s: S) -> Self;
}

/// Error bar variant of Default
trait ErrorBarDefault<S> {
    /// Creates `errorbar::Properties` with default configuration
    fn default(s: S) -> Self;
}

/// Structs that can produce gnuplot code
trait Script {
    /// Translates some configuration struct into gnuplot code
    fn script(&self) -> String;
}

#[derive(Clone)]
struct Plot {
    data: Matrix,
    script: String,
}

File: criterion.rs/plot/src/lib.rs
Start Line: 911
End Line: 960
Chunks:

impl Plot {
    fn new<S>(data: Matrix, script: &S) -> Plot
    where
        S: Script,
    {
        Plot {
            data,
            script: script.script(),
        }
    }

    fn data(&self) -> &Matrix {
        &self.data
    }

    fn script(&self) -> &str {
        &self.script
    }
}

/// Possible errors when parsing gnuplot's version string
#[derive(Debug)]
pub enum VersionError {
    /// The `gnuplot` command couldn't be executed
    Exec(io::Error),
    /// The `gnuplot` command returned an error message
    Error(String),
    /// The `gnuplot` command returned invalid utf-8
    OutputError,
    /// The `gnuplot` command returned an unparseable string
    ParseError(String),
}
impl fmt::Display for VersionError {
    fn fmt(&self, f: &mut fmt::Formatter) -> fmt::Result {
        match self {
            VersionError::Exec(err) => write!(f, "`gnuplot --version` failed: {}", err),
            VersionError::Error(msg) => {
                write!(f, "`gnuplot --version` failed with error message:\n{}", msg)
            }
            VersionError::OutputError => write!(f, "`gnuplot --version` returned invalid utf-8"),
            VersionError::ParseError(msg) => write!(
                f,
                "`gnuplot --version` returned an unparseable version string: {}",
                msg
            ),
        }
    }
}

File: criterion.rs/plot/src/lib.rs
Start Line: 960
End Line: 1004
Chunks:
impl ::std::error::Error for VersionError {
    fn description(&self) -> &str {
        match self {
            VersionError::Exec(_) => "Execution Error",
            VersionError::Error(_) => "Other Error",
            VersionError::OutputError => "Output Error",
            VersionError::ParseError(_) => "Parse Error",
        }
    }

    fn cause(&self) -> Option<&dyn ::std::error::Error> {
        match self {
            VersionError::Exec(err) => Some(err),
            _ => None,
        }
    }
}

/// Structure representing a gnuplot version number.
pub struct Version {
    /// The major version number
    pub major: usize,
    /// The minor version number
    pub minor: usize,
    /// The patch level
    pub patch: String,
}

/// Returns `gnuplot` version
pub fn version() -> Result<Version, VersionError> {
    let command_output = Command::new("gnuplot")
        .arg("--version")
        .output()
        .map_err(VersionError::Exec)?;
    if !command_output.status.success() {
        let error =
            String::from_utf8(command_output.stderr).map_err(|_| VersionError::OutputError)?;
        return Err(VersionError::Error(error));
    }

    let output = String::from_utf8(command_output.stdout).map_err(|_| VersionError::OutputError)?;

    parse_version(&output).map_err(|_| VersionError::ParseError(output.clone()))
}

File: criterion.rs/plot/src/lib.rs
Start Line: 1004
End Line: 1049
Chunks:

fn parse_version(version_str: &str) -> Result<Version, Option<ParseIntError>> {
    let mut words = version_str.split_whitespace().skip(1);
    let mut version = words.next().ok_or(None)?.split('.');
    let major = version.next().ok_or(None)?.parse()?;
    let minor = version.next().ok_or(None)?.parse()?;
    let patchlevel = words.nth(1).ok_or(None)?.to_owned();

    Ok(Version {
        major,
        minor,
        patch: patchlevel,
    })
}

fn scale_factor(map: &map::axis::Map<axis::Properties>, axes: Axes) -> (f64, f64) {
    use crate::Axes::*;
    use crate::Axis::*;

    match axes {
        BottomXLeftY => (
            map.get(BottomX).map_or(1., ScaleFactorTrait::scale_factor),
            map.get(LeftY).map_or(1., ScaleFactorTrait::scale_factor),
        ),
        BottomXRightY => (
            map.get(BottomX).map_or(1., ScaleFactorTrait::scale_factor),
            map.get(RightY).map_or(1., ScaleFactorTrait::scale_factor),
        ),
        TopXLeftY => (
            map.get(TopX).map_or(1., ScaleFactorTrait::scale_factor),
            map.get(LeftY).map_or(1., ScaleFactorTrait::scale_factor),
        ),
        TopXRightY => (
            map.get(TopX).map_or(1., ScaleFactorTrait::scale_factor),
            map.get(RightY).map_or(1., ScaleFactorTrait::scale_factor),
        ),
    }
}

// XXX :-1: to intra-crate privacy rules
/// Private
trait ScaleFactorTrait {
    /// Private
    fn scale_factor(&self) -> f64;
}

File: criterion.rs/plot/src/lib.rs
Start Line: 1049
End Line: 1093
Chunks:

#[cfg(test)]
mod test {
    #[test]
    fn version() {
        if let Ok(version) = super::version() {
            assert!(version.major >= 4);
        } else {
            println!("Gnuplot not installed.");
        }
    }

    #[test]
    fn test_parse_version_on_valid_string() {
        let string = "gnuplot 5.0 patchlevel 7";
        let version = super::parse_version(&string).unwrap();
        assert_eq!(5, version.major);
        assert_eq!(0, version.minor);
        assert_eq!("7", &version.patch);
    }

    #[test]
    fn test_parse_gentoo_version() {
        let string = "gnuplot 5.2 patchlevel 5a (Gentoo revision r0)";
        let version = super::parse_version(&string).unwrap();
        assert_eq!(5, version.major);
        assert_eq!(2, version.minor);
        assert_eq!("5a", &version.patch);
    }

    #[test]
    fn test_parse_version_returns_error_on_invalid_strings() {
        let strings = [
            "",
            "foobar",
            "gnuplot 50 patchlevel 7",
            "gnuplot 5.0 patchlevel",
            "gnuplot foo.bar patchlevel 7",
        ];
        for string in &strings {
            assert!(super::parse_version(string).is_err());
        }
    }
}

Ripgrep filtered Lines: [0, 28, 73, 113, 155]
File: criterion.rs/plot/src/candlestick.rs
Start Line: 0
End Line: 27
Chunks:
//! "Candlestick" plots

use std::borrow::Cow;
use std::iter::IntoIterator;

use crate::data::Matrix;
use crate::traits::{self, Data, Set};
use crate::{Color, Default, Display, Figure, Label, LineType, LineWidth, Plot, Script};

/// Properties common to candlestick plots
pub struct Properties {
    color: Option<Color>,
    label: Option<Cow<'static, str>>,
    line_type: LineType,
    linewidth: Option<f64>,
}

impl Default for Properties {
    fn default() -> Properties {
        Properties {
            color: None,
            label: None,
            line_type: LineType::Solid,
            linewidth: None,
        }
    }
}

File: criterion.rs/plot/src/candlestick.rs
Start Line: 27
End Line: 72
Chunks:

impl Script for Properties {
    // Allow clippy::format_push_string even with older versions of rust (<1.62) which
    // don't have it defined.
    #[allow(clippy::all)]
    fn script(&self) -> String {
        let mut script = String::from("with candlesticks ");

        script.push_str(&format!("lt {} ", self.line_type.display()));

        if let Some(lw) = self.linewidth {
            script.push_str(&format!("lw {} ", lw))
        }

        if let Some(color) = self.color {
            script.push_str(&format!("lc rgb '{}' ", color.display()));
        }

        if let Some(ref label) = self.label {
            script.push_str("title '");
            script.push_str(label);
            script.push('\'')
        } else {
            script.push_str("notitle")
        }

        script
    }
}

impl Set<Color> for Properties {
    /// Sets the line color
    fn set(&mut self, color: Color) -> &mut Properties {
        self.color = Some(color);
        self
    }
}

impl Set<Label> for Properties {
    /// Sets the legend label
    fn set(&mut self, label: Label) -> &mut Properties {
        self.label = Some(label.0);
        self
    }
}

File: criterion.rs/plot/src/candlestick.rs
Start Line: 72
End Line: 112
Chunks:

impl Set<LineType> for Properties {
    /// Changes the line type
    ///
    /// **Note** By default `Solid` lines are used
    fn set(&mut self, lt: LineType) -> &mut Properties {
        self.line_type = lt;
        self
    }
}

impl Set<LineWidth> for Properties {
    /// Changes the width of the line
    ///
    /// # Panics
    ///
    /// Panics if `width` is a non-positive value
    fn set(&mut self, lw: LineWidth) -> &mut Properties {
        let lw = lw.0;

        assert!(lw > 0.);

        self.linewidth = Some(lw);
        self
    }
}

/// A candlestick consists of a box and two whiskers that extend beyond the box
pub struct Candlesticks<X, WM, BM, BH, WH> {
    /// X coordinate of the candlestick
    pub x: X,
    /// Y coordinate of the end point of the bottom whisker
    pub whisker_min: WM,
    /// Y coordinate of the bottom of the box
    pub box_min: BM,
    /// Y coordinate of the top of the box
    pub box_high: BH,
    /// Y coordinate of the end point of the top whisker
    pub whisker_high: WH,
}

File: criterion.rs/plot/src/candlestick.rs
Start Line: 112
End Line: 154
Chunks:

impl<X, WM, BM, BH, WH> traits::Plot<Candlesticks<X, WM, BM, BH, WH>> for Figure
where
    BH: IntoIterator,
    BH::Item: Data,
    BM: IntoIterator,
    BM::Item: Data,
    WH: IntoIterator,
    WH::Item: Data,
    WM: IntoIterator,
    WM::Item: Data,
    X: IntoIterator,
    X::Item: Data,
{
    type Properties = Properties;

    fn plot<F>(
        &mut self,
        candlesticks: Candlesticks<X, WM, BM, BH, WH>,
        configure: F,
    ) -> &mut Figure
    where
        F: FnOnce(&mut Properties) -> &mut Properties,
    {
        let (x_factor, y_factor) = crate::scale_factor(&self.axes, crate::Axes::BottomXLeftY);
        let Candlesticks {
            x,
            whisker_min,
            box_min,
            box_high,
            whisker_high,
        } = candlesticks;

        let data = Matrix::new(
            izip!(x, box_min, whisker_min, whisker_high, box_high),
            (x_factor, y_factor, y_factor, y_factor, y_factor),
        );
        self.plots
            .push(Plot::new(data, configure(&mut Default::default())));
        self
    }
}

Ripgrep filtered Lines: [0, 44, 67]
File: criterion.rs/src/async_executor.rs
Start Line: 0
End Line: 43
Chunks:
//! This module defines a trait that can be used to plug in different Futures executors into
//! Criterion.rs' async benchmarking support.
//!
//! Implementations are provided for:
//! * Tokio (implemented directly for tokio::Runtime)
//! * Async-std
//! * Smol
//! * The Futures crate
//!
//! Please note that async benchmarks will have a small amount of measurement overhead relative
//! to synchronous benchmarks. It is recommended to use synchronous benchmarks where possible, to
//! improve measurement accuracy.

use std::future::Future;

/// Plugin trait used to allow benchmarking on multiple different async runtimes.
///
/// Smol, Tokio and Async-std are supported out of the box, as is the current-thread runner from the
/// Futures crate; it is recommended to use whichever runtime you use in production.
pub trait AsyncExecutor {
    /// Spawn the given future onto this runtime and block until it's complete, returning the result.
    fn block_on<T>(&self, future: impl Future<Output = T>) -> T;
}

/// Runs futures on the 'futures' crate's built-in current-thread executor
#[cfg(feature = "async_futures")]
pub struct FuturesExecutor;
#[cfg(feature = "async_futures")]
impl AsyncExecutor for FuturesExecutor {
    fn block_on<T>(&self, future: impl Future<Output = T>) -> T {
        futures::executor::block_on(future)
    }
}

/// Runs futures on the 'smol' crate's global executor
#[cfg(feature = "async_smol")]
pub struct SmolExecutor;
#[cfg(feature = "async_smol")]
impl AsyncExecutor for SmolExecutor {
    fn block_on<T>(&self, future: impl Future<Output = T>) -> T {
        smol::block_on(future)
    }
}

File: criterion.rs/src/async_executor.rs
Start Line: 43
End Line: 66
Chunks:

#[cfg(feature = "async_tokio")]
impl AsyncExecutor for tokio::runtime::Runtime {
    fn block_on<T>(&self, future: impl Future<Output = T>) -> T {
        self.block_on(future)
    }
}
#[cfg(feature = "async_tokio")]
impl AsyncExecutor for &tokio::runtime::Runtime {
    fn block_on<T>(&self, future: impl Future<Output = T>) -> T {
        (*self).block_on(future)
    }
}

/// Runs futures on the 'async-std' crate's global executor
#[cfg(feature = "async_std")]
pub struct AsyncStdExecutor;
#[cfg(feature = "async_std")]
impl AsyncExecutor for AsyncStdExecutor {
    fn block_on<T>(&self, future: impl Future<Output = T>) -> T {
        async_std::task::block_on(future)
    }
}

Ripgrep filtered Lines: [0, 44, 72, 113, 162, 185]
File: criterion.rs/src/estimate.rs
Start Line: 0
End Line: 43
Chunks:
use std::fmt;

use crate::stats::Distribution;

#[derive(Clone, Copy, Eq, Ord, PartialEq, PartialOrd, Deserialize, Serialize, Debug)]
pub enum Statistic {
    Mean,
    Median,
    MedianAbsDev,
    Slope,
    StdDev,
    Typical,
}

impl fmt::Display for Statistic {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match *self {
            Statistic::Mean => f.pad("mean"),
            Statistic::Median => f.pad("median"),
            Statistic::MedianAbsDev => f.pad("MAD"),
            Statistic::Slope => f.pad("slope"),
            Statistic::StdDev => f.pad("SD"),
            Statistic::Typical => f.pad("typical"),
        }
    }
}

#[derive(Clone, PartialEq, Deserialize, Serialize, Debug)]
pub struct ConfidenceInterval {
    pub confidence_level: f64,
    pub lower_bound: f64,
    pub upper_bound: f64,
}

#[derive(Clone, PartialEq, Deserialize, Serialize, Debug)]
pub struct Estimate {
    /// The confidence interval for this estimate
    pub confidence_interval: ConfidenceInterval,
    ///
    pub point_estimate: f64,
    /// The standard error of this estimate
    pub standard_error: f64,
}

File: criterion.rs/src/estimate.rs
Start Line: 43
End Line: 71
Chunks:

pub fn build_estimates(
    distributions: &Distributions,
    points: &PointEstimates,
    cl: f64,
) -> Estimates {
    let to_estimate = |point_estimate, distribution: &Distribution<f64>| {
        let (lb, ub) = distribution.confidence_interval(cl);

        Estimate {
            confidence_interval: ConfidenceInterval {
                confidence_level: cl,
                lower_bound: lb,
                upper_bound: ub,
            },
            point_estimate,
            standard_error: distribution.std_dev(None),
        }
    };

    Estimates {
        mean: to_estimate(points.mean, &distributions.mean),
        median: to_estimate(points.median, &distributions.median),
        median_abs_dev: to_estimate(points.median_abs_dev, &distributions.median_abs_dev),
        slope: None,
        std_dev: to_estimate(points.std_dev, &distributions.std_dev),
    }
}

File: criterion.rs/src/estimate.rs
Start Line: 71
End Line: 112
Chunks:

pub fn build_change_estimates(
    distributions: &ChangeDistributions,
    points: &ChangePointEstimates,
    cl: f64,
) -> ChangeEstimates {
    let to_estimate = |point_estimate, distribution: &Distribution<f64>| {
        let (lb, ub) = distribution.confidence_interval(cl);

        Estimate {
            confidence_interval: ConfidenceInterval {
                confidence_level: cl,
                lower_bound: lb,
                upper_bound: ub,
            },
            point_estimate,
            standard_error: distribution.std_dev(None),
        }
    };

    ChangeEstimates {
        mean: to_estimate(points.mean, &distributions.mean),
        median: to_estimate(points.median, &distributions.median),
    }
}

pub struct PointEstimates {
    pub mean: f64,
    pub median: f64,
    pub median_abs_dev: f64,
    pub std_dev: f64,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct Estimates {
    pub mean: Estimate,
    pub median: Estimate,
    pub median_abs_dev: Estimate,
    pub slope: Option<Estimate>,
    pub std_dev: Estimate,
}

File: criterion.rs/src/estimate.rs
Start Line: 112
End Line: 161
Chunks:
impl Estimates {
    pub fn typical(&self) -> &Estimate {
        self.slope.as_ref().unwrap_or(&self.mean)
    }
    pub fn get(&self, stat: Statistic) -> Option<&Estimate> {
        match stat {
            Statistic::Mean => Some(&self.mean),
            Statistic::Median => Some(&self.median),
            Statistic::MedianAbsDev => Some(&self.median_abs_dev),
            Statistic::Slope => self.slope.as_ref(),
            Statistic::StdDev => Some(&self.std_dev),
            Statistic::Typical => Some(self.typical()),
        }
    }
}

pub struct Distributions {
    pub mean: Distribution<f64>,
    pub median: Distribution<f64>,
    pub median_abs_dev: Distribution<f64>,
    pub slope: Option<Distribution<f64>>,
    pub std_dev: Distribution<f64>,
}
impl Distributions {
    pub fn typical(&self) -> &Distribution<f64> {
        self.slope.as_ref().unwrap_or(&self.mean)
    }
    pub fn get(&self, stat: Statistic) -> Option<&Distribution<f64>> {
        match stat {
            Statistic::Mean => Some(&self.mean),
            Statistic::Median => Some(&self.median),
            Statistic::MedianAbsDev => Some(&self.median_abs_dev),
            Statistic::Slope => self.slope.as_ref(),
            Statistic::StdDev => Some(&self.std_dev),
            Statistic::Typical => Some(self.typical()),
        }
    }
}

pub struct ChangePointEstimates {
    pub mean: f64,
    pub median: f64,
}

#[derive(Debug, Serialize, Deserialize, Clone)]
pub struct ChangeEstimates {
    pub mean: Estimate,
    pub median: Estimate,
}

File: criterion.rs/src/estimate.rs
Start Line: 161
End Line: 184
Chunks:
impl ChangeEstimates {
    pub fn get(&self, stat: Statistic) -> &Estimate {
        match stat {
            Statistic::Mean => &self.mean,
            Statistic::Median => &self.median,
            _ => panic!("Unexpected statistic"),
        }
    }
}

pub struct ChangeDistributions {
    pub mean: Distribution<f64>,
    pub median: Distribution<f64>,
}
impl ChangeDistributions {
    pub fn get(&self, stat: Statistic) -> &Distribution<f64> {
        match stat {
            Statistic::Mean => &self.mean,
            Statistic::Median => &self.median,
            _ => panic!("Unexpected statistic"),
        }
    }
}

Ripgrep filtered Lines: [0, 31, 77, 123, 137, 182, 216, 264, 295, 337, 370, 419, 453, 489, 520, 560, 596, 621, 660, 709, 732, 774, 807, 828]
File: criterion.rs/src/html/mod.rs
Start Line: 0
End Line: 30
Chunks:
use crate::report::{make_filename_safe, BenchmarkId, MeasurementData, Report, ReportContext};
use crate::stats::bivariate::regression::Slope;

use crate::estimate::Estimate;
use crate::format;
use crate::fs;
use crate::measurement::ValueFormatter;
use crate::plot::{PlotContext, PlotData, Plotter};
use crate::SavedSample;
use criterion_plot::Size;
use serde::Serialize;
use std::cell::RefCell;
use std::cmp::Ordering;
use std::collections::{BTreeSet, HashMap};
use std::path::{Path, PathBuf};
use tinytemplate::TinyTemplate;

const THUMBNAIL_SIZE: Option<Size> = Some(Size(450, 300));

fn debug_context<S: Serialize>(path: &Path, context: &S) {
    if crate::debug_enabled() {
        let mut context_path = PathBuf::from(path);
        context_path.set_extension("json");
        println!("Writing report context to {:?}", context_path);
        let result = fs::save(context, &context_path);
        if let Err(e) = result {
            error!("Failed to write report context debug output: {}", e);
        }
    }
}

File: criterion.rs/src/html/mod.rs
Start Line: 30
End Line: 76
Chunks:

#[derive(Serialize)]
struct Context {
    title: String,
    confidence: String,

    thumbnail_width: usize,
    thumbnail_height: usize,

    slope: Option<ConfidenceInterval>,
    r2: ConfidenceInterval,
    mean: ConfidenceInterval,
    std_dev: ConfidenceInterval,
    median: ConfidenceInterval,
    mad: ConfidenceInterval,
    throughput: Option<ConfidenceInterval>,

    additional_plots: Vec<Plot>,

    comparison: Option<Comparison>,
}

#[derive(Serialize)]
struct IndividualBenchmark {
    name: String,
    path: String,
    regression_exists: bool,
}
impl IndividualBenchmark {
    fn from_id(
        output_directory: &Path,
        path_prefix: &str,
        id: &BenchmarkId,
    ) -> IndividualBenchmark {
        let mut regression_path = PathBuf::from(output_directory);
        regression_path.push(id.as_directory_name());
        regression_path.push("report");
        regression_path.push("regression.svg");

        IndividualBenchmark {
            name: id.as_title().to_owned(),
            path: format!("{}/{}", path_prefix, id.as_directory_name()),
            regression_exists: regression_path.is_file(),
        }
    }
}

File: criterion.rs/src/html/mod.rs
Start Line: 76
End Line: 122
Chunks:

#[derive(Serialize)]
struct SummaryContext {
    group_id: String,

    thumbnail_width: usize,
    thumbnail_height: usize,

    violin_plot: Option<String>,
    line_chart: Option<String>,

    benchmarks: Vec<IndividualBenchmark>,
}

#[derive(Serialize)]
struct ConfidenceInterval {
    lower: String,
    upper: String,
    point: String,
}

#[derive(Serialize)]
struct Plot {
    name: String,
    url: String,
}
impl Plot {
    fn new(name: &str, url: &str) -> Plot {
        Plot {
            name: name.to_owned(),
            url: url.to_owned(),
        }
    }
}

#[derive(Serialize)]
struct Comparison {
    p_value: String,
    inequality: String,
    significance_level: String,
    explanation: String,

    change: ConfidenceInterval,
    thrpt_change: Option<ConfidenceInterval>,
    additional_plots: Vec<Plot>,
}

File: criterion.rs/src/html/mod.rs
Start Line: 122
End Line: 136
Chunks:

fn if_exists(output_directory: &Path, path: &Path) -> Option<String> {
    let report_path = path.join("report/index.html");
    if PathBuf::from(output_directory).join(&report_path).is_file() {
        Some(report_path.to_string_lossy().to_string())
    } else {
        None
    }
}
#[derive(Serialize, Debug)]
struct ReportLink<'a> {
    name: &'a str,
    path: Option<String>,
}

File: criterion.rs/src/html/mod.rs
Start Line: 136
End Line: 181
Chunks:
impl<'a> ReportLink<'a> {
    // TODO: Would be nice if I didn't have to keep making these components filename-safe.
    fn group(output_directory: &Path, group_id: &'a str) -> ReportLink<'a> {
        let path = PathBuf::from(make_filename_safe(group_id));

        ReportLink {
            name: group_id,
            path: if_exists(output_directory, &path),
        }
    }

    fn function(output_directory: &Path, group_id: &str, function_id: &'a str) -> ReportLink<'a> {
        let mut path = PathBuf::from(make_filename_safe(group_id));
        path.push(make_filename_safe(function_id));

        ReportLink {
            name: function_id,
            path: if_exists(output_directory, &path),
        }
    }

    fn value(output_directory: &Path, group_id: &str, value_str: &'a str) -> ReportLink<'a> {
        let mut path = PathBuf::from(make_filename_safe(group_id));
        path.push(make_filename_safe(value_str));

        ReportLink {
            name: value_str,
            path: if_exists(output_directory, &path),
        }
    }

    fn individual(output_directory: &Path, id: &'a BenchmarkId) -> ReportLink<'a> {
        let path = PathBuf::from(id.as_directory_name());
        ReportLink {
            name: id.as_title(),
            path: if_exists(output_directory, &path),
        }
    }
}

#[derive(Serialize)]
struct BenchmarkValueGroup<'a> {
    value: Option<ReportLink<'a>>,
    benchmarks: Vec<ReportLink<'a>>,
}

File: criterion.rs/src/html/mod.rs
Start Line: 181
End Line: 215
Chunks:

#[derive(Serialize)]
struct BenchmarkGroup<'a> {
    group_report: ReportLink<'a>,

    function_ids: Option<Vec<ReportLink<'a>>>,
    values: Option<Vec<ReportLink<'a>>>,

    individual_links: Vec<BenchmarkValueGroup<'a>>,
}
impl<'a> BenchmarkGroup<'a> {
    fn new(output_directory: &Path, ids: &[&'a BenchmarkId]) -> BenchmarkGroup<'a> {
        let group_id = &ids[0].group_id;
        let group_report = ReportLink::group(output_directory, group_id);

        let mut function_ids = Vec::with_capacity(ids.len());
        let mut values = Vec::with_capacity(ids.len());
        let mut individual_links = HashMap::with_capacity(ids.len());

        for id in ids.iter() {
            let function_id = id.function_id.as_deref();
            let value = id.value_str.as_deref();

            let individual_link = ReportLink::individual(output_directory, id);

            function_ids.push(function_id);
            values.push(value);

            individual_links.insert((function_id, value), individual_link);
        }

        fn parse_opt(os: &Option<&str>) -> Option<f64> {
            os.and_then(|s| s.parse::<f64>().ok())
        }

File: criterion.rs/src/html/mod.rs
Start Line: 215
End Line: 263
Chunks:

        // If all of the value strings can be parsed into a number, sort/dedupe
        // numerically. Otherwise sort lexicographically.
        if values.iter().all(|os| parse_opt(os).is_some()) {
            values.sort_unstable_by(|v1, v2| {
                let num1 = parse_opt(v1);
                let num2 = parse_opt(v2);

                num1.partial_cmp(&num2).unwrap_or(Ordering::Less)
            });
            values.dedup_by_key(|os| parse_opt(os).unwrap());
        } else {
            values.sort_unstable();
            values.dedup();
        }

        // Sort and dedupe functions by name.
        function_ids.sort_unstable();
        function_ids.dedup();

        let mut value_groups = Vec::with_capacity(values.len());
        for value in values.iter() {
            let row = function_ids
                .iter()
                .filter_map(|f| individual_links.remove(&(*f, *value)))
                .collect::<Vec<_>>();
            value_groups.push(BenchmarkValueGroup {
                value: value.map(|s| ReportLink::value(output_directory, group_id, s)),
                benchmarks: row,
            });
        }

        let function_ids = function_ids
            .into_iter()
            .map(|os| os.map(|s| ReportLink::function(output_directory, group_id, s)))
            .collect::<Option<Vec<_>>>();
        let values = values
            .into_iter()
            .map(|os| os.map(|s| ReportLink::value(output_directory, group_id, s)))
            .collect::<Option<Vec<_>>>();

        BenchmarkGroup {
            group_report,
            function_ids,
            values,
            individual_links: value_groups,
        }
    }

File: criterion.rs/src/html/mod.rs
Start Line: 263
End Line: 294
Chunks:
}

#[derive(Serialize)]
struct IndexContext<'a> {
    groups: Vec<BenchmarkGroup<'a>>,
}

pub struct Html {
    templates: TinyTemplate<'static>,
    plotter: RefCell<Box<dyn Plotter>>,
}
impl Html {
    pub(crate) fn new(plotter: Box<dyn Plotter>) -> Html {
        let mut templates = TinyTemplate::new();
        templates
            .add_template("report_link", include_str!("report_link.html.tt"))
            .expect("Unable to parse report_link template.");
        templates
            .add_template("index", include_str!("index.html.tt"))
            .expect("Unable to parse index template.");
        templates
            .add_template("benchmark_report", include_str!("benchmark_report.html.tt"))
            .expect("Unable to parse benchmark_report template");
        templates
            .add_template("summary_report", include_str!("summary_report.html.tt"))
            .expect("Unable to parse summary_report template");

        let plotter = RefCell::new(plotter);
        Html { templates, plotter }
    }
}

File: criterion.rs/src/html/mod.rs
Start Line: 294
End Line: 336
Chunks:
impl Report for Html {
    fn measurement_complete(
        &self,
        id: &BenchmarkId,
        report_context: &ReportContext,
        measurements: &MeasurementData<'_>,
        formatter: &dyn ValueFormatter,
    ) {
        try_else_return!({
            let mut report_dir = report_context.output_directory.clone();
            report_dir.push(id.as_directory_name());
            report_dir.push("report");
            fs::mkdirp(&report_dir)
        });

        let typical_estimate = &measurements.absolute_estimates.typical();

        let time_interval = |est: &Estimate| -> ConfidenceInterval {
            ConfidenceInterval {
                lower: formatter.format_value(est.confidence_interval.lower_bound),
                point: formatter.format_value(est.point_estimate),
                upper: formatter.format_value(est.confidence_interval.upper_bound),
            }
        };

        let data = measurements.data;

        elapsed! {
            "Generating plots",
            self.generate_plots(id, report_context, formatter, measurements)
        }

        let mut additional_plots = vec![
            Plot::new("Typical", "typical.svg"),
            Plot::new("Mean", "mean.svg"),
            Plot::new("Std. Dev.", "SD.svg"),
            Plot::new("Median", "median.svg"),
            Plot::new("MAD", "MAD.svg"),
        ];
        if measurements.absolute_estimates.slope.is_some() {
            additional_plots.push(Plot::new("Slope", "slope.svg"));
        }

File: criterion.rs/src/html/mod.rs
Start Line: 336
End Line: 369
Chunks:

        let throughput = measurements
            .throughput
            .as_ref()
            .map(|thr| ConfidenceInterval {
                lower: formatter
                    .format_throughput(thr, typical_estimate.confidence_interval.upper_bound),
                upper: formatter
                    .format_throughput(thr, typical_estimate.confidence_interval.lower_bound),
                point: formatter.format_throughput(thr, typical_estimate.point_estimate),
            });

        let context = Context {
            title: id.as_title().to_owned(),
            confidence: format!(
                "{:.2}",
                typical_estimate.confidence_interval.confidence_level
            ),

            thumbnail_width: THUMBNAIL_SIZE.unwrap().0,
            thumbnail_height: THUMBNAIL_SIZE.unwrap().1,

            slope: measurements
                .absolute_estimates
                .slope
                .as_ref()
                .map(time_interval),
            mean: time_interval(&measurements.absolute_estimates.mean),
            median: time_interval(&measurements.absolute_estimates.median),
            mad: time_interval(&measurements.absolute_estimates.median_abs_dev),
            std_dev: time_interval(&measurements.absolute_estimates.std_dev),
            throughput,


File: criterion.rs/src/html/mod.rs
Start Line: 369
End Line: 418
Chunks:
            r2: ConfidenceInterval {
                lower: format!(
                    "{:0.7}",
                    Slope(typical_estimate.confidence_interval.lower_bound).r_squared(&data)
                ),
                upper: format!(
                    "{:0.7}",
                    Slope(typical_estimate.confidence_interval.upper_bound).r_squared(&data)
                ),
                point: format!(
                    "{:0.7}",
                    Slope(typical_estimate.point_estimate).r_squared(&data)
                ),
            },

            additional_plots,

            comparison: self.comparison(measurements),
        };

        let mut report_path = report_context.output_directory.clone();
        report_path.push(id.as_directory_name());
        report_path.push("report");
        report_path.push("index.html");
        debug_context(&report_path, &context);

        let text = self
            .templates
            .render("benchmark_report", &context)
            .expect("Failed to render benchmark report template");
        try_else_return!(fs::save_string(&text, &report_path));
    }

    fn summarize(
        &self,
        context: &ReportContext,
        all_ids: &[BenchmarkId],
        formatter: &dyn ValueFormatter,
    ) {
        let all_ids = all_ids
            .iter()
            .filter(|id| {
                let id_dir = context.output_directory.join(id.as_directory_name());
                fs::is_dir(&id_dir)
            })
            .collect::<Vec<_>>();
        if all_ids.is_empty() {
            return;
        }

File: criterion.rs/src/html/mod.rs
Start Line: 418
End Line: 452
Chunks:

        let group_id = all_ids[0].group_id.clone();

        let data = self.load_summary_data(&context.output_directory, &all_ids);

        let mut function_ids = BTreeSet::new();
        let mut value_strs = Vec::with_capacity(all_ids.len());
        for id in all_ids {
            if let Some(ref function_id) = id.function_id {
                function_ids.insert(function_id);
            }
            if let Some(ref value_str) = id.value_str {
                value_strs.push(value_str);
            }
        }

        fn try_parse(s: &str) -> Option<f64> {
            s.parse::<f64>().ok()
        }

        // If all of the value strings can be parsed into a number, sort/dedupe
        // numerically. Otherwise sort lexicographically.
        if value_strs.iter().all(|os| try_parse(os).is_some()) {
            value_strs.sort_unstable_by(|v1, v2| {
                let num1 = try_parse(v1);
                let num2 = try_parse(v2);

                num1.partial_cmp(&num2).unwrap_or(Ordering::Less)
            });
            value_strs.dedup_by_key(|os| try_parse(os).unwrap());
        } else {
            value_strs.sort_unstable();
            value_strs.dedup();
        }

File: criterion.rs/src/html/mod.rs
Start Line: 452
End Line: 488
Chunks:

        for function_id in function_ids {
            let samples_with_function: Vec<_> = data
                .iter()
                .by_ref()
                .filter(|&&(id, _)| id.function_id.as_ref() == Some(function_id))
                .collect();

            if samples_with_function.len() > 1 {
                let subgroup_id =
                    BenchmarkId::new(group_id.clone(), Some(function_id.clone()), None, None);

                self.generate_summary(
                    &subgroup_id,
                    &samples_with_function,
                    context,
                    formatter,
                    false,
                );
            }
        }

        for value_str in value_strs {
            let samples_with_value: Vec<_> = data
                .iter()
                .by_ref()
                .filter(|&&(id, _)| id.value_str.as_ref() == Some(value_str))
                .collect();

            if samples_with_value.len() > 1 {
                let subgroup_id =
                    BenchmarkId::new(group_id.clone(), None, Some(value_str.clone()), None);

                self.generate_summary(&subgroup_id, &samples_with_value, context, formatter, false);
            }
        }

File: criterion.rs/src/html/mod.rs
Start Line: 488
End Line: 519
Chunks:

        let mut all_data = data.iter().by_ref().collect::<Vec<_>>();
        // First sort the ids/data by value.
        // If all of the value strings can be parsed into a number, sort/dedupe
        // numerically. Otherwise sort lexicographically.
        let all_values_numeric = all_data
            .iter()
            .all(|(id, _)| id.value_str.as_deref().and_then(try_parse).is_some());
        if all_values_numeric {
            all_data.sort_unstable_by(|(a, _), (b, _)| {
                let num1 = a.value_str.as_deref().and_then(try_parse);
                let num2 = b.value_str.as_deref().and_then(try_parse);

                num1.partial_cmp(&num2).unwrap_or(Ordering::Less)
            });
        } else {
            all_data.sort_unstable_by_key(|(id, _)| id.value_str.as_ref());
        }
        // Next, sort the ids/data by function name. This results in a sorting priority of
        // function name, then value. This one has to be a stable sort.
        all_data.sort_by_key(|(id, _)| id.function_id.as_ref());

        self.generate_summary(
            &BenchmarkId::new(group_id, None, None, None),
            &all_data,
            context,
            formatter,
            true,
        );
        self.plotter.borrow_mut().wait();
    }

File: criterion.rs/src/html/mod.rs
Start Line: 519
End Line: 559
Chunks:

    fn final_summary(&self, report_context: &ReportContext) {
        let output_directory = &report_context.output_directory;
        if !fs::is_dir(&output_directory) {
            return;
        }

        let mut found_ids = try_else_return!(fs::list_existing_benchmarks(&output_directory));
        found_ids.sort_unstable_by_key(|id| id.id().to_owned());

        // Group IDs by group id
        let mut id_groups: HashMap<&str, Vec<&BenchmarkId>> = HashMap::new();
        for id in found_ids.iter() {
            id_groups
                .entry(&id.group_id)
                .or_insert_with(Vec::new)
                .push(id);
        }

        let mut groups = id_groups
            .into_values()
            .map(|group| BenchmarkGroup::new(output_directory, &group))
            .collect::<Vec<BenchmarkGroup<'_>>>();
        groups.sort_unstable_by_key(|g| g.group_report.name);

        try_else_return!(fs::mkdirp(&output_directory.join("report")));

        let report_path = output_directory.join("report").join("index.html");

        let context = IndexContext { groups };

        debug_context(&report_path, &context);

        let text = self
            .templates
            .render("index", &context)
            .expect("Failed to render index template");
        try_else_return!(fs::save_string(&text, &report_path,));
    }
}

File: criterion.rs/src/html/mod.rs
Start Line: 559
End Line: 595
Chunks:
impl Html {
    fn comparison(&self, measurements: &MeasurementData<'_>) -> Option<Comparison> {
        if let Some(ref comp) = measurements.comparison {
            let different_mean = comp.p_value < comp.significance_threshold;
            let mean_est = &comp.relative_estimates.mean;
            let explanation_str: String;

            if !different_mean {
                explanation_str = "No change in performance detected.".to_owned();
            } else {
                let comparison = compare_to_threshold(mean_est, comp.noise_threshold);
                match comparison {
                    ComparisonResult::Improved => {
                        explanation_str = "Performance has improved.".to_owned();
                    }
                    ComparisonResult::Regressed => {
                        explanation_str = "Performance has regressed.".to_owned();
                    }
                    ComparisonResult::NonSignificant => {
                        explanation_str = "Change within noise threshold.".to_owned();
                    }
                }
            }

            let comp = Comparison {
                p_value: format!("{:.2}", comp.p_value),
                inequality: (if different_mean { "<" } else { ">" }).to_owned(),
                significance_level: format!("{:.2}", comp.significance_threshold),
                explanation: explanation_str,

                change: ConfidenceInterval {
                    point: format::change(mean_est.point_estimate, true),
                    lower: format::change(mean_est.confidence_interval.lower_bound, true),
                    upper: format::change(mean_est.confidence_interval.upper_bound, true),
                },


File: criterion.rs/src/html/mod.rs
Start Line: 595
End Line: 620
Chunks:
                thrpt_change: measurements.throughput.as_ref().map(|_| {
                    let to_thrpt_estimate = |ratio: f64| 1.0 / (1.0 + ratio) - 1.0;
                    ConfidenceInterval {
                        point: format::change(to_thrpt_estimate(mean_est.point_estimate), true),
                        lower: format::change(
                            to_thrpt_estimate(mean_est.confidence_interval.lower_bound),
                            true,
                        ),
                        upper: format::change(
                            to_thrpt_estimate(mean_est.confidence_interval.upper_bound),
                            true,
                        ),
                    }
                }),

                additional_plots: vec![
                    Plot::new("Change in mean", "change/mean.svg"),
                    Plot::new("Change in median", "change/median.svg"),
                    Plot::new("T-Test", "change/t-test.svg"),
                ],
            };
            Some(comp)
        } else {
            None
        }

File: criterion.rs/src/html/mod.rs
Start Line: 620
End Line: 659
Chunks:
    }

    fn generate_plots(
        &self,
        id: &BenchmarkId,
        context: &ReportContext,
        formatter: &dyn ValueFormatter,
        measurements: &MeasurementData<'_>,
    ) {
        let plot_ctx = PlotContext {
            id,
            context,
            size: None,
            is_thumbnail: false,
        };

        let plot_data = PlotData {
            measurements,
            formatter,
            comparison: None,
        };

        let plot_ctx_small = plot_ctx.thumbnail(true).size(THUMBNAIL_SIZE);

        self.plotter.borrow_mut().pdf(plot_ctx, plot_data);
        self.plotter.borrow_mut().pdf(plot_ctx_small, plot_data);
        if measurements.absolute_estimates.slope.is_some() {
            self.plotter.borrow_mut().regression(plot_ctx, plot_data);
            self.plotter
                .borrow_mut()
                .regression(plot_ctx_small, plot_data);
        } else {
            self.plotter
                .borrow_mut()
                .iteration_times(plot_ctx, plot_data);
            self.plotter
                .borrow_mut()
                .iteration_times(plot_ctx_small, plot_data);
        }

File: criterion.rs/src/html/mod.rs
Start Line: 659
End Line: 708
Chunks:

        self.plotter
            .borrow_mut()
            .abs_distributions(plot_ctx, plot_data);

        if let Some(ref comp) = measurements.comparison {
            try_else_return!({
                let mut change_dir = context.output_directory.clone();
                change_dir.push(id.as_directory_name());
                change_dir.push("report");
                change_dir.push("change");
                fs::mkdirp(&change_dir)
            });

            try_else_return!({
                let mut both_dir = context.output_directory.clone();
                both_dir.push(id.as_directory_name());
                both_dir.push("report");
                both_dir.push("both");
                fs::mkdirp(&both_dir)
            });

            let comp_data = plot_data.comparison(comp);

            self.plotter.borrow_mut().pdf(plot_ctx, comp_data);
            self.plotter.borrow_mut().pdf(plot_ctx_small, comp_data);
            if measurements.absolute_estimates.slope.is_some()
                && comp.base_estimates.slope.is_some()
            {
                self.plotter.borrow_mut().regression(plot_ctx, comp_data);
                self.plotter
                    .borrow_mut()
                    .regression(plot_ctx_small, comp_data);
            } else {
                self.plotter
                    .borrow_mut()
                    .iteration_times(plot_ctx, comp_data);
                self.plotter
                    .borrow_mut()
                    .iteration_times(plot_ctx_small, comp_data);
            }
            self.plotter.borrow_mut().t_test(plot_ctx, comp_data);
            self.plotter
                .borrow_mut()
                .rel_distributions(plot_ctx, comp_data);
        }

        self.plotter.borrow_mut().wait();
    }

File: criterion.rs/src/html/mod.rs
Start Line: 708
End Line: 731
Chunks:

    fn load_summary_data<'a>(
        &self,
        output_directory: &Path,
        all_ids: &[&'a BenchmarkId],
    ) -> Vec<(&'a BenchmarkId, Vec<f64>)> {
        all_ids
            .iter()
            .filter_map(|id| {
                let entry = output_directory.join(id.as_directory_name()).join("new");

                let SavedSample { iters, times, .. } =
                    try_else_return!(fs::load(&entry.join("sample.json")), || None);
                let avg_times = iters
                    .into_iter()
                    .zip(times)
                    .map(|(iters, time)| time / iters)
                    .collect::<Vec<_>>();

                Some((*id, avg_times))
            })
            .collect::<Vec<_>>()
    }

File: criterion.rs/src/html/mod.rs
Start Line: 731
End Line: 773
Chunks:

    fn generate_summary(
        &self,
        id: &BenchmarkId,
        data: &[&(&BenchmarkId, Vec<f64>)],
        report_context: &ReportContext,
        formatter: &dyn ValueFormatter,
        full_summary: bool,
    ) {
        let plot_ctx = PlotContext {
            id,
            context: report_context,
            size: None,
            is_thumbnail: false,
        };

        try_else_return!(
            {
                let mut report_dir = report_context.output_directory.clone();
                report_dir.push(id.as_directory_name());
                report_dir.push("report");
                fs::mkdirp(&report_dir)
            },
            || {}
        );

        self.plotter.borrow_mut().violin(plot_ctx, formatter, data);

        let value_types: Vec<_> = data.iter().map(|&&(id, _)| id.value_type()).collect();
        let mut line_path = None;

        if value_types.iter().all(|x| x == &value_types[0]) {
            if let Some(value_type) = value_types[0] {
                let values: Vec<_> = data.iter().map(|&&(id, _)| id.as_number()).collect();
                if values.iter().any(|x| x != &values[0]) {
                    self.plotter
                        .borrow_mut()
                        .line_comparison(plot_ctx, formatter, data, value_type);
                    line_path = Some(plot_ctx.line_comparison_path());
                }
            }
        }

File: criterion.rs/src/html/mod.rs
Start Line: 773
End Line: 806
Chunks:

        let path_prefix = if full_summary { "../.." } else { "../../.." };
        let benchmarks = data
            .iter()
            .map(|&&(id, _)| {
                IndividualBenchmark::from_id(&report_context.output_directory, path_prefix, id)
            })
            .collect();

        let context = SummaryContext {
            group_id: id.as_title().to_owned(),

            thumbnail_width: THUMBNAIL_SIZE.unwrap().0,
            thumbnail_height: THUMBNAIL_SIZE.unwrap().1,

            violin_plot: Some(plot_ctx.violin_path().to_string_lossy().into_owned()),
            line_chart: line_path.map(|p| p.to_string_lossy().into_owned()),

            benchmarks,
        };

        let mut report_path = report_context.output_directory.clone();
        report_path.push(id.as_directory_name());
        report_path.push("report");
        report_path.push("index.html");
        debug_context(&report_path, &context);

        let text = self
            .templates
            .render("summary_report", &context)
            .expect("Failed to render summary report template");
        try_else_return!(fs::save_string(&text, &report_path,), || {});
    }

File: criterion.rs/src/html/mod.rs
Start Line: 806
End Line: 827
Chunks:
}

enum ComparisonResult {
    Improved,
    Regressed,
    NonSignificant,
}

fn compare_to_threshold(estimate: &Estimate, noise: f64) -> ComparisonResult {
    let ci = &estimate.confidence_interval;
    let lb = ci.lower_bound;
    let ub = ci.upper_bound;

    if lb < -noise && ub < -noise {
        ComparisonResult::Improved
    } else if lb > noise && ub > noise {
        ComparisonResult::Regressed
    } else {
        ComparisonResult::NonSignificant
    }
}

Ripgrep filtered Lines: [0, 39, 83, 133]
File: criterion.rs/src/macros.rs
Start Line: 0
End Line: 38
Chunks:
//! Contains macros which together define a benchmark harness that can be used
//! in place of the standard benchmark harness. This allows the user to run
//! Criterion.rs benchmarks with `cargo bench`.

/// Macro used to define a function group for the benchmark harness; see the
/// `criterion_main!` macro for more details.
///
/// This is used to define a function group; a collection of functions to call with a common
/// Criterion configuration. Accepts two forms which can be seen below.
///
/// Note that the group name given here is not important, it must simply
/// be unique. Note also that this macro is not related to the `Criterion::benchmark_group` function
/// or the `BenchmarkGroup` type.
///
/// # Examples:
///
/// Complete form:
///
/// ```
/// # #[macro_use]
/// # extern crate criterion;
/// # use criterion::Criterion;
/// # fn bench_method1(c: &mut Criterion) {
/// # }
/// #
/// # fn bench_method2(c: &mut Criterion) {
/// # }
/// #
/// criterion_group!{
///     name = benches;
///     config = Criterion::default();
///     targets = bench_method1, bench_method2
/// }
/// #
/// # fn main() {}
/// ```
///
/// In this form, all of the options are clearly spelled out. This expands to

File: criterion.rs/src/macros.rs
Start Line: 38
End Line: 82
Chunks:
/// a function named benches, which uses the given config expression to create
/// an instance of the Criterion struct. This is then passed by mutable
/// reference to the targets.
///
/// Compact Form:
///
/// ```
/// # #[macro_use]
/// # extern crate criterion;
/// # use criterion::Criterion;
/// # fn bench_method1(c: &mut Criterion) {
/// # }
/// #
/// # fn bench_method2(c: &mut Criterion) {
/// # }
/// #
/// criterion_group!(benches, bench_method1, bench_method2);
/// #
/// # fn main() {}
/// ```
/// In this form, the first parameter is the name of the group and subsequent
/// parameters are the target methods. The Criterion struct will be created using
/// the `Criterion::default()` function. If you wish to customize the
/// configuration, use the complete form and provide your own configuration
/// function.
#[macro_export]
macro_rules! criterion_group {
    (name = $name:ident; config = $config:expr; targets = $( $target:path ),+ $(,)*) => {
        pub fn $name() {
            let mut criterion: $crate::Criterion<_> = $config
                .configure_from_args();
            $(
                $target(&mut criterion);
            )+
        }
    };
    ($name:ident, $( $target:path ),+ $(,)*) => {
        $crate::criterion_group!{
            name = $name;
            config = $crate::Criterion::default();
            targets = $( $target ),+
        }
    }
}

File: criterion.rs/src/macros.rs
Start Line: 82
End Line: 132
Chunks:

/// Macro which expands to a benchmark harness.
///
/// Currently, using Criterion.rs requires disabling the benchmark harness
/// generated automatically by rustc. This can be done like so:
///
/// ```toml
/// [[bench]]
/// name = "my_bench"
/// harness = false
/// ```
///
/// In this case, `my_bench` must be a rust file inside the 'benches' directory,
/// like so:
///
/// `benches/my_bench.rs`
///
/// Since we've disabled the default benchmark harness, we need to add our own:
///
/// ```ignore
/// #[macro_use]
/// extern crate criterion;
/// use criterion::Criterion;
/// fn bench_method1(c: &mut Criterion) {
/// }
///
/// fn bench_method2(c: &mut Criterion) {
/// }
///
/// criterion_group!(benches, bench_method1, bench_method2);
/// criterion_main!(benches);
/// ```
///
/// The `criterion_main` macro expands to a `main` function which runs all of the
/// benchmarks in the given groups.
///
#[macro_export]
macro_rules! criterion_main {
    ( $( $group:path ),+ $(,)* ) => {
        fn main() {
            $(
                $group();
            )+

            $crate::Criterion::default()
                .configure_from_args()
                .final_summary();
        }
    }
}

Ripgrep filtered Lines: [0, 29]
File: criterion.rs/src/profiler.rs
Start Line: 0
End Line: 28
Chunks:
//! This module provides an extension trait which allows in-process profilers
//! to be hooked into the `--profile-time` argument at compile-time. Users of
//! out-of-process profilers such as perf don't need to do anything special.

use std::path::Path;

/// Extension trait for external crates to implement which provides start/stop
/// hooks when profiling (but not when benchmarking) functions.
pub trait Profiler {
    /// This function is called when Criterion.rs starts profiling a particular
    /// benchmark. It provides the stringified benchmark ID and
    /// a path to a directory where the profiler can store its data.
    fn start_profiling(&mut self, benchmark_id: &str, benchmark_dir: &Path);

    /// This function is called after Criterion.rs stops profiling a particular
    /// benchmark. The benchmark ID and directory are the same as in the call
    /// to `start`, provided for convenience.
    fn stop_profiling(&mut self, benchmark_id: &str, benchmark_dir: &Path);
}

/// Dummy profiler implementation, representing cases where the profiler is
/// an external process (eg. perftools, etc.) which do not require start/stop
/// hooks. This implementation does nothing and is used as the default.
pub struct ExternalProfiler;
impl Profiler for ExternalProfiler {
    fn start_profiling(&mut self, _benchmark_id: &str, _benchmark_dir: &Path) {}
    fn stop_profiling(&mut self, _benchmark_id: &str, _benchmark_dir: &Path) {}
}

Ripgrep filtered Lines: [0, 48]
File: criterion.rs/src/macros_private.rs
Start Line: 0
End Line: 47
Chunks:
//! Private macro used for error handling.

/// Logs an error, ignores an `Ok` value.
macro_rules! log_if_err {
    ($x:expr) => {
        let closure = || {
            try_else_return!($x);
        };
        closure();
    };
}

/// Matches a result, returning the `Ok` value in case of success,
/// exits the calling function otherwise.
/// A closure which returns the return value for the function can
/// be passed as second parameter.
macro_rules! try_else_return {
    ($x:expr) => {
        try_else_return!($x, || {})
    };
    ($x:expr, $el:expr) => {
        match $x {
            Ok(x) => x,
            Err(e) => {
                crate::error::log_error(&e);
                let closure = $el;
                return closure();
            }
        }
    };
}

/// Print an error message to stdout. Format is the same as println! or format!
macro_rules! error {
    ($($arg:tt)*) => (
        println!("Criterion.rs ERROR: {}", &format!($($arg)*))
    )
}

/// Print a debug message to stdout. Format is the same as println! or format!
macro_rules! info {
    ($($arg:tt)*) => (
        if $crate::debug_enabled() {
            println!("Criterion.rs DEBUG: {}", &format!($($arg)*))
        }
    )
}

Ripgrep filtered Lines: [0, 33, 51]
File: criterion.rs/src/benchmark.rs
Start Line: 0
End Line: 32
Chunks:
use crate::{PlotConfiguration, SamplingMode};
use std::time::Duration;

// TODO: Move the benchmark config stuff to a separate module for easier use.

/// Struct containing all of the configuration options for a benchmark.
pub struct BenchmarkConfig {
    pub confidence_level: f64,
    pub measurement_time: Duration,
    pub noise_threshold: f64,
    pub nresamples: usize,
    pub sample_size: usize,
    pub significance_level: f64,
    pub warm_up_time: Duration,
    pub sampling_mode: SamplingMode,
    pub quick_mode: bool,
}

/// Struct representing a partially-complete per-benchmark configuration.
#[derive(Clone, Default)]
pub(crate) struct PartialBenchmarkConfig {
    pub(crate) confidence_level: Option<f64>,
    pub(crate) measurement_time: Option<Duration>,
    pub(crate) noise_threshold: Option<f64>,
    pub(crate) nresamples: Option<usize>,
    pub(crate) sample_size: Option<usize>,
    pub(crate) significance_level: Option<f64>,
    pub(crate) warm_up_time: Option<Duration>,
    pub(crate) sampling_mode: Option<SamplingMode>,
    pub(crate) quick_mode: Option<bool>,
    pub(crate) plot_config: PlotConfiguration,
}

File: criterion.rs/src/benchmark.rs
Start Line: 32
End Line: 50
Chunks:

impl PartialBenchmarkConfig {
    pub(crate) fn to_complete(&self, defaults: &BenchmarkConfig) -> BenchmarkConfig {
        BenchmarkConfig {
            confidence_level: self.confidence_level.unwrap_or(defaults.confidence_level),
            measurement_time: self.measurement_time.unwrap_or(defaults.measurement_time),
            noise_threshold: self.noise_threshold.unwrap_or(defaults.noise_threshold),
            nresamples: self.nresamples.unwrap_or(defaults.nresamples),
            sample_size: self.sample_size.unwrap_or(defaults.sample_size),
            significance_level: self
                .significance_level
                .unwrap_or(defaults.significance_level),
            warm_up_time: self.warm_up_time.unwrap_or(defaults.warm_up_time),
            sampling_mode: self.sampling_mode.unwrap_or(defaults.sampling_mode),
            quick_mode: self.quick_mode.unwrap_or(defaults.quick_mode),
        }
    }
}

Ripgrep filtered Lines: [0, 40, 65, 113, 156, 177, 223, 250, 277]
File: criterion.rs/src/stats/univariate/outliers/tukey.rs
Start Line: 0
End Line: 39
Chunks:
//! Tukey's method
//!
//! The original method uses two "fences" to classify the data. All the observations "inside" the
//! fences are considered "normal", and the rest are considered outliers.
//!
//! The fences are computed from the quartiles of the sample, according to the following formula:
//!
//! ``` ignore
//! // q1, q3 are the first and third quartiles
//! let iqr = q3 - q1;  // The interquartile range
//! let (f1, f2) = (q1 - 1.5 * iqr, q3 + 1.5 * iqr);  // the "fences"
//!
//! let is_outlier = |x| if x > f1 && x < f2 { true } else { false };
//! ```
//!
//! The classifier provided here adds two extra outer fences:
//!
//! ``` ignore
//! let (f3, f4) = (q1 - 3 * iqr, q3 + 3 * iqr);  // the outer "fences"
//! ```
//!
//! The extra fences add a sense of "severity" to the classification. Data points outside of the
//! outer fences are considered "severe" outliers, whereas points outside the inner fences are just
//! "mild" outliers, and, as the original method, everything inside the inner fences is considered
//! "normal" data.
//!
//! Some ASCII art for the visually oriented people:
//!
//! ``` ignore
//!          LOW-ish                NORMAL-ish                 HIGH-ish
//!         x   |       +    |  o o  o    o   o o  o  |        +   |   x
//!             f3           f1                       f2           f4
//!
//! Legend:
//! o: "normal" data (not an outlier)
//! +: "mild" outlier
//! x: "severe" outlier
//! ```


File: criterion.rs/src/stats/univariate/outliers/tukey.rs
Start Line: 39
End Line: 64
Chunks:
use std::iter::IntoIterator;
use std::ops::{Deref, Index};
use std::slice;

use crate::stats::float::Float;
use crate::stats::univariate::Sample;

use self::Label::*;

/// A classified/labeled sample.
///
/// The labeled data can be accessed using the indexing operator. The order of the data points is
/// retained.
///
/// NOTE: Due to limitations in the indexing traits, only the label is returned. Once the
/// `IndexGet` trait lands in stdlib, the indexing operation will return a `(data_point, label)`
/// pair.
#[derive(Clone, Copy)]
pub struct LabeledSample<'a, A>
where
    A: Float,
{
    fences: (A, A, A, A),
    sample: &'a Sample<A>,
}

File: criterion.rs/src/stats/univariate/outliers/tukey.rs
Start Line: 64
End Line: 112
Chunks:

impl<'a, A> LabeledSample<'a, A>
where
    A: Float,
{
    /// Returns the number of data points per label
    ///
    /// - Time: `O(length)`
    #[cfg_attr(feature = "cargo-clippy", allow(clippy::similar_names))]
    pub fn count(&self) -> (usize, usize, usize, usize, usize) {
        let (mut los, mut lom, mut noa, mut him, mut his) = (0, 0, 0, 0, 0);

        for (_, label) in self {
            match label {
                LowSevere => {
                    los += 1;
                }
                LowMild => {
                    lom += 1;
                }
                NotAnOutlier => {
                    noa += 1;
                }
                HighMild => {
                    him += 1;
                }
                HighSevere => {
                    his += 1;
                }
            }
        }

        (los, lom, noa, him, his)
    }

    /// Returns the fences used to classify the outliers
    pub fn fences(&self) -> (A, A, A, A) {
        self.fences
    }

    /// Returns an iterator over the labeled data
    pub fn iter(&self) -> Iter<'a, A> {
        Iter {
            fences: self.fences,
            iter: self.sample.iter(),
        }
    }
}

File: criterion.rs/src/stats/univariate/outliers/tukey.rs
Start Line: 112
End Line: 155
Chunks:

impl<'a, A> Deref for LabeledSample<'a, A>
where
    A: Float,
{
    type Target = Sample<A>;

    fn deref(&self) -> &Sample<A> {
        self.sample
    }
}

// FIXME Use the `IndexGet` trait
impl<'a, A> Index<usize> for LabeledSample<'a, A>
where
    A: Float,
{
    type Output = Label;

    #[cfg_attr(feature = "cargo-clippy", allow(clippy::similar_names))]
    fn index(&self, i: usize) -> &Label {
        static LOW_SEVERE: Label = LowSevere;
        static LOW_MILD: Label = LowMild;
        static HIGH_MILD: Label = HighMild;
        static HIGH_SEVERE: Label = HighSevere;
        static NOT_AN_OUTLIER: Label = NotAnOutlier;

        let x = self.sample[i];
        let (lost, lomt, himt, hist) = self.fences;

        if x < lost {
            &LOW_SEVERE
        } else if x > hist {
            &HIGH_SEVERE
        } else if x < lomt {
            &LOW_MILD
        } else if x > himt {
            &HIGH_MILD
        } else {
            &NOT_AN_OUTLIER
        }
    }
}

File: criterion.rs/src/stats/univariate/outliers/tukey.rs
Start Line: 155
End Line: 176
Chunks:

impl<'a, 'b, A> IntoIterator for &'b LabeledSample<'a, A>
where
    A: Float,
{
    type Item = (A, Label);
    type IntoIter = Iter<'a, A>;

    fn into_iter(self) -> Iter<'a, A> {
        self.iter()
    }
}

/// Iterator over the labeled data
pub struct Iter<'a, A>
where
    A: Float,
{
    fences: (A, A, A, A),
    iter: slice::Iter<'a, A>,
}

File: criterion.rs/src/stats/univariate/outliers/tukey.rs
Start Line: 176
End Line: 222
Chunks:

impl<'a, A> Iterator for Iter<'a, A>
where
    A: Float,
{
    type Item = (A, Label);

    #[cfg_attr(feature = "cargo-clippy", allow(clippy::similar_names))]
    fn next(&mut self) -> Option<(A, Label)> {
        self.iter.next().map(|&x| {
            let (lost, lomt, himt, hist) = self.fences;

            let label = if x < lost {
                LowSevere
            } else if x > hist {
                HighSevere
            } else if x < lomt {
                LowMild
            } else if x > himt {
                HighMild
            } else {
                NotAnOutlier
            };

            (x, label)
        })
    }

    fn size_hint(&self) -> (usize, Option<usize>) {
        self.iter.size_hint()
    }
}

/// Labels used to classify outliers
pub enum Label {
    /// A "mild" outlier in the "high" spectrum
    HighMild,
    /// A "severe" outlier in the "high" spectrum
    HighSevere,
    /// A "mild" outlier in the "low" spectrum
    LowMild,
    /// A "severe" outlier in the "low" spectrum
    LowSevere,
    /// A normal data point
    NotAnOutlier,
}

File: criterion.rs/src/stats/univariate/outliers/tukey.rs
Start Line: 222
End Line: 249
Chunks:

impl Label {
    /// Checks if the data point has an "unusually" high value
    pub fn is_high(&self) -> bool {
        matches!(*self, HighMild | HighSevere)
    }

    /// Checks if the data point is labeled as a "mild" outlier
    pub fn is_mild(&self) -> bool {
        matches!(*self, HighMild | LowMild)
    }

    /// Checks if the data point has an "unusually" low value
    pub fn is_low(&self) -> bool {
        matches!(*self, LowMild | LowSevere)
    }

    /// Checks if the data point is labeled as an outlier
    pub fn is_outlier(&self) -> bool {
        matches!(*self, NotAnOutlier)
    }

    /// Checks if the data point is labeled as a "severe" outlier
    pub fn is_severe(&self) -> bool {
        matches!(*self, HighSevere | LowSevere)
    }
}

File: criterion.rs/src/stats/univariate/outliers/tukey.rs
Start Line: 249
End Line: 276
Chunks:

/// Classifies the sample, and returns a labeled sample.
///
/// - Time: `O(N log N) where N = length`
pub fn classify<A>(sample: &Sample<A>) -> LabeledSample<'_, A>
where
    A: Float,
    usize: cast::From<A, Output = Result<usize, cast::Error>>,
{
    let (q1, _, q3) = sample.percentiles().quartiles();
    let iqr = q3 - q1;

    // Mild
    let k_m = A::cast(1.5_f32);
    // Severe
    let k_s = A::cast(3);

    LabeledSample {
        fences: (
            q1 - k_s * iqr,
            q1 - k_m * iqr,
            q3 + k_m * iqr,
            q3 + k_s * iqr,
        ),
        sample,
    }
}

Ripgrep filtered Lines: [50]
File: criterion.rs/src/stats/univariate/outliers/mod.rs
Start Line: 0
End Line: 7
Chunks:
//! Classification of outliers
//!
//! WARNING: There's no formal/mathematical definition of what an outlier actually is. Therefore,
//! all outlier classifiers are *subjective*, however some classifiers that have become *de facto*
//! standard are provided here.

pub mod tukey;

Ripgrep filtered Lines: [0, 42, 79]
File: criterion.rs/src/stats/univariate/mixed.rs
Start Line: 0
End Line: 41
Chunks:
//! Mixed bootstrap

use crate::stats::float::Float;
use crate::stats::tuple::{Tuple, TupledDistributionsBuilder};
use crate::stats::univariate::Resamples;
use crate::stats::univariate::Sample;
#[cfg(feature = "rayon")]
use rayon::prelude::*;

/// Performs a *mixed* two-sample bootstrap
pub fn bootstrap<A, T, S>(
    a: &Sample<A>,
    b: &Sample<A>,
    nresamples: usize,
    statistic: S,
) -> T::Distributions
where
    A: Float,
    S: Fn(&Sample<A>, &Sample<A>) -> T + Sync,
    T: Tuple + Send,
    T::Distributions: Send,
    T::Builder: Send,
{
    let n_a = a.len();
    let n_b = b.len();
    let mut c = Vec::with_capacity(n_a + n_b);
    c.extend_from_slice(a);
    c.extend_from_slice(b);
    let c = Sample::new(&c);

    #[cfg(feature = "rayon")]
    {
        (0..nresamples)
            .into_par_iter()
            .map_init(
                || Resamples::new(c),
                |resamples, _| {
                    let resample = resamples.next();
                    let a: &Sample<A> = Sample::new(&resample[..n_a]);
                    let b: &Sample<A> = Sample::new(&resample[n_a..]);


File: criterion.rs/src/stats/univariate/mixed.rs
Start Line: 41
End Line: 78
Chunks:
                    statistic(a, b)
                },
            )
            .fold(
                || T::Builder::new(0),
                |mut sub_distributions, sample| {
                    sub_distributions.push(sample);
                    sub_distributions
                },
            )
            .reduce(
                || T::Builder::new(0),
                |mut a, mut b| {
                    a.extend(&mut b);
                    a
                },
            )
            .complete()
    }
    #[cfg(not(feature = "rayon"))]
    {
        let mut resamples = Resamples::new(c);
        (0..nresamples)
            .map(|_| {
                let resample = resamples.next();
                let a: &Sample<A> = Sample::new(&resample[..n_a]);
                let b: &Sample<A> = Sample::new(&resample[n_a..]);

                statistic(a, b)
            })
            .fold(T::Builder::new(0), |mut sub_distributions, sample| {
                sub_distributions.push(sample);
                sub_distributions
            })
            .complete()
    }
}

Ripgrep filtered Lines: [0, 9, 57, 106, 155, 178]
File: criterion.rs/src/stats/univariate/bootstrap.rs
Start Line: 0
End Line: 8
Chunks:
#[cfg(test)]
macro_rules! test {
    ($ty:ident) => {
        mod $ty {
            use approx::relative_eq;
            use quickcheck::quickcheck;
            use quickcheck::TestResult;


File: criterion.rs/src/stats/univariate/bootstrap.rs
Start Line: 8
End Line: 56
Chunks:
            use crate::stats::univariate::{Sample, mixed, self};

            quickcheck!{
                fn mean(size: u8, start: u8, nresamples: u8) -> TestResult {
                    let size = size as usize;
                    let start = start as usize;
                    let nresamples = nresamples as usize;
                    if let Some(v) = crate::stats::test::vec::<$ty>(size, start) {
                        let sample = Sample::new(&v[start..]);

                        let means = if nresamples > 0 {
                            sample.bootstrap(nresamples, |s| (s.mean(),)).0
                        } else {
                            return TestResult::discard();
                        };

                        let min = sample.min();
                        let max = sample.max();

                        TestResult::from_bool(
                            // Computed the correct number of resamples
                            means.len() == nresamples &&
                            // No uninitialized values
                            means.iter().all(|&x| {
                                (x > min || relative_eq!(x, min)) &&
                                (x < max || relative_eq!(x, max))
                            })
                        )
                    } else {
                        TestResult::discard()
                    }
                }
            }

            quickcheck!{
                fn mean_median(size: u8, start: u8, nresamples: u8) -> TestResult {
                    let size = size as usize;
                    let start = start as usize;
                    let nresamples = nresamples as usize;
                    if let Some(v) = crate::stats::test::vec::<$ty>(size, start) {
                        let sample = Sample::new(&v[start..]);

                        let (means, medians) = if nresamples > 0 {
                            sample.bootstrap(nresamples, |s| (s.mean(), s.median()))
                        } else {
                            return TestResult::discard();
                        };


File: criterion.rs/src/stats/univariate/bootstrap.rs
Start Line: 56
End Line: 105
Chunks:
                        let min = sample.min();
                        let max = sample.max();

                        TestResult::from_bool(
                            // Computed the correct number of resamples
                            means.len() == nresamples &&
                            medians.len() == nresamples &&
                            // No uninitialized values
                            means.iter().all(|&x| {
                                (x > min || relative_eq!(x, min)) &&
                                (x < max || relative_eq!(x, max))
                            }) &&
                            medians.iter().all(|&x| {
                                (x > min || relative_eq!(x, min)) &&
                                (x < max || relative_eq!(x, max))
                            })
                        )
                    } else {
                        TestResult::discard()
                    }
                }
            }

            quickcheck!{
                fn mixed_two_sample(
                    a_size: u8, a_start: u8,
                    b_size: u8, b_start: u8,
                    nresamples: u8
                ) -> TestResult {
                    let a_size = a_size as usize;
                    let b_size = b_size as usize;
                    let a_start = a_start as usize;
                    let b_start = b_start as usize;
                    let nresamples = nresamples as usize;
                    if let (Some(a), Some(b)) =
                        (crate::stats::test::vec::<$ty>(a_size, a_start), crate::stats::test::vec::<$ty>(b_size, b_start))
                    {
                        let a = Sample::new(&a);
                        let b = Sample::new(&b);

                        let distribution = if nresamples > 0 {
                            mixed::bootstrap(a, b, nresamples, |a, b| (a.mean() - b.mean(),)).0
                        } else {
                            return TestResult::discard();
                        };

                        let min = <$ty>::min(a.min() - b.max(), b.min() - a.max());
                        let max = <$ty>::max(a.max() - b.min(), b.max() - a.min());


File: criterion.rs/src/stats/univariate/bootstrap.rs
Start Line: 105
End Line: 154
Chunks:
                        TestResult::from_bool(
                            // Computed the correct number of resamples
                            distribution.len() == nresamples &&
                            // No uninitialized values
                            distribution.iter().all(|&x| {
                                (x > min || relative_eq!(x, min)) &&
                                (x < max || relative_eq!(x, max))
                            })
                        )
                    } else {
                        TestResult::discard()
                    }
                }
            }

            quickcheck!{
                fn two_sample(
                    a_size: u8, a_start: u8,
                    b_size: u8, b_start: u8,
                    nresamples: u8
                ) -> TestResult {
                    let a_size = a_size as usize;
                    let b_size = b_size as usize;
                    let a_start = a_start as usize;
                    let b_start = b_start as usize;
                    let nresamples = nresamples as usize;
                    if let (Some(a), Some(b)) =
                        (crate::stats::test::vec::<$ty>(a_size, a_start), crate::stats::test::vec::<$ty>(b_size, b_start))
                    {
                        let a = Sample::new(&a[a_start..]);
                        let b = Sample::new(&b[b_start..]);

                        let distribution = if nresamples > 0 {
                            univariate::bootstrap(a, b, nresamples, |a, b| (a.mean() - b.mean(),)).0
                        } else {
                            return TestResult::discard();
                        };

                        let min = <$ty>::min(a.min() - b.max(), b.min() - a.max());
                        let max = <$ty>::max(a.max() - b.min(), b.max() - a.min());

                        // Computed the correct number of resamples
                        let pass = distribution.len() == nresamples &&
                            // No uninitialized values
                            distribution.iter().all(|&x| {
                                (x > min || relative_eq!(x, min)) &&
                                (x < max || relative_eq!(x, max))
                            });


File: criterion.rs/src/stats/univariate/bootstrap.rs
Start Line: 154
End Line: 177
Chunks:
                        if !pass {
                            println!("A: {:?} (len={})", a.as_ref(), a.len());
                            println!("B: {:?} (len={})", b.as_ref(), b.len());
                            println!("Dist: {:?} (len={})", distribution.as_ref(), distribution.len());
                            println!("Min: {}, Max: {}, nresamples: {}",
                                min, max, nresamples);
                        }

                        TestResult::from_bool(pass)
                    } else {
                        TestResult::discard()
                    }
                }
            }
        }
    }
}

#[cfg(test)]
mod test {
    test!(f32);
    test!(f64);
}

Ripgrep filtered Lines: [0, 15, 61, 96, 120]
File: criterion.rs/src/stats/univariate/resamples.rs
Start Line: 0
End Line: 14
Chunks:
use std::mem;

use crate::stats::float::Float;
use crate::stats::rand_util::{new_rng, Rng};
use crate::stats::univariate::Sample;

pub struct Resamples<'a, A>
where
    A: Float,
{
    rng: Rng,
    sample: &'a [A],
    stage: Option<Vec<A>>,
}

File: criterion.rs/src/stats/univariate/resamples.rs
Start Line: 14
End Line: 60
Chunks:

#[cfg_attr(feature = "cargo-clippy", allow(clippy::should_implement_trait))]
impl<'a, A> Resamples<'a, A>
where
    A: 'a + Float,
{
    pub fn new(sample: &'a Sample<A>) -> Resamples<'a, A> {
        let slice = sample;

        Resamples {
            rng: new_rng(),
            sample: slice,
            stage: None,
        }
    }

    pub fn next(&mut self) -> &Sample<A> {
        let n = self.sample.len();
        let rng = &mut self.rng;

        match self.stage {
            None => {
                let mut stage = Vec::with_capacity(n);

                for _ in 0..n {
                    let idx = rng.rand_range(0u64..(self.sample.len() as u64));
                    stage.push(self.sample[idx as usize])
                }

                self.stage = Some(stage);
            }
            Some(ref mut stage) => {
                for elem in stage.iter_mut() {
                    let idx = rng.rand_range(0u64..(self.sample.len() as u64));
                    *elem = self.sample[idx as usize]
                }
            }
        }

        if let Some(ref v) = self.stage {
            unsafe { mem::transmute::<&[_], _>(v) }
        } else {
            unreachable!();
        }
    }
}

File: criterion.rs/src/stats/univariate/resamples.rs
Start Line: 60
End Line: 95
Chunks:

#[cfg(test)]
mod test {
    use quickcheck::quickcheck;
    use quickcheck::TestResult;
    use std::collections::HashSet;

    use crate::stats::univariate::resamples::Resamples;
    use crate::stats::univariate::Sample;

    // Check that the resample is a subset of the sample
    quickcheck! {
        fn subset(size: u8, nresamples: u8) -> TestResult {
            let size = size as usize;
            let nresamples = nresamples as usize;
            if size > 1 {
                let v: Vec<_> = (0..size).map(|i| i as f32).collect();
                let sample = Sample::new(&v);
                let mut resamples = Resamples::new(sample);
                let sample = v.iter().map(|&x| x as i64).collect::<HashSet<_>>();

                TestResult::from_bool((0..nresamples).all(|_| {
                    let resample = resamples.next()

                        .iter()
                        .map(|&x| x as i64)
                        .collect::<HashSet<_>>();

                    resample.is_subset(&sample)
                }))
            } else {
                TestResult::discard()
            }
        }
    }

File: criterion.rs/src/stats/univariate/resamples.rs
Start Line: 95
End Line: 119
Chunks:

    #[test]
    fn different_subsets() {
        let size = 1000;
        let v: Vec<_> = (0..size).map(|i| i as f32).collect();
        let sample = Sample::new(&v);
        let mut resamples = Resamples::new(sample);

        // Hypothetically, we might see one duplicate, but more than one is likely to be a bug.
        let mut num_duplicated = 0;
        for _ in 0..1000 {
            let sample_1 = resamples.next().iter().cloned().collect::<Vec<_>>();
            let sample_2 = resamples.next().iter().cloned().collect::<Vec<_>>();

            if sample_1 == sample_2 {
                num_duplicated += 1;
            }
        }

        if num_duplicated > 1 {
            panic!("Found {} duplicate samples", num_duplicated);
        }
    }
}

Ripgrep filtered Lines: [0, 39, 77]
File: criterion.rs/src/stats/univariate/percentiles.rs
Start Line: 0
End Line: 38
Chunks:
use crate::stats::float::Float;
use cast::{self, usize};

/// A "view" into the percentiles of a sample
pub struct Percentiles<A>(Box<[A]>)
where
    A: Float;

// TODO(rust-lang/rfcs#735) move this `impl` into a private percentiles module
impl<A> Percentiles<A>
where
    A: Float,
    usize: cast::From<A, Output = Result<usize, cast::Error>>,
{
    /// Returns the percentile at `p`%
    ///
    /// Safety:
    ///
    /// - Make sure that `p` is in the range `[0, 100]`
    unsafe fn at_unchecked(&self, p: A) -> A {
        let _100 = A::cast(100);
        debug_assert!(p >= A::cast(0) && p <= _100);
        debug_assert!(self.0.len() > 0);
        let len = self.0.len() - 1;

        if p == _100 {
            self.0[len]
        } else {
            let rank = (p / _100) * A::cast(len);
            let integer = rank.floor();
            let fraction = rank - integer;
            let n = usize(integer).unwrap();
            let &floor = self.0.get_unchecked(n);
            let &ceiling = self.0.get_unchecked(n + 1);

            floor + (ceiling - floor) * fraction
        }
    }

File: criterion.rs/src/stats/univariate/percentiles.rs
Start Line: 38
End Line: 76
Chunks:

    /// Returns the percentile at `p`%
    ///
    /// # Panics
    ///
    /// Panics if `p` is outside the closed `[0, 100]` range
    pub fn at(&self, p: A) -> A {
        let _0 = A::cast(0);
        let _100 = A::cast(100);

        assert!(p >= _0 && p <= _100);
        assert!(self.0.len() > 0);

        unsafe { self.at_unchecked(p) }
    }

    /// Returns the interquartile range
    pub fn iqr(&self) -> A {
        let q1 = self.at(A::cast(25));
        let q3 = self.at(A::cast(75));

        q3 - q1
    }

    /// Returns the 50th percentile
    pub fn median(&self) -> A {
        self.at(A::cast(50))
    }

    /// Returns the 25th, 50th and 75th percentiles
    pub fn quartiles(&self) -> (A, A, A) {
        (
            self.at(A::cast(25)),
            self.at(A::cast(50)),
            self.at(A::cast(75)),
        )
    }
}

Ripgrep filtered Lines: [0, 35, 78, 106, 149, 181, 200, 250, 275]
File: criterion.rs/src/stats/univariate/sample.rs
Start Line: 0
End Line: 34
Chunks:
use std::{mem, ops};

use crate::stats::float::Float;
use crate::stats::tuple::{Tuple, TupledDistributionsBuilder};
use crate::stats::univariate::Percentiles;
use crate::stats::univariate::Resamples;
#[cfg(feature = "rayon")]
use rayon::prelude::*;

/// A collection of data points drawn from a population
///
/// Invariants:
///
/// - The sample contains at least 2 data points
/// - The sample contains no `NaN`s
#[repr(transparent)]
pub struct Sample<A>([A]);

// TODO(rust-lang/rfcs#735) move this `impl` into a private percentiles module
impl<A> Sample<A>
where
    A: Float,
{
    /// Creates a new sample from an existing slice
    ///
    /// # Panics
    ///
    /// Panics if `slice` contains any `NaN` or if `slice` has less than two elements
    #[cfg_attr(feature = "cargo-clippy", allow(clippy::new_ret_no_self))]
    pub fn new(slice: &[A]) -> &Sample<A> {
        assert!(slice.len() > 1 && slice.iter().all(|x| !x.is_nan()));

        unsafe { mem::transmute(slice) }
    }

File: criterion.rs/src/stats/univariate/sample.rs
Start Line: 34
End Line: 77
Chunks:

    /// Returns the biggest element in the sample
    ///
    /// - Time: `O(length)`
    pub fn max(&self) -> A {
        let mut elems = self.iter();

        match elems.next() {
            Some(&head) => elems.fold(head, |a, &b| a.max(b)),
            // NB `unreachable!` because `Sample` is guaranteed to have at least one data point
            None => unreachable!(),
        }
    }

    /// Returns the arithmetic average of the sample
    ///
    /// - Time: `O(length)`
    pub fn mean(&self) -> A {
        let n = self.len();

        self.sum() / A::cast(n)
    }

    /// Returns the median absolute deviation
    ///
    /// The `median` can be optionally passed along to speed up (2X) the computation
    ///
    /// - Time: `O(length)`
    /// - Memory: `O(length)`
    pub fn median_abs_dev(&self, median: Option<A>) -> A
    where
        usize: cast::From<A, Output = Result<usize, cast::Error>>,
    {
        let median = median.unwrap_or_else(|| self.percentiles().median());

        // NB Although this operation can be SIMD accelerated, the gain is negligible because the
        // bottle neck is the sorting operation which is part of the computation of the median
        let abs_devs = self.iter().map(|&x| (x - median).abs()).collect::<Vec<_>>();

        let abs_devs: &Self = Self::new(&abs_devs);

        abs_devs.percentiles().median() * A::cast(1.4826)
    }

File: criterion.rs/src/stats/univariate/sample.rs
Start Line: 77
End Line: 105
Chunks:

    /// Returns the median absolute deviation as a percentage of the median
    ///
    /// - Time: `O(length)`
    /// - Memory: `O(length)`
    pub fn median_abs_dev_pct(&self) -> A
    where
        usize: cast::From<A, Output = Result<usize, cast::Error>>,
    {
        let _100 = A::cast(100);
        let median = self.percentiles().median();
        let mad = self.median_abs_dev(Some(median));

        (mad / median) * _100
    }

    /// Returns the smallest element in the sample
    ///
    /// - Time: `O(length)`
    pub fn min(&self) -> A {
        let mut elems = self.iter();

        match elems.next() {
            Some(&elem) => elems.fold(elem, |a, &b| a.min(b)),
            // NB `unreachable!` because `Sample` is guaranteed to have at least one data point
            None => unreachable!(),
        }
    }

File: criterion.rs/src/stats/univariate/sample.rs
Start Line: 105
End Line: 148
Chunks:

    /// Returns a "view" into the percentiles of the sample
    ///
    /// This "view" makes consecutive computations of percentiles much faster (`O(1)`)
    ///
    /// - Time: `O(N log N) where N = length`
    /// - Memory: `O(length)`
    pub fn percentiles(&self) -> Percentiles<A>
    where
        usize: cast::From<A, Output = Result<usize, cast::Error>>,
    {
        use std::cmp::Ordering;

        // NB This function assumes that there are no `NaN`s in the sample
        fn cmp<T>(a: &T, b: &T) -> Ordering
        where
            T: PartialOrd,
        {
            match a.partial_cmp(b) {
                Some(o) => o,
                // Arbitrary way to handle NaNs that should never happen
                None => Ordering::Equal,
            }
        }

        let mut v = self.to_vec().into_boxed_slice();
        #[cfg(feature = "rayon")]
        v.par_sort_unstable_by(cmp);
        #[cfg(not(feature = "rayon"))]
        v.sort_unstable_by(cmp);

        // NB :-1: to intra-crate privacy rules
        unsafe { mem::transmute(v) }
    }

    /// Returns the standard deviation of the sample
    ///
    /// The `mean` can be optionally passed along to speed up (2X) the computation
    ///
    /// - Time: `O(length)`
    pub fn std_dev(&self, mean: Option<A>) -> A {
        self.var(mean).sqrt()
    }

File: criterion.rs/src/stats/univariate/sample.rs
Start Line: 148
End Line: 180
Chunks:

    /// Returns the standard deviation as a percentage of the mean
    ///
    /// - Time: `O(length)`
    pub fn std_dev_pct(&self) -> A {
        let _100 = A::cast(100);
        let mean = self.mean();
        let std_dev = self.std_dev(Some(mean));

        (std_dev / mean) * _100
    }

    /// Returns the sum of all the elements of the sample
    ///
    /// - Time: `O(length)`
    pub fn sum(&self) -> A {
        crate::stats::sum(self)
    }

    /// Returns the t score between these two samples
    ///
    /// - Time: `O(length)`
    pub fn t(&self, other: &Sample<A>) -> A {
        let (x_bar, y_bar) = (self.mean(), other.mean());
        let (s2_x, s2_y) = (self.var(Some(x_bar)), other.var(Some(y_bar)));
        let n_x = A::cast(self.len());
        let n_y = A::cast(other.len());
        let num = x_bar - y_bar;
        let den = (s2_x / n_x + s2_y / n_y).sqrt();

        num / den
    }

File: criterion.rs/src/stats/univariate/sample.rs
Start Line: 180
End Line: 199
Chunks:

    /// Returns the variance of the sample
    ///
    /// The `mean` can be optionally passed along to speed up (2X) the computation
    ///
    /// - Time: `O(length)`
    pub fn var(&self, mean: Option<A>) -> A {
        use std::ops::Add;

        let mean = mean.unwrap_or_else(|| self.mean());
        let slice = self;

        let sum = slice
            .iter()
            .map(|&x| (x - mean).powi(2))
            .fold(A::cast(0), Add::add);

        sum / A::cast(slice.len() - 1)
    }

File: criterion.rs/src/stats/univariate/sample.rs
Start Line: 199
End Line: 249
Chunks:

    // TODO Remove the `T` parameter in favor of `S::Output`
    /// Returns the bootstrap distributions of the parameters estimated by the 1-sample statistic
    ///
    /// - Multi-threaded
    /// - Time: `O(nresamples)`
    /// - Memory: `O(nresamples)`
    pub fn bootstrap<T, S>(&self, nresamples: usize, statistic: S) -> T::Distributions
    where
        S: Fn(&Sample<A>) -> T + Sync,
        T: Tuple + Send,
        T::Distributions: Send,
        T::Builder: Send,
    {
        #[cfg(feature = "rayon")]
        {
            (0..nresamples)
                .into_par_iter()
                .map_init(
                    || Resamples::new(self),
                    |resamples, _| statistic(resamples.next()),
                )
                .fold(
                    || T::Builder::new(0),
                    |mut sub_distributions, sample| {
                        sub_distributions.push(sample);
                        sub_distributions
                    },
                )
                .reduce(
                    || T::Builder::new(0),
                    |mut a, mut b| {
                        a.extend(&mut b);
                        a
                    },
                )
                .complete()
        }
        #[cfg(not(feature = "rayon"))]
        {
            let mut resamples = Resamples::new(self);
            (0..nresamples)
                .map(|_| statistic(resamples.next()))
                .fold(T::Builder::new(0), |mut sub_distributions, sample| {
                    sub_distributions.push(sample);
                    sub_distributions
                })
                .complete()
        }
    }

File: criterion.rs/src/stats/univariate/sample.rs
Start Line: 249
End Line: 274
Chunks:

    #[cfg(test)]
    pub fn iqr(&self) -> A
    where
        usize: cast::From<A, Output = Result<usize, cast::Error>>,
    {
        self.percentiles().iqr()
    }

    #[cfg(test)]
    pub fn median(&self) -> A
    where
        usize: cast::From<A, Output = Result<usize, cast::Error>>,
    {
        self.percentiles().median()
    }
}

impl<A> ops::Deref for Sample<A> {
    type Target = [A];

    fn deref(&self) -> &[A] {
        &self.0
    }
}

Ripgrep filtered Lines: [0, 28, 77, 85]
File: criterion.rs/src/stats/univariate/kde/kernel.rs
Start Line: 0
End Line: 27
Chunks:
//! Kernels

use crate::stats::float::Float;

/// Kernel function
pub trait Kernel<A>: Copy + Sync
where
    A: Float,
{
    /// Apply the kernel function to the given x-value.
    fn evaluate(&self, x: A) -> A;
}

/// Gaussian kernel
#[derive(Clone, Copy)]
pub struct Gaussian;

impl<A> Kernel<A> for Gaussian
where
    A: Float,
{
    fn evaluate(&self, x: A) -> A {
        use std::f32::consts::PI;

        (x.powi(2).exp() * A::cast(2. * PI)).sqrt().recip()
    }
}

File: criterion.rs/src/stats/univariate/kde/kernel.rs
Start Line: 27
End Line: 76
Chunks:

#[cfg(test)]
macro_rules! test {
    ($ty:ident) => {
        mod $ty {
            mod gaussian {
                use approx::relative_eq;
                use quickcheck::quickcheck;
                use quickcheck::TestResult;

                use crate::stats::univariate::kde::kernel::{Gaussian, Kernel};

                quickcheck! {
                    fn symmetric(x: $ty) -> bool {
                        x.is_nan() || relative_eq!(Gaussian.evaluate(-x), Gaussian.evaluate(x))
                    }
                }

                // Any [a b] integral should be in the range [0 1]
                quickcheck! {
                    fn integral(a: $ty, b: $ty) -> TestResult {
                        let a = a.sin().abs(); // map the value to [0 1]
                        let b = b.sin().abs(); // map the value to [0 1]
                        const DX: $ty = 1e-3;

                        if a > b {
                            TestResult::discard()
                        } else {
                            let mut acc = 0.;
                            let mut x = a;
                            let mut y = Gaussian.evaluate(a);

                            while x < b {
                                acc += DX * y / 2.;

                                x += DX;
                                y = Gaussian.evaluate(x);

                                acc += DX * y / 2.;
                            }

                            TestResult::from_bool(
                                (acc > 0. || relative_eq!(acc, 0.)) &&
                                (acc < 1. || relative_eq!(acc, 1.)))
                        }
                    }
                }
            }
        }

File: criterion.rs/src/stats/univariate/kde/kernel.rs
Start Line: 76
End Line: 84
Chunks:
    };
}

#[cfg(test)]
mod test {
    test!(f32);
    test!(f64);
}

Ripgrep filtered Lines: [0, 21, 71, 92, 141, 149]
File: criterion.rs/src/stats/univariate/kde/mod.rs
Start Line: 0
End Line: 20
Chunks:
//! Kernel density estimation

pub mod kernel;

use self::kernel::Kernel;
use crate::stats::float::Float;
use crate::stats::univariate::Sample;
#[cfg(feature = "rayon")]
use rayon::prelude::*;

/// Univariate kernel density estimator
pub struct Kde<'a, A, K>
where
    A: Float,
    K: Kernel<A>,
{
    bandwidth: A,
    kernel: K,
    sample: &'a Sample<A>,
}

File: criterion.rs/src/stats/univariate/kde/mod.rs
Start Line: 20
End Line: 70
Chunks:

impl<'a, A, K> Kde<'a, A, K>
where
    A: 'a + Float,
    K: Kernel<A>,
{
    /// Creates a new kernel density estimator from the `sample`, using a kernel and estimating
    /// the bandwidth using the method `bw`
    pub fn new(sample: &'a Sample<A>, kernel: K, bw: Bandwidth) -> Kde<'a, A, K> {
        Kde {
            bandwidth: bw.estimate(sample),
            kernel,
            sample,
        }
    }

    /// Returns the bandwidth used by the estimator
    pub fn bandwidth(&self) -> A {
        self.bandwidth
    }

    /// Maps the KDE over `xs`
    ///
    /// - Multihreaded
    pub fn map(&self, xs: &[A]) -> Box<[A]> {
        #[cfg(feature = "rayon")]
        let iter = xs.par_iter();

        #[cfg(not(feature = "rayon"))]
        let iter = xs.iter();

        iter.map(|&x| self.estimate(x))
            .collect::<Vec<_>>()
            .into_boxed_slice()
    }

    /// Estimates the probability density of `x`
    pub fn estimate(&self, x: A) -> A {
        let _0 = A::cast(0);
        let slice = self.sample;
        let h = self.bandwidth;
        let n = A::cast(slice.len());

        let sum = slice
            .iter()
            .fold(_0, |acc, &x_i| acc + self.kernel.evaluate((x - x_i) / h));

        sum / (h * n)
    }
}

File: criterion.rs/src/stats/univariate/kde/mod.rs
Start Line: 70
End Line: 91
Chunks:

/// Method to estimate the bandwidth
pub enum Bandwidth {
    /// Use Silverman's rule of thumb to estimate the bandwidth from the sample
    Silverman,
}

impl Bandwidth {
    fn estimate<A: Float>(self, sample: &Sample<A>) -> A {
        match self {
            Bandwidth::Silverman => {
                let factor = A::cast(4. / 3.);
                let exponent = A::cast(1. / 5.);
                let n = A::cast(sample.len());
                let sigma = sample.std_dev(None);

                sigma * (factor / n).powf(exponent)
            }
        }
    }
}

File: criterion.rs/src/stats/univariate/kde/mod.rs
Start Line: 91
End Line: 140
Chunks:

#[cfg(test)]
macro_rules! test {
    ($ty:ident) => {
        mod $ty {
            use approx::relative_eq;
            use quickcheck::quickcheck;
            use quickcheck::TestResult;

            use crate::stats::univariate::kde::kernel::Gaussian;
            use crate::stats::univariate::kde::{Bandwidth, Kde};
            use crate::stats::univariate::Sample;

            // The [-inf inf] integral of the estimated PDF should be one
            quickcheck! {
                fn integral(size: u8, start: u8) -> TestResult {
                    let size = size as usize;
                    let start = start as usize;
                    const DX: $ty = 1e-3;

                    if let Some(v) = crate::stats::test::vec::<$ty>(size, start) {
                        let slice = &v[start..];
                        let data = Sample::new(slice);
                        let kde = Kde::new(data, Gaussian, Bandwidth::Silverman);
                        let h = kde.bandwidth();
                        // NB Obviously a [-inf inf] integral is not feasible, but this range works
                        // quite well
                        let (a, b) = (data.min() - 5. * h, data.max() + 5. * h);

                        let mut acc = 0.;
                        let mut x = a;
                        let mut y = kde.estimate(a);

                        while x < b {
                            acc += DX * y / 2.;

                            x += DX;
                            y = kde.estimate(x);

                            acc += DX * y / 2.;
                        }

                        TestResult::from_bool(relative_eq!(acc, 1., epsilon = 2e-5))
                    } else {
                        TestResult::discard()
                    }
                }
            }
        }

File: criterion.rs/src/stats/univariate/kde/mod.rs
Start Line: 140
End Line: 148
Chunks:
    };
}

#[cfg(test)]
mod test {
    test!(f32);
    test!(f64);
}

Ripgrep filtered Lines: [0, 46, 76, 102]
File: criterion.rs/src/stats/univariate/mod.rs
Start Line: 0
End Line: 45
Chunks:
//! Univariate analysis

mod bootstrap;
mod percentiles;
mod resamples;
mod sample;

pub mod kde;
pub mod mixed;
pub mod outliers;

use crate::stats::float::Float;
use crate::stats::tuple::{Tuple, TupledDistributionsBuilder};
#[cfg(feature = "rayon")]
use rayon::prelude::*;
use std::cmp;

use self::resamples::Resamples;

pub use self::percentiles::Percentiles;
pub use self::sample::Sample;

/// Performs a two-sample bootstrap
///
/// - Multithreaded
/// - Time: `O(nresamples)`
/// - Memory: `O(nresamples)`
#[cfg_attr(feature = "cargo-clippy", allow(clippy::cast_lossless))]
pub fn bootstrap<A, B, T, S>(
    a: &Sample<A>,
    b: &Sample<B>,
    nresamples: usize,
    statistic: S,
) -> T::Distributions
where
    A: Float,
    B: Float,
    S: Fn(&Sample<A>, &Sample<B>) -> T + Sync,
    T: Tuple + Send,
    T::Distributions: Send,
    T::Builder: Send,
{
    let nresamples_sqrt = (nresamples as f64).sqrt().ceil() as usize;
    let per_chunk = (nresamples + nresamples_sqrt - 1) / nresamples_sqrt;


File: criterion.rs/src/stats/univariate/mod.rs
Start Line: 45
End Line: 75
Chunks:
    #[cfg(feature = "rayon")]
    {
        (0..nresamples_sqrt)
            .into_par_iter()
            .map_init(
                || (Resamples::new(a), Resamples::new(b)),
                |(a_resamples, b_resamples), i| {
                    let start = i * per_chunk;
                    let end = cmp::min((i + 1) * per_chunk, nresamples);
                    let a_resample = a_resamples.next();

                    let mut sub_distributions: T::Builder =
                        TupledDistributionsBuilder::new(end - start);

                    for _ in start..end {
                        let b_resample = b_resamples.next();
                        sub_distributions.push(statistic(a_resample, b_resample));
                    }
                    sub_distributions
                },
            )
            .reduce(
                || T::Builder::new(0),
                |mut a, mut b| {
                    a.extend(&mut b);
                    a
                },
            )
            .complete()
    }

File: criterion.rs/src/stats/univariate/mod.rs
Start Line: 75
End Line: 101
Chunks:
    #[cfg(not(feature = "rayon"))]
    {
        let mut a_resamples = Resamples::new(a);
        let mut b_resamples = Resamples::new(b);
        (0..nresamples_sqrt)
            .map(|i| {
                let start = i * per_chunk;
                let end = cmp::min((i + 1) * per_chunk, nresamples);
                let a_resample = a_resamples.next();

                let mut sub_distributions: T::Builder =
                    TupledDistributionsBuilder::new(end - start);

                for _ in start..end {
                    let b_resample = b_resamples.next();
                    sub_distributions.push(statistic(a_resample, b_resample));
                }
                sub_distributions
            })
            .fold(T::Builder::new(0), |mut a, mut b| {
                a.extend(&mut b);
                a
            })
            .complete()
    }
}

Ripgrep filtered Lines: [0, 13]
File: criterion.rs/src/stats/float.rs
Start Line: 0
End Line: 12
Chunks:
//! Float trait

use cast::From;
use num_traits::float;

/// This is an extension of `num_traits::float::Float` that adds safe
/// casting and Sync + Send. Once `num_traits` has these features this
/// can be removed.
pub trait Float:
    float::Float + From<usize, Output = Self> + From<f32, Output = Self> + Sync + Send
{
}

Ripgrep filtered Lines: [0, 22]
File: criterion.rs/src/stats/rand_util.rs
Start Line: 0
End Line: 21
Chunks:
use oorandom::Rand64;
use std::cell::RefCell;
use std::time::{SystemTime, UNIX_EPOCH};

pub type Rng = Rand64;

thread_local! {
    static SEED_RAND: RefCell<Rand64> = RefCell::new(Rand64::new(
        SystemTime::now().duration_since(UNIX_EPOCH)
            .expect("Time went backwards")
            .as_millis()
    ));
}

pub fn new_rng() -> Rng {
    SEED_RAND.with(|r| {
        let mut r = r.borrow_mut();
        let seed = ((r.rand_u64() as u128) << 64) | (r.rand_u64() as u128);
        Rand64::new(seed)
    })
}

Ripgrep filtered Lines: [0, 45, 91, 138, 174, 206, 254]
File: criterion.rs/src/stats/tuple.rs
Start Line: 0
End Line: 44
Chunks:
//! Helper traits for tupling/untupling

use crate::stats::Distribution;

/// Any tuple: `(A, B, ..)`
pub trait Tuple: Sized {
    /// A tuple of distributions associated with this tuple
    type Distributions: TupledDistributions<Item = Self>;

    /// A tuple of vectors associated with this tuple
    type Builder: TupledDistributionsBuilder<Item = Self>;
}

/// A tuple of distributions: `(Distribution<A>, Distribution<B>, ..)`
pub trait TupledDistributions: Sized {
    /// A tuple that can be pushed/inserted into the tupled distributions
    type Item: Tuple<Distributions = Self>;
}

/// A tuple of vecs used to build distributions.
pub trait TupledDistributionsBuilder: Sized {
    /// A tuple that can be pushed/inserted into the tupled distributions
    type Item: Tuple<Builder = Self>;

    /// Creates a new tuple of vecs
    fn new(size: usize) -> Self;

    /// Push one element into each of the vecs
    fn push(&mut self, tuple: Self::Item);

    /// Append one tuple of vecs to this one, leaving the vecs in the other tuple empty
    fn extend(&mut self, other: &mut Self);

    /// Convert the tuple of vectors into a tuple of distributions
    fn complete(self) -> <Self::Item as Tuple>::Distributions;
}

impl<A> Tuple for (A,)
where
    A: Copy,
{
    type Distributions = (Distribution<A>,);
    type Builder = (Vec<A>,);
}

File: criterion.rs/src/stats/tuple.rs
Start Line: 44
End Line: 90
Chunks:

impl<A> TupledDistributions for (Distribution<A>,)
where
    A: Copy,
{
    type Item = (A,);
}
impl<A> TupledDistributionsBuilder for (Vec<A>,)
where
    A: Copy,
{
    type Item = (A,);

    fn new(size: usize) -> (Vec<A>,) {
        (Vec::with_capacity(size),)
    }

    fn push(&mut self, tuple: (A,)) {
        (self.0).push(tuple.0);
    }

    fn extend(&mut self, other: &mut (Vec<A>,)) {
        (self.0).append(&mut other.0);
    }

    fn complete(self) -> (Distribution<A>,) {
        (Distribution(self.0.into_boxed_slice()),)
    }
}

impl<A, B> Tuple for (A, B)
where
    A: Copy,
    B: Copy,
{
    type Distributions = (Distribution<A>, Distribution<B>);
    type Builder = (Vec<A>, Vec<B>);
}

impl<A, B> TupledDistributions for (Distribution<A>, Distribution<B>)
where
    A: Copy,
    B: Copy,
{
    type Item = (A, B);
}

File: criterion.rs/src/stats/tuple.rs
Start Line: 90
End Line: 137
Chunks:
impl<A, B> TupledDistributionsBuilder for (Vec<A>, Vec<B>)
where
    A: Copy,
    B: Copy,
{
    type Item = (A, B);

    fn new(size: usize) -> (Vec<A>, Vec<B>) {
        (Vec::with_capacity(size), Vec::with_capacity(size))
    }

    fn push(&mut self, tuple: (A, B)) {
        (self.0).push(tuple.0);
        (self.1).push(tuple.1);
    }

    fn extend(&mut self, other: &mut (Vec<A>, Vec<B>)) {
        (self.0).append(&mut other.0);
        (self.1).append(&mut other.1);
    }

    fn complete(self) -> (Distribution<A>, Distribution<B>) {
        (
            Distribution(self.0.into_boxed_slice()),
            Distribution(self.1.into_boxed_slice()),
        )
    }
}

impl<A, B, C> Tuple for (A, B, C)
where
    A: Copy,
    B: Copy,
    C: Copy,
{
    type Distributions = (Distribution<A>, Distribution<B>, Distribution<C>);
    type Builder = (Vec<A>, Vec<B>, Vec<C>);
}

impl<A, B, C> TupledDistributions for (Distribution<A>, Distribution<B>, Distribution<C>)
where
    A: Copy,
    B: Copy,
    C: Copy,
{
    type Item = (A, B, C);
}

File: criterion.rs/src/stats/tuple.rs
Start Line: 137
End Line: 173
Chunks:
impl<A, B, C> TupledDistributionsBuilder for (Vec<A>, Vec<B>, Vec<C>)
where
    A: Copy,
    B: Copy,
    C: Copy,
{
    type Item = (A, B, C);

    fn new(size: usize) -> (Vec<A>, Vec<B>, Vec<C>) {
        (
            Vec::with_capacity(size),
            Vec::with_capacity(size),
            Vec::with_capacity(size),
        )
    }

    fn push(&mut self, tuple: (A, B, C)) {
        (self.0).push(tuple.0);
        (self.1).push(tuple.1);
        (self.2).push(tuple.2);
    }

    fn extend(&mut self, other: &mut (Vec<A>, Vec<B>, Vec<C>)) {
        (self.0).append(&mut other.0);
        (self.1).append(&mut other.1);
        (self.2).append(&mut other.2);
    }

    fn complete(self) -> (Distribution<A>, Distribution<B>, Distribution<C>) {
        (
            Distribution(self.0.into_boxed_slice()),
            Distribution(self.1.into_boxed_slice()),
            Distribution(self.2.into_boxed_slice()),
        )
    }
}

File: criterion.rs/src/stats/tuple.rs
Start Line: 173
End Line: 205
Chunks:

impl<A, B, C, D> Tuple for (A, B, C, D)
where
    A: Copy,
    B: Copy,
    C: Copy,
    D: Copy,
{
    type Distributions = (
        Distribution<A>,
        Distribution<B>,
        Distribution<C>,
        Distribution<D>,
    );
    type Builder = (Vec<A>, Vec<B>, Vec<C>, Vec<D>);
}

impl<A, B, C, D> TupledDistributions
    for (
        Distribution<A>,
        Distribution<B>,
        Distribution<C>,
        Distribution<D>,
    )
where
    A: Copy,
    B: Copy,
    C: Copy,
    D: Copy,
{
    type Item = (A, B, C, D);
}

File: criterion.rs/src/stats/tuple.rs
Start Line: 205
End Line: 253
Chunks:
impl<A, B, C, D> TupledDistributionsBuilder for (Vec<A>, Vec<B>, Vec<C>, Vec<D>)
where
    A: Copy,
    B: Copy,
    C: Copy,
    D: Copy,
{
    type Item = (A, B, C, D);

    fn new(size: usize) -> (Vec<A>, Vec<B>, Vec<C>, Vec<D>) {
        (
            Vec::with_capacity(size),
            Vec::with_capacity(size),
            Vec::with_capacity(size),
            Vec::with_capacity(size),
        )
    }

    fn push(&mut self, tuple: (A, B, C, D)) {
        (self.0).push(tuple.0);
        (self.1).push(tuple.1);
        (self.2).push(tuple.2);
        (self.3).push(tuple.3);
    }

    fn extend(&mut self, other: &mut (Vec<A>, Vec<B>, Vec<C>, Vec<D>)) {
        (self.0).append(&mut other.0);
        (self.1).append(&mut other.1);
        (self.2).append(&mut other.2);
        (self.3).append(&mut other.3);
    }

    fn complete(
        self,
    ) -> (
        Distribution<A>,
        Distribution<B>,
        Distribution<C>,
        Distribution<D>,
    ) {
        (
            Distribution(self.0.into_boxed_slice()),
            Distribution(self.1.into_boxed_slice()),
            Distribution(self.2.into_boxed_slice()),
            Distribution(self.3.into_boxed_slice()),
        )
    }
}

Ripgrep filtered Lines: [0, 17]
File: criterion.rs/src/stats/test.rs
Start Line: 0
End Line: 16
Chunks:
use rand::distributions::{Distribution, Standard};
use rand::prelude::*;
use rand::rngs::StdRng;

pub fn vec<T>(size: usize, start: usize) -> Option<Vec<T>>
where
    Standard: Distribution<T>,
{
    if size > start + 2 {
        let mut rng = StdRng::from_entropy();

        Some((0..size).map(|_| rng.gen()).collect())
    } else {
        None
    }
}

Ripgrep filtered Lines: [0, 36, 77, 113]
File: criterion.rs/src/stats/mod.rs
Start Line: 0
End Line: 35
Chunks:
//! [Criterion]'s statistics library.
//!
//! [Criterion]: https://github.com/bheisler/criterion.rs
//!
//! **WARNING** This library is criterion's implementation detail and there no plans to stabilize
//! it. In other words, the API may break at any time without notice.

#[cfg(test)]
mod test;

pub mod bivariate;
pub mod tuple;
pub mod univariate;

mod float;
mod rand_util;

use std::mem;
use std::ops::Deref;

use crate::stats::float::Float;
use crate::stats::univariate::Sample;

/// The bootstrap distribution of some parameter
#[derive(Clone)]
pub struct Distribution<A>(Box<[A]>);

impl<A> Distribution<A>
where
    A: Float,
{
    /// Create a distribution from the given values
    pub fn from(values: Box<[A]>) -> Distribution<A> {
        Distribution(values)
    }

File: criterion.rs/src/stats/mod.rs
Start Line: 35
End Line: 76
Chunks:

    /// Computes the confidence interval of the population parameter using percentiles
    ///
    /// # Panics
    ///
    /// Panics if the `confidence_level` is not in the `(0, 1)` range.
    pub fn confidence_interval(&self, confidence_level: A) -> (A, A)
    where
        usize: cast::From<A, Output = Result<usize, cast::Error>>,
    {
        let _0 = A::cast(0);
        let _1 = A::cast(1);
        let _50 = A::cast(50);

        assert!(confidence_level > _0 && confidence_level < _1);

        let percentiles = self.percentiles();

        // FIXME(privacy) this should use the `at_unchecked()` method
        (
            percentiles.at(_50 * (_1 - confidence_level)),
            percentiles.at(_50 * (_1 + confidence_level)),
        )
    }

    /// Computes the "likelihood" of seeing the value `t` or "more extreme" values in the
    /// distribution.
    pub fn p_value(&self, t: A, tails: &Tails) -> A {
        use std::cmp;

        let n = self.0.len();
        let hits = self.0.iter().filter(|&&x| x < t).count();

        let tails = A::cast(match *tails {
            Tails::One => 1,
            Tails::Two => 2,
        });

        A::cast(cmp::min(hits, n - hits)) / A::cast(n) * tails
    }
}

File: criterion.rs/src/stats/mod.rs
Start Line: 76
End Line: 112
Chunks:

impl<A> Deref for Distribution<A> {
    type Target = Sample<A>;

    fn deref(&self) -> &Sample<A> {
        let slice: &[_] = &self.0;

        unsafe { mem::transmute(slice) }
    }
}

/// Number of tails for significance testing
pub enum Tails {
    /// One tailed test
    One,
    /// Two tailed test
    Two,
}

fn dot<A>(xs: &[A], ys: &[A]) -> A
where
    A: Float,
{
    xs.iter()
        .zip(ys)
        .fold(A::cast(0), |acc, (&x, &y)| acc + x * y)
}

fn sum<A>(xs: &[A]) -> A
where
    A: Float,
{
    use std::ops::Add;

    xs.iter().cloned().fold(A::cast(0), Add::add)
}

Ripgrep filtered Lines: [0, 29, 54]
File: criterion.rs/src/stats/bivariate/regression.rs
Start Line: 0
End Line: 28
Chunks:
//! Regression analysis

use crate::stats::bivariate::Data;
use crate::stats::float::Float;

/// A straight line that passes through the origin `y = m * x`
#[derive(Clone, Copy)]
pub struct Slope<A>(pub A)
where
    A: Float;

impl<A> Slope<A>
where
    A: Float,
{
    /// Fits the data to a straight line that passes through the origin using ordinary least
    /// squares
    ///
    /// - Time: `O(length)`
    pub fn fit(data: &Data<'_, A, A>) -> Slope<A> {
        let xs = data.0;
        let ys = data.1;

        let xy = crate::stats::dot(xs, ys);
        let x2 = crate::stats::dot(xs, xs);

        Slope(xy / x2)
    }

File: criterion.rs/src/stats/bivariate/regression.rs
Start Line: 28
End Line: 53
Chunks:

    /// Computes the goodness of fit (coefficient of determination) for this data set
    ///
    /// - Time: `O(length)`
    pub fn r_squared(&self, data: &Data<'_, A, A>) -> A {
        let _0 = A::cast(0);
        let _1 = A::cast(1);
        let m = self.0;
        let xs = data.0;
        let ys = data.1;

        let n = A::cast(xs.len());
        let y_bar = crate::stats::sum(ys) / n;

        let mut ss_res = _0;
        let mut ss_tot = _0;

        for (&x, &y) in data.iter() {
            ss_res = ss_res + (y - m * x).powi(2);
            ss_tot = ss_res + (y - y_bar).powi(2);
        }

        _1 - ss_res / ss_tot
    }
}

Ripgrep filtered Lines: [0, 9, 54, 92]
File: criterion.rs/src/stats/bivariate/bootstrap.rs
Start Line: 0
End Line: 8
Chunks:
#[cfg(test)]
macro_rules! test {
    ($ty:ident) => {
        mod $ty {
            use quickcheck::TestResult;
            use quickcheck::quickcheck;
            use approx::relative_eq;


File: criterion.rs/src/stats/bivariate/bootstrap.rs
Start Line: 8
End Line: 53
Chunks:
            use crate::stats::bivariate::regression::Slope;
            use crate::stats::bivariate::Data;

            quickcheck! {
                fn means(size: u8, start: u8,
                         offset: u8, nresamples: u8) -> TestResult {
                    let size = size as usize;
                    let start = start as usize;
                    let offset = offset as usize;
                    let nresamples = nresamples as usize;
                    if let Some(x) = crate::stats::test::vec::<$ty>(size, start) {
                        let y = crate::stats::test::vec::<$ty>(size + offset, start + offset).unwrap();
                        let data = Data::new(&x[start..], &y[start+offset..]);

                        let (x_means, y_means) = if nresamples > 0 {
                            data.bootstrap(nresamples, |d| (d.x().mean(), d.y().mean()))
                        } else {
                            return TestResult::discard();
                        };

                        let x_min = data.x().min();
                        let x_max = data.x().max();
                        let y_min = data.y().min();
                        let y_max = data.y().max();

                        TestResult::from_bool(
                            // Computed the correct number of resamples
                            x_means.len() == nresamples &&
                            y_means.len() == nresamples &&
                            // No uninitialized values
                            x_means.iter().all(|&x| {
                                (x > x_min || relative_eq!(x, x_min)) &&
                                (x < x_max || relative_eq!(x, x_max))
                            }) &&
                            y_means.iter().all(|&y| {
                                (y > y_min || relative_eq!(y, y_min)) &&
                                (y < y_max || relative_eq!(y, y_max))
                            })
                        )
                    } else {
                        TestResult::discard()
                    }
                }
            }


File: criterion.rs/src/stats/bivariate/bootstrap.rs
Start Line: 53
End Line: 91
Chunks:
            quickcheck! {
                fn slope(size: u8, start: u8,
                         offset: u8, nresamples: u8) -> TestResult {
                    let size = size as usize;
                    let start = start as usize;
                    let offset = offset as usize;
                    let nresamples = nresamples as usize;
                    if let Some(x) = crate::stats::test::vec::<$ty>(size, start) {
                        let y = crate::stats::test::vec::<$ty>(size + offset, start + offset).unwrap();
                        let data = Data::new(&x[start..], &y[start+offset..]);

                        let slopes = if nresamples > 0 {
                            data.bootstrap(nresamples, |d| (Slope::fit(&d),)).0
                        } else {
                            return TestResult::discard();
                        };

                        TestResult::from_bool(
                            // Computed the correct number of resamples
                            slopes.len() == nresamples &&
                            // No uninitialized values
                            slopes.iter().all(|s| s.0 > 0.)
                        )
                    } else {
                        TestResult::discard()
                    }
                }
            }

        }
    };
}

#[cfg(test)]
mod test {
    test!(f32);
    test!(f64);
}

Ripgrep filtered Lines: [0, 14, 62]
File: criterion.rs/src/stats/bivariate/resamples.rs
Start Line: 0
End Line: 13
Chunks:
use crate::stats::bivariate::Data;
use crate::stats::float::Float;
use crate::stats::rand_util::{new_rng, Rng};

pub struct Resamples<'a, X, Y>
where
    X: 'a + Float,
    Y: 'a + Float,
{
    rng: Rng,
    data: (&'a [X], &'a [Y]),
    stage: Option<(Vec<X>, Vec<Y>)>,
}

File: criterion.rs/src/stats/bivariate/resamples.rs
Start Line: 13
End Line: 61
Chunks:

#[cfg_attr(feature = "cargo-clippy", allow(clippy::should_implement_trait))]
impl<'a, X, Y> Resamples<'a, X, Y>
where
    X: 'a + Float,
    Y: 'a + Float,
{
    pub fn new(data: Data<'a, X, Y>) -> Resamples<'a, X, Y> {
        Resamples {
            rng: new_rng(),
            data: (data.x(), data.y()),
            stage: None,
        }
    }

    pub fn next(&mut self) -> Data<'_, X, Y> {
        let n = self.data.0.len();

        match self.stage {
            None => {
                let mut stage = (Vec::with_capacity(n), Vec::with_capacity(n));

                for _ in 0..n {
                    let i = self.rng.rand_range(0u64..(self.data.0.len() as u64)) as usize;

                    stage.0.push(self.data.0[i]);
                    stage.1.push(self.data.1[i]);
                }

                self.stage = Some(stage);
            }
            Some(ref mut stage) => {
                for i in 0..n {
                    let j = self.rng.rand_range(0u64..(self.data.0.len() as u64)) as usize;

                    stage.0[i] = self.data.0[j];
                    stage.1[i] = self.data.1[j];
                }
            }
        }

        if let Some((ref x, ref y)) = self.stage {
            Data(x, y)
        } else {
            unreachable!();
        }
    }
}

Ripgrep filtered Lines: [0, 45, 62, 112, 147]
File: criterion.rs/src/stats/bivariate/mod.rs
Start Line: 0
End Line: 44
Chunks:
//! Bivariate analysis

mod bootstrap;
pub mod regression;
mod resamples;

use crate::stats::bivariate::resamples::Resamples;
use crate::stats::float::Float;
use crate::stats::tuple::{Tuple, TupledDistributionsBuilder};
use crate::stats::univariate::Sample;
#[cfg(feature = "rayon")]
use rayon::iter::{IntoParallelIterator, ParallelIterator};

/// Bivariate `(X, Y)` data
///
/// Invariants:
///
/// - No `NaN`s in the data
/// - At least two data points in the set
pub struct Data<'a, X, Y>(&'a [X], &'a [Y]);

impl<'a, X, Y> Copy for Data<'a, X, Y> {}

#[cfg_attr(feature = "cargo-clippy", allow(clippy::expl_impl_clone_on_copy))]
impl<'a, X, Y> Clone for Data<'a, X, Y> {
    fn clone(&self) -> Data<'a, X, Y> {
        *self
    }
}

impl<'a, X, Y> Data<'a, X, Y> {
    /// Returns the length of the data set
    pub fn len(&self) -> usize {
        self.0.len()
    }

    /// Iterate over the data set
    pub fn iter(&self) -> Pairs<'a, X, Y> {
        Pairs {
            data: *self,
            state: 0,
        }
    }
}

File: criterion.rs/src/stats/bivariate/mod.rs
Start Line: 44
End Line: 61
Chunks:

impl<'a, X, Y> Data<'a, X, Y>
where
    X: Float,
    Y: Float,
{
    /// Creates a new data set from two existing slices
    pub fn new(xs: &'a [X], ys: &'a [Y]) -> Data<'a, X, Y> {
        assert!(
            xs.len() == ys.len()
                && xs.len() > 1
                && xs.iter().all(|x| !x.is_nan())
                && ys.iter().all(|y| !y.is_nan())
        );

        Data(xs, ys)
    }

File: criterion.rs/src/stats/bivariate/mod.rs
Start Line: 61
End Line: 111
Chunks:

    // TODO Remove the `T` parameter in favor of `S::Output`
    /// Returns the bootstrap distributions of the parameters estimated by the `statistic`
    ///
    /// - Multi-threaded
    /// - Time: `O(nresamples)`
    /// - Memory: `O(nresamples)`
    pub fn bootstrap<T, S>(&self, nresamples: usize, statistic: S) -> T::Distributions
    where
        S: Fn(Data<X, Y>) -> T + Sync,
        T: Tuple + Send,
        T::Distributions: Send,
        T::Builder: Send,
    {
        #[cfg(feature = "rayon")]
        {
            (0..nresamples)
                .into_par_iter()
                .map_init(
                    || Resamples::new(*self),
                    |resamples, _| statistic(resamples.next()),
                )
                .fold(
                    || T::Builder::new(0),
                    |mut sub_distributions, sample| {
                        sub_distributions.push(sample);
                        sub_distributions
                    },
                )
                .reduce(
                    || T::Builder::new(0),
                    |mut a, mut b| {
                        a.extend(&mut b);
                        a
                    },
                )
                .complete()
        }
        #[cfg(not(feature = "rayon"))]
        {
            let mut resamples = Resamples::new(*self);
            (0..nresamples)
                .map(|_| statistic(resamples.next()))
                .fold(T::Builder::new(0), |mut sub_distributions, sample| {
                    sub_distributions.push(sample);
                    sub_distributions
                })
                .complete()
        }
    }

File: criterion.rs/src/stats/bivariate/mod.rs
Start Line: 111
End Line: 146
Chunks:

    /// Returns a view into the `X` data
    pub fn x(&self) -> &'a Sample<X> {
        Sample::new(self.0)
    }

    /// Returns a view into the `Y` data
    pub fn y(&self) -> &'a Sample<Y> {
        Sample::new(self.1)
    }
}

/// Iterator over `Data`
pub struct Pairs<'a, X: 'a, Y: 'a> {
    data: Data<'a, X, Y>,
    state: usize,
}

impl<'a, X, Y> Iterator for Pairs<'a, X, Y> {
    type Item = (&'a X, &'a Y);

    fn next(&mut self) -> Option<(&'a X, &'a Y)> {
        if self.state < self.data.len() {
            let i = self.state;
            self.state += 1;

            // This is safe because i will always be < self.data.{0,1}.len()
            debug_assert!(i < self.data.0.len());
            debug_assert!(i < self.data.1.len());
            unsafe { Some((self.data.0.get_unchecked(i), self.data.1.get_unchecked(i))) }
        } else {
            None
        }
    }
}

Ripgrep filtered Lines: [0, 42, 85, 128, 171, 214, 257, 300, 343, 387, 394, 440, 486, 532, 579, 625, 672, 718, 765]
File: criterion.rs/src/bencher.rs
Start Line: 0
End Line: 41
Chunks:
use std::iter::IntoIterator;
use std::time::Duration;
use std::time::Instant;

use crate::black_box;
use crate::measurement::{Measurement, WallTime};
use crate::BatchSize;

#[cfg(feature = "async")]
use std::future::Future;

#[cfg(feature = "async")]
use crate::async_executor::AsyncExecutor;

// ================================== MAINTENANCE NOTE =============================================
// Any changes made to either Bencher or AsyncBencher will have to be replicated to the other!
// ================================== MAINTENANCE NOTE =============================================

/// Timer struct used to iterate a benchmarked function and measure the runtime.
///
/// This struct provides different timing loops as methods. Each timing loop provides a different
/// way to time a routine and each has advantages and disadvantages.
///
/// * If you want to do the iteration and measurement yourself (eg. passing the iteration count
///   to a separate process), use `iter_custom`.
/// * If your routine requires no per-iteration setup and returns a value with an expensive `drop`
///   method, use `iter_with_large_drop`.
/// * If your routine requires some per-iteration setup that shouldn't be timed, use `iter_batched`
///   or `iter_batched_ref`. See [`BatchSize`](enum.BatchSize.html) for a discussion of batch sizes.
///   If the setup value implements `Drop` and you don't want to include the `drop` time in the
///   measurement, use `iter_batched_ref`, otherwise use `iter_batched`. These methods are also
///   suitable for benchmarking routines which return a value with an expensive `drop` method,
///   but are more complex than `iter_with_large_drop`.
/// * Otherwise, use `iter`.
pub struct Bencher<'a, M: Measurement = WallTime> {
    pub(crate) iterated: bool,         // Have we iterated this benchmark?
    pub(crate) iters: u64,             // Number of times to iterate this benchmark
    pub(crate) value: M::Value,        // The measured value
    pub(crate) measurement: &'a M,     // Reference to the measurement object
    pub(crate) elapsed_time: Duration, // How much time did it take to perform the iteration? Used for the warmup period.
}

File: criterion.rs/src/bencher.rs
Start Line: 41
End Line: 84
Chunks:
impl<'a, M: Measurement> Bencher<'a, M> {
    /// Times a `routine` by executing it many times and timing the total elapsed time.
    ///
    /// Prefer this timing loop when `routine` returns a value that doesn't have a destructor.
    ///
    /// # Timing model
    ///
    /// Note that the `Bencher` also times the time required to destroy the output of `routine()`.
    /// Therefore prefer this timing loop when the runtime of `mem::drop(O)` is negligible compared
    /// to the runtime of the `routine`.
    ///
    /// ```text
    /// elapsed = Instant::now + iters * (routine + mem::drop(O) + Range::next)
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    ///
    /// use criterion::*;
    ///
    /// // The function to benchmark
    /// fn foo() {
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     c.bench_function("iter", move |b| {
    ///         b.iter(|| foo())
    ///     });
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    ///
    #[inline(never)]
    pub fn iter<O, R>(&mut self, mut routine: R)
    where
        R: FnMut() -> O,
    {
        self.iterated = true;

File: criterion.rs/src/bencher.rs
Start Line: 84
End Line: 127
Chunks:
        let time_start = Instant::now();
        let start = self.measurement.start();
        for _ in 0..self.iters {
            black_box(routine());
        }
        self.value = self.measurement.end(start);
        self.elapsed_time = time_start.elapsed();
    }

    /// Times a `routine` by executing it many times and relying on `routine` to measure its own execution time.
    ///
    /// Prefer this timing loop in cases where `routine` has to do its own measurements to
    /// get accurate timing information (for example in multi-threaded scenarios where you spawn
    /// and coordinate with multiple threads).
    ///
    /// # Timing model
    /// Custom, the timing model is whatever is returned as the Duration from `routine`.
    ///
    /// # Example
    /// ```rust
    /// #[macro_use] extern crate criterion;
    /// use criterion::*;
    /// use criterion::black_box;
    /// use std::time::Instant;
    ///
    /// fn foo() {
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     c.bench_function("iter", move |b| {
    ///         b.iter_custom(|iters| {
    ///             let start = Instant::now();
    ///             for _i in 0..iters {
    ///                 black_box(foo());
    ///             }
    ///             start.elapsed()
    ///         })
    ///     });
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);

File: criterion.rs/src/bencher.rs
Start Line: 127
End Line: 170
Chunks:
    /// ```
    ///
    #[inline(never)]
    pub fn iter_custom<R>(&mut self, mut routine: R)
    where
        R: FnMut(u64) -> M::Value,
    {
        self.iterated = true;
        let time_start = Instant::now();
        self.value = routine(self.iters);
        self.elapsed_time = time_start.elapsed();
    }

    #[doc(hidden)]
    pub fn iter_with_setup<I, O, S, R>(&mut self, setup: S, routine: R)
    where
        S: FnMut() -> I,
        R: FnMut(I) -> O,
    {
        self.iter_batched(setup, routine, BatchSize::PerIteration);
    }

    /// Times a `routine` by collecting its output on each iteration. This avoids timing the
    /// destructor of the value returned by `routine`.
    ///
    /// WARNING: This requires `O(iters * mem::size_of::<O>())` of memory, and `iters` is not under the
    /// control of the caller. If this causes out-of-memory errors, use `iter_batched` instead.
    ///
    /// # Timing model
    ///
    /// ``` text
    /// elapsed = Instant::now + iters * (routine) + Iterator::collect::<Vec<_>>
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    ///
    /// use criterion::*;
    ///
    /// fn create_vector() -> Vec<u64> {
    ///     # vec![]

File: criterion.rs/src/bencher.rs
Start Line: 170
End Line: 213
Chunks:
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     c.bench_function("with_drop", move |b| {
    ///         // This will avoid timing the Vec::drop.
    ///         b.iter_with_large_drop(|| create_vector())
    ///     });
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    ///
    pub fn iter_with_large_drop<O, R>(&mut self, mut routine: R)
    where
        R: FnMut() -> O,
    {
        self.iter_batched(|| (), |_| routine(), BatchSize::SmallInput);
    }

    /// Times a `routine` that requires some input by generating a batch of input, then timing the
    /// iteration of the benchmark over the input. See [`BatchSize`](enum.BatchSize.html) for
    /// details on choosing the batch size. Use this when the routine must consume its input.
    ///
    /// For example, use this loop to benchmark sorting algorithms, because they require unsorted
    /// data on each iteration.
    ///
    /// # Timing model
    ///
    /// ```text
    /// elapsed = (Instant::now * num_batches) + (iters * (routine + O::drop)) + Vec::extend
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    ///
    /// use criterion::*;
    ///
    /// fn create_scrambled_data() -> Vec<u64> {
    ///     # vec![]

File: criterion.rs/src/bencher.rs
Start Line: 213
End Line: 256
Chunks:
    ///     // ...
    /// }
    ///
    /// // The sorting algorithm to test
    /// fn sort(data: &mut [u64]) {
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     let data = create_scrambled_data();
    ///
    ///     c.bench_function("with_setup", move |b| {
    ///         // This will avoid timing the to_vec call.
    ///         b.iter_batched(|| data.clone(), |mut data| sort(&mut data), BatchSize::SmallInput)
    ///     });
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    ///
    #[inline(never)]
    pub fn iter_batched<I, O, S, R>(&mut self, mut setup: S, mut routine: R, size: BatchSize)
    where
        S: FnMut() -> I,
        R: FnMut(I) -> O,
    {
        self.iterated = true;
        let batch_size = size.iters_per_batch(self.iters);
        assert!(batch_size != 0, "Batch size must not be zero.");
        let time_start = Instant::now();
        self.value = self.measurement.zero();

        if batch_size == 1 {
            for _ in 0..self.iters {
                let input = black_box(setup());

                let start = self.measurement.start();
                let output = routine(input);
                let end = self.measurement.end(start);
                self.value = self.measurement.add(&self.value, &end);

                drop(black_box(output));

File: criterion.rs/src/bencher.rs
Start Line: 256
End Line: 299
Chunks:
            }
        } else {
            let mut iteration_counter = 0;

            while iteration_counter < self.iters {
                let batch_size = ::std::cmp::min(batch_size, self.iters - iteration_counter);

                let inputs = black_box((0..batch_size).map(|_| setup()).collect::<Vec<_>>());
                let mut outputs = Vec::with_capacity(batch_size as usize);

                let start = self.measurement.start();
                outputs.extend(inputs.into_iter().map(&mut routine));
                let end = self.measurement.end(start);
                self.value = self.measurement.add(&self.value, &end);

                black_box(outputs);

                iteration_counter += batch_size;
            }
        }

        self.elapsed_time = time_start.elapsed();
    }

    /// Times a `routine` that requires some input by generating a batch of input, then timing the
    /// iteration of the benchmark over the input. See [`BatchSize`](enum.BatchSize.html) for
    /// details on choosing the batch size. Use this when the routine should accept the input by
    /// mutable reference.
    ///
    /// For example, use this loop to benchmark sorting algorithms, because they require unsorted
    /// data on each iteration.
    ///
    /// # Timing model
    ///
    /// ```text
    /// elapsed = (Instant::now * num_batches) + (iters * routine) + Vec::extend
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    ///

File: criterion.rs/src/bencher.rs
Start Line: 299
End Line: 342
Chunks:
    /// use criterion::*;
    ///
    /// fn create_scrambled_data() -> Vec<u64> {
    ///     # vec![]
    ///     // ...
    /// }
    ///
    /// // The sorting algorithm to test
    /// fn sort(data: &mut [u64]) {
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     let data = create_scrambled_data();
    ///
    ///     c.bench_function("with_setup", move |b| {
    ///         // This will avoid timing the to_vec call.
    ///         b.iter_batched(|| data.clone(), |mut data| sort(&mut data), BatchSize::SmallInput)
    ///     });
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    ///
    #[inline(never)]
    pub fn iter_batched_ref<I, O, S, R>(&mut self, mut setup: S, mut routine: R, size: BatchSize)
    where
        S: FnMut() -> I,
        R: FnMut(&mut I) -> O,
    {
        self.iterated = true;
        let batch_size = size.iters_per_batch(self.iters);
        assert!(batch_size != 0, "Batch size must not be zero.");
        let time_start = Instant::now();
        self.value = self.measurement.zero();

        if batch_size == 1 {
            for _ in 0..self.iters {
                let mut input = black_box(setup());

                let start = self.measurement.start();
                let output = routine(&mut input);

File: criterion.rs/src/bencher.rs
Start Line: 342
End Line: 386
Chunks:
                let end = self.measurement.end(start);
                self.value = self.measurement.add(&self.value, &end);

                drop(black_box(output));
                drop(black_box(input));
            }
        } else {
            let mut iteration_counter = 0;

            while iteration_counter < self.iters {
                let batch_size = ::std::cmp::min(batch_size, self.iters - iteration_counter);

                let mut inputs = black_box((0..batch_size).map(|_| setup()).collect::<Vec<_>>());
                let mut outputs = Vec::with_capacity(batch_size as usize);

                let start = self.measurement.start();
                outputs.extend(inputs.iter_mut().map(&mut routine));
                let end = self.measurement.end(start);
                self.value = self.measurement.add(&self.value, &end);

                black_box(outputs);

                iteration_counter += batch_size;
            }
        }
        self.elapsed_time = time_start.elapsed();
    }

    // Benchmarks must actually call one of the iter methods. This causes benchmarks to fail loudly
    // if they don't.
    pub(crate) fn assert_iterated(&mut self) {
        assert!(
            self.iterated,
            "Benchmark function must call Bencher::iter or related method."
        );
        self.iterated = false;
    }

    /// Convert this bencher into an AsyncBencher, which enables async/await support.
    #[cfg(feature = "async")]
    pub fn to_async<'b, A: AsyncExecutor>(&'b mut self, runner: A) -> AsyncBencher<'a, 'b, A, M> {
        AsyncBencher { b: self, runner }
    }
}

File: criterion.rs/src/bencher.rs
Start Line: 386
End Line: 393
Chunks:

/// Async/await variant of the Bencher struct.
#[cfg(feature = "async")]
pub struct AsyncBencher<'a, 'b, A: AsyncExecutor, M: Measurement = WallTime> {
    b: &'b mut Bencher<'a, M>,
    runner: A,
}

File: criterion.rs/src/bencher.rs
Start Line: 393
End Line: 439
Chunks:
#[cfg(feature = "async")]
impl<'a, 'b, A: AsyncExecutor, M: Measurement> AsyncBencher<'a, 'b, A, M> {
    /// Times a `routine` by executing it many times and timing the total elapsed time.
    ///
    /// Prefer this timing loop when `routine` returns a value that doesn't have a destructor.
    ///
    /// # Timing model
    ///
    /// Note that the `AsyncBencher` also times the time required to destroy the output of `routine()`.
    /// Therefore prefer this timing loop when the runtime of `mem::drop(O)` is negligible compared
    /// to the runtime of the `routine`.
    ///
    /// ```text
    /// elapsed = Instant::now + iters * (routine + mem::drop(O) + Range::next)
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    ///
    /// use criterion::*;
    /// use criterion::async_executor::FuturesExecutor;
    ///
    /// // The function to benchmark
    /// async fn foo() {
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     c.bench_function("iter", move |b| {
    ///         b.to_async(FuturesExecutor).iter(|| async { foo().await } )
    ///     });
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    ///
    #[inline(never)]
    pub fn iter<O, R, F>(&mut self, mut routine: R)
    where
        R: FnMut() -> F,
        F: Future<Output = O>,
    {
        let AsyncBencher { b, runner } = self;

File: criterion.rs/src/bencher.rs
Start Line: 439
End Line: 485
Chunks:
        runner.block_on(async {
            b.iterated = true;
            let time_start = Instant::now();
            let start = b.measurement.start();
            for _ in 0..b.iters {
                black_box(routine().await);
            }
            b.value = b.measurement.end(start);
            b.elapsed_time = time_start.elapsed();
        });
    }

    /// Times a `routine` by executing it many times and relying on `routine` to measure its own execution time.
    ///
    /// Prefer this timing loop in cases where `routine` has to do its own measurements to
    /// get accurate timing information (for example in multi-threaded scenarios where you spawn
    /// and coordinate with multiple threads).
    ///
    /// # Timing model
    /// Custom, the timing model is whatever is returned as the Duration from `routine`.
    ///
    /// # Example
    /// ```rust
    /// #[macro_use] extern crate criterion;
    /// use criterion::*;
    /// use criterion::black_box;
    /// use criterion::async_executor::FuturesExecutor;
    /// use std::time::Instant;
    ///
    /// async fn foo() {
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     c.bench_function("iter", move |b| {
    ///         b.to_async(FuturesExecutor).iter_custom(|iters| {
    ///             async move {
    ///                 let start = Instant::now();
    ///                 for _i in 0..iters {
    ///                     black_box(foo().await);
    ///                 }
    ///                 start.elapsed()
    ///             }
    ///         })
    ///     });
    /// }

File: criterion.rs/src/bencher.rs
Start Line: 485
End Line: 531
Chunks:
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    ///
    #[inline(never)]
    pub fn iter_custom<R, F>(&mut self, mut routine: R)
    where
        R: FnMut(u64) -> F,
        F: Future<Output = M::Value>,
    {
        let AsyncBencher { b, runner } = self;
        runner.block_on(async {
            b.iterated = true;
            let time_start = Instant::now();
            b.value = routine(b.iters).await;
            b.elapsed_time = time_start.elapsed();
        })
    }

    #[doc(hidden)]
    pub fn iter_with_setup<I, O, S, R, F>(&mut self, setup: S, routine: R)
    where
        S: FnMut() -> I,
        R: FnMut(I) -> F,
        F: Future<Output = O>,
    {
        self.iter_batched(setup, routine, BatchSize::PerIteration);
    }

    /// Times a `routine` by collecting its output on each iteration. This avoids timing the
    /// destructor of the value returned by `routine`.
    ///
    /// WARNING: This requires `O(iters * mem::size_of::<O>())` of memory, and `iters` is not under the
    /// control of the caller. If this causes out-of-memory errors, use `iter_batched` instead.
    ///
    /// # Timing model
    ///
    /// ``` text
    /// elapsed = Instant::now + iters * (routine) + Iterator::collect::<Vec<_>>
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;

File: criterion.rs/src/bencher.rs
Start Line: 531
End Line: 578
Chunks:
    ///
    /// use criterion::*;
    /// use criterion::async_executor::FuturesExecutor;
    ///
    /// async fn create_vector() -> Vec<u64> {
    ///     # vec![]
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     c.bench_function("with_drop", move |b| {
    ///         // This will avoid timing the Vec::drop.
    ///         b.to_async(FuturesExecutor).iter_with_large_drop(|| async { create_vector().await })
    ///     });
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    ///
    pub fn iter_with_large_drop<O, R, F>(&mut self, mut routine: R)
    where
        R: FnMut() -> F,
        F: Future<Output = O>,
    {
        self.iter_batched(|| (), |_| routine(), BatchSize::SmallInput);
    }

    #[doc(hidden)]
    pub fn iter_with_large_setup<I, O, S, R, F>(&mut self, setup: S, routine: R)
    where
        S: FnMut() -> I,
        R: FnMut(I) -> F,
        F: Future<Output = O>,
    {
        self.iter_batched(setup, routine, BatchSize::NumBatches(1));
    }

    /// Times a `routine` that requires some input by generating a batch of input, then timing the
    /// iteration of the benchmark over the input. See [`BatchSize`](enum.BatchSize.html) for
    /// details on choosing the batch size. Use this when the routine must consume its input.
    ///
    /// For example, use this loop to benchmark sorting algorithms, because they require unsorted
    /// data on each iteration.
    ///
    /// # Timing model
    ///

File: criterion.rs/src/bencher.rs
Start Line: 578
End Line: 624
Chunks:
    /// ```text
    /// elapsed = (Instant::now * num_batches) + (iters * (routine + O::drop)) + Vec::extend
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    ///
    /// use criterion::*;
    /// use criterion::async_executor::FuturesExecutor;
    ///
    /// fn create_scrambled_data() -> Vec<u64> {
    ///     # vec![]
    ///     // ...
    /// }
    ///
    /// // The sorting algorithm to test
    /// async fn sort(data: &mut [u64]) {
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     let data = create_scrambled_data();
    ///
    ///     c.bench_function("with_setup", move |b| {
    ///         // This will avoid timing the to_vec call.
    ///         b.iter_batched(|| data.clone(), |mut data| async move { sort(&mut data).await }, BatchSize::SmallInput)
    ///     });
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    ///
    #[inline(never)]
    pub fn iter_batched<I, O, S, R, F>(&mut self, mut setup: S, mut routine: R, size: BatchSize)
    where
        S: FnMut() -> I,
        R: FnMut(I) -> F,
        F: Future<Output = O>,
    {
        let AsyncBencher { b, runner } = self;
        runner.block_on(async {
            b.iterated = true;
            let batch_size = size.iters_per_batch(b.iters);

File: criterion.rs/src/bencher.rs
Start Line: 624
End Line: 671
Chunks:
            assert!(batch_size != 0, "Batch size must not be zero.");
            let time_start = Instant::now();
            b.value = b.measurement.zero();

            if batch_size == 1 {
                for _ in 0..b.iters {
                    let input = black_box(setup());

                    let start = b.measurement.start();
                    let output = routine(input).await;
                    let end = b.measurement.end(start);
                    b.value = b.measurement.add(&b.value, &end);

                    drop(black_box(output));
                }
            } else {
                let mut iteration_counter = 0;

                while iteration_counter < b.iters {
                    let batch_size = ::std::cmp::min(batch_size, b.iters - iteration_counter);

                    let inputs = black_box((0..batch_size).map(|_| setup()).collect::<Vec<_>>());
                    let mut outputs = Vec::with_capacity(batch_size as usize);

                    let start = b.measurement.start();
                    // Can't use .extend here like the sync version does
                    for input in inputs {
                        outputs.push(routine(input).await);
                    }
                    let end = b.measurement.end(start);
                    b.value = b.measurement.add(&b.value, &end);

                    black_box(outputs);

                    iteration_counter += batch_size;
                }
            }

            b.elapsed_time = time_start.elapsed();
        })
    }

    /// Times a `routine` that requires some input by generating a batch of input, then timing the
    /// iteration of the benchmark over the input. See [`BatchSize`](enum.BatchSize.html) for
    /// details on choosing the batch size. Use this when the routine should accept the input by
    /// mutable reference.
    ///

File: criterion.rs/src/bencher.rs
Start Line: 671
End Line: 717
Chunks:
    /// For example, use this loop to benchmark sorting algorithms, because they require unsorted
    /// data on each iteration.
    ///
    /// # Timing model
    ///
    /// ```text
    /// elapsed = (Instant::now * num_batches) + (iters * routine) + Vec::extend
    /// ```
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    ///
    /// use criterion::*;
    /// use criterion::async_executor::FuturesExecutor;
    ///
    /// fn create_scrambled_data() -> Vec<u64> {
    ///     # vec![]
    ///     // ...
    /// }
    ///
    /// // The sorting algorithm to test
    /// async fn sort(data: &mut [u64]) {
    ///     // ...
    /// }
    ///
    /// fn bench(c: &mut Criterion) {
    ///     let data = create_scrambled_data();
    ///
    ///     c.bench_function("with_setup", move |b| {
    ///         // This will avoid timing the to_vec call.
    ///         b.iter_batched(|| data.clone(), |mut data| async move { sort(&mut data).await }, BatchSize::SmallInput)
    ///     });
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    ///
    #[inline(never)]
    pub fn iter_batched_ref<I, O, S, R, F>(&mut self, mut setup: S, mut routine: R, size: BatchSize)
    where
        S: FnMut() -> I,
        R: FnMut(&mut I) -> F,
        F: Future<Output = O>,

File: criterion.rs/src/bencher.rs
Start Line: 717
End Line: 764
Chunks:
    {
        let AsyncBencher { b, runner } = self;
        runner.block_on(async {
            b.iterated = true;
            let batch_size = size.iters_per_batch(b.iters);
            assert!(batch_size != 0, "Batch size must not be zero.");
            let time_start = Instant::now();
            b.value = b.measurement.zero();

            if batch_size == 1 {
                for _ in 0..b.iters {
                    let mut input = black_box(setup());

                    let start = b.measurement.start();
                    let output = routine(&mut input).await;
                    let end = b.measurement.end(start);
                    b.value = b.measurement.add(&b.value, &end);

                    drop(black_box(output));
                    drop(black_box(input));
                }
            } else {
                let mut iteration_counter = 0;

                while iteration_counter < b.iters {
                    let batch_size = ::std::cmp::min(batch_size, b.iters - iteration_counter);

                    let inputs = black_box((0..batch_size).map(|_| setup()).collect::<Vec<_>>());
                    let mut outputs = Vec::with_capacity(batch_size as usize);

                    let start = b.measurement.start();
                    // Can't use .extend here like the sync version does
                    for mut input in inputs {
                        outputs.push(routine(&mut input).await);
                    }
                    let end = b.measurement.end(start);
                    b.value = b.measurement.add(&b.value, &end);

                    black_box(outputs);

                    iteration_counter += batch_size;
                }
            }
            b.elapsed_time = time_start.elapsed();
        });
    }
}

Ripgrep filtered Lines: [0, 49, 86, 133, 173, 218, 257, 272, 308, 357, 360, 408, 447, 471, 501]
File: criterion.rs/src/benchmark_group.rs
Start Line: 0
End Line: 48
Chunks:
use crate::analysis;
use crate::benchmark::PartialBenchmarkConfig;
use crate::connection::OutgoingMessage;
use crate::measurement::Measurement;
use crate::report::BenchmarkId as InternalBenchmarkId;
use crate::report::Report;
use crate::report::ReportContext;
use crate::routine::{Function, Routine};
use crate::{Bencher, Criterion, Mode, PlotConfiguration, SamplingMode, Throughput};
use std::time::Duration;

/// Structure used to group together a set of related benchmarks, along with custom configuration
/// settings for groups of benchmarks. All benchmarks performed using a benchmark group will be
/// grouped together in the final report.
///
/// # Examples:
///
/// ```no_run
/// #[macro_use] extern crate criterion;
/// use self::criterion::*;
/// use std::time::Duration;
///
/// fn bench_simple(c: &mut Criterion) {
///     let mut group = c.benchmark_group("My Group");
///
///     // Now we can perform benchmarks with this group
///     group.bench_function("Bench 1", |b| b.iter(|| 1 ));
///     group.bench_function("Bench 2", |b| b.iter(|| 2 ));
///    
///     // It's recommended to call group.finish() explicitly at the end, but if you don't it will
///     // be called automatically when the group is dropped.
///     group.finish();
/// }
///
/// fn bench_nested(c: &mut Criterion) {
///     let mut group = c.benchmark_group("My Second Group");
///     // We can override the configuration on a per-group level
///     group.measurement_time(Duration::from_secs(1));
///
///     // We can also use loops to define multiple benchmarks, even over multiple dimensions.
///     for x in 0..3 {
///         for y in 0..3 {
///             let point = (x, y);
///             let parameter_string = format!("{} * {}", x, y);
///             group.bench_with_input(BenchmarkId::new("Multiply", parameter_string), &point,
///                 |b, (p_x, p_y)| b.iter(|| p_x * p_y));
///         }
///     }

File: criterion.rs/src/benchmark_group.rs
Start Line: 48
End Line: 85
Chunks:
///    
///     group.finish();
/// }
///
/// fn bench_throughput(c: &mut Criterion) {
///     let mut group = c.benchmark_group("Summation");
///     
///     for size in [1024, 2048, 4096].iter() {
///         // Generate input of an appropriate size...
///         let input = vec![1u64, *size];
///
///         // We can use the throughput function to tell Criterion.rs how large the input is
///         // so it can calculate the overall throughput of the function. If we wanted, we could
///         // even change the benchmark configuration for different inputs (eg. to reduce the
///         // number of samples for extremely large and slow inputs) or even different functions.
///         group.throughput(Throughput::Elements(*size as u64));
///
///         group.bench_with_input(BenchmarkId::new("sum", *size), &input,
///             |b, i| b.iter(|| i.iter().sum::<u64>()));
///         group.bench_with_input(BenchmarkId::new("fold", *size), &input,
///             |b, i| b.iter(|| i.iter().fold(0u64, |a, b| a + b)));
///     }
///
///     group.finish();
/// }
///
/// criterion_group!(benches, bench_simple, bench_nested, bench_throughput);
/// criterion_main!(benches);
/// ```
pub struct BenchmarkGroup<'a, M: Measurement> {
    criterion: &'a mut Criterion<M>,
    group_name: String,
    all_ids: Vec<InternalBenchmarkId>,
    any_matched: bool,
    partial_config: PartialBenchmarkConfig,
    throughput: Option<Throughput>,
}

File: criterion.rs/src/benchmark_group.rs
Start Line: 85
End Line: 132
Chunks:
impl<'a, M: Measurement> BenchmarkGroup<'a, M> {
    /// Changes the size of the sample for this benchmark
    ///
    /// A bigger sample should yield more accurate results if paired with a sufficiently large
    /// measurement time.
    ///
    /// Sample size must be at least 10.
    ///
    /// # Panics
    ///
    /// Panics if n < 10.
    pub fn sample_size(&mut self, n: usize) -> &mut Self {
        assert!(n >= 10);

        self.partial_config.sample_size = Some(n);
        self
    }

    /// Changes the warm up time for this benchmark
    ///
    /// # Panics
    ///
    /// Panics if the input duration is zero
    pub fn warm_up_time(&mut self, dur: Duration) -> &mut Self {
        assert!(dur.as_nanos() > 0);

        self.partial_config.warm_up_time = Some(dur);
        self
    }

    /// Changes the target measurement time for this benchmark group.
    ///
    /// Criterion will attempt to spent approximately this amount of time measuring each
    /// benchmark on a best-effort basis. If it is not possible to perform the measurement in
    /// the requested time (eg. because each iteration of the benchmark is long) then Criterion
    /// will spend as long as is needed to collect the desired number of samples. With a longer
    /// time, the measurement will become more resilient to interference from other programs.
    ///
    /// # Panics
    ///
    /// Panics if the input duration is zero
    pub fn measurement_time(&mut self, dur: Duration) -> &mut Self {
        assert!(dur.as_nanos() > 0);

        self.partial_config.measurement_time = Some(dur);
        self
    }

File: criterion.rs/src/benchmark_group.rs
Start Line: 132
End Line: 172
Chunks:

    /// Changes the number of resamples for this benchmark group
    ///
    /// Number of resamples to use for the
    /// [bootstrap](http://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Case_resampling)
    ///
    /// A larger number of resamples reduces the random sampling errors which are inherent to the
    /// bootstrap method, but also increases the analysis time.
    ///
    /// # Panics
    ///
    /// Panics if the number of resamples is set to zero
    pub fn nresamples(&mut self, n: usize) -> &mut Self {
        assert!(n > 0);
        if n <= 1000 {
            eprintln!("\nWarning: It is not recommended to reduce nresamples below 1000.");
        }

        self.partial_config.nresamples = Some(n);
        self
    }

    /// Changes the noise threshold for benchmarks in this group. The noise threshold
    /// is used to filter out small changes in performance from one run to the next, even if they
    /// are statistically significant. Sometimes benchmarking the same code twice will result in
    /// small but statistically significant differences solely because of noise. This provides a way
    /// to filter out some of these false positives at the cost of making it harder to detect small
    /// changes to the true performance of the benchmark.
    ///
    /// The default is 0.01, meaning that changes smaller than 1% will be ignored.
    ///
    /// # Panics
    ///
    /// Panics if the threshold is set to a negative value
    pub fn noise_threshold(&mut self, threshold: f64) -> &mut Self {
        assert!(threshold >= 0.0);

        self.partial_config.noise_threshold = Some(threshold);
        self
    }

File: criterion.rs/src/benchmark_group.rs
Start Line: 172
End Line: 217
Chunks:

    /// Changes the confidence level for benchmarks in this group. The confidence
    /// level is the desired probability that the true runtime lies within the estimated
    /// [confidence interval](https://en.wikipedia.org/wiki/Confidence_interval). The default is
    /// 0.95, meaning that the confidence interval should capture the true value 95% of the time.
    ///
    /// # Panics
    ///
    /// Panics if the confidence level is set to a value outside the `(0, 1)` range
    pub fn confidence_level(&mut self, cl: f64) -> &mut Self {
        assert!(cl > 0.0 && cl < 1.0);
        if cl < 0.5 {
            eprintln!("\nWarning: It is not recommended to reduce confidence level below 0.5.");
        }

        self.partial_config.confidence_level = Some(cl);
        self
    }

    /// Changes the [significance level](https://en.wikipedia.org/wiki/Statistical_significance)
    /// for benchmarks in this group. This is used to perform a
    /// [hypothesis test](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) to see if
    /// the measurements from this run are different from the measured performance of the last run.
    /// The significance level is the desired probability that two measurements of identical code
    /// will be considered 'different' due to noise in the measurements. The default value is 0.05,
    /// meaning that approximately 5% of identical benchmarks will register as different due to
    /// noise.
    ///
    /// This presents a trade-off. By setting the significance level closer to 0.0, you can increase
    /// the statistical robustness against noise, but it also weakens Criterion.rs' ability to
    /// detect small but real changes in the performance. By setting the significance level
    /// closer to 1.0, Criterion.rs will be more able to detect small true changes, but will also
    /// report more spurious differences.
    ///
    /// See also the noise threshold setting.
    ///
    /// # Panics
    ///
    /// Panics if the significance level is set to a value outside the `(0, 1)` range
    pub fn significance_level(&mut self, sl: f64) -> &mut Self {
        assert!(sl > 0.0 && sl < 1.0);

        self.partial_config.significance_level = Some(sl);
        self
    }

File: criterion.rs/src/benchmark_group.rs
Start Line: 217
End Line: 256
Chunks:

    /// Changes the plot configuration for this benchmark group.
    pub fn plot_config(&mut self, new_config: PlotConfiguration) -> &mut Self {
        self.partial_config.plot_config = new_config;
        self
    }

    /// Set the input size for this benchmark group. Used for reporting the
    /// throughput.
    pub fn throughput(&mut self, throughput: Throughput) -> &mut Self {
        self.throughput = Some(throughput);
        self
    }

    /// Set the sampling mode for this benchmark group.
    pub fn sampling_mode(&mut self, new_mode: SamplingMode) -> &mut Self {
        self.partial_config.sampling_mode = Some(new_mode);
        self
    }

    pub(crate) fn new(criterion: &mut Criterion<M>, group_name: String) -> BenchmarkGroup<'_, M> {
        BenchmarkGroup {
            criterion,
            group_name,
            all_ids: vec![],
            any_matched: false,
            partial_config: PartialBenchmarkConfig::default(),
            throughput: None,
        }
    }

    /// Benchmark the given parameterless function inside this benchmark group.
    pub fn bench_function<ID: IntoBenchmarkId, F>(&mut self, id: ID, mut f: F) -> &mut Self
    where
        F: FnMut(&mut Bencher<'_, M>),
    {
        self.run_bench(id.into_benchmark_id(), &(), |b, _| f(b));
        self
    }

File: criterion.rs/src/benchmark_group.rs
Start Line: 256
End Line: 271
Chunks:

    /// Benchmark the given parameterized function inside this benchmark group.
    pub fn bench_with_input<ID: IntoBenchmarkId, F, I>(
        &mut self,
        id: ID,
        input: &I,
        f: F,
    ) -> &mut Self
    where
        F: FnMut(&mut Bencher<'_, M>, &I),
        I: ?Sized,
    {
        self.run_bench(id.into_benchmark_id(), input, f);
        self
    }

File: criterion.rs/src/benchmark_group.rs
Start Line: 271
End Line: 307
Chunks:

    fn run_bench<F, I>(&mut self, id: BenchmarkId, input: &I, f: F)
    where
        F: FnMut(&mut Bencher<'_, M>, &I),
        I: ?Sized,
    {
        let config = self.partial_config.to_complete(&self.criterion.config);
        let report_context = ReportContext {
            output_directory: self.criterion.output_directory.clone(),
            plot_config: self.partial_config.plot_config.clone(),
        };

        let mut id = InternalBenchmarkId::new(
            self.group_name.clone(),
            id.function_name,
            id.parameter,
            self.throughput.clone(),
        );

        assert!(
            !self.all_ids.contains(&id),
            "Benchmark IDs must be unique within a group. Encountered duplicated benchmark ID {}",
            &id
        );

        id.ensure_directory_name_unique(&self.criterion.all_directories);
        self.criterion
            .all_directories
            .insert(id.as_directory_name().to_owned());
        id.ensure_title_unique(&self.criterion.all_titles);
        self.criterion.all_titles.insert(id.as_title().to_owned());

        let do_run = self.criterion.filter_matches(id.id());
        self.any_matched |= do_run;
        let mut func = Function::new(f);


File: criterion.rs/src/benchmark_group.rs
Start Line: 307
End Line: 356
Chunks:
        match &self.criterion.mode {
            Mode::Benchmark => {
                if let Some(conn) = &self.criterion.connection {
                    if do_run {
                        conn.send(&OutgoingMessage::BeginningBenchmark { id: (&id).into() })
                            .unwrap();
                    } else {
                        conn.send(&OutgoingMessage::SkippingBenchmark { id: (&id).into() })
                            .unwrap();
                    }
                }
                if do_run {
                    analysis::common(
                        &id,
                        &mut func,
                        &config,
                        self.criterion,
                        &report_context,
                        input,
                        self.throughput.clone(),
                    );
                }
            }
            Mode::List(_) => {
                if do_run {
                    println!("{}: benchmark", id);
                }
            }
            Mode::Test => {
                if do_run {
                    // In test mode, run the benchmark exactly once, then exit.
                    self.criterion.report.test_start(&id, &report_context);
                    func.test(&self.criterion.measurement, input);
                    self.criterion.report.test_pass(&id, &report_context);
                }
            }
            &Mode::Profile(duration) => {
                if do_run {
                    func.profile(
                        &self.criterion.measurement,
                        &id,
                        self.criterion,
                        &report_context,
                        duration,
                        input,
                    );
                }
            }
        }

File: criterion.rs/src/benchmark_group.rs
Start Line: 356
End Line: 359
Chunks:

        self.all_ids.push(id);
    }

File: criterion.rs/src/benchmark_group.rs
Start Line: 359
End Line: 407
Chunks:

    /// Consume the benchmark group and generate the summary reports for the group.
    ///
    /// It is recommended to call this explicitly, but if you forget it will be called when the
    /// group is dropped.
    pub fn finish(self) {
        ::std::mem::drop(self);
    }
}
impl<'a, M: Measurement> Drop for BenchmarkGroup<'a, M> {
    fn drop(&mut self) {
        // I don't really like having a bunch of non-trivial code in drop, but this is the only way
        // to really write linear types like this in Rust...
        if let Some(conn) = &mut self.criterion.connection {
            conn.send(&OutgoingMessage::FinishedBenchmarkGroup {
                group: &self.group_name,
            })
            .unwrap();

            conn.serve_value_formatter(self.criterion.measurement.formatter())
                .unwrap();
        }

        if self.all_ids.len() > 1 && self.any_matched && self.criterion.mode.is_benchmark() {
            let report_context = ReportContext {
                output_directory: self.criterion.output_directory.clone(),
                plot_config: self.partial_config.plot_config.clone(),
            };

            self.criterion.report.summarize(
                &report_context,
                &self.all_ids,
                self.criterion.measurement.formatter(),
            );
        }
        if self.any_matched && !self.criterion.mode.is_terse() {
            self.criterion.report.group_separator();
        }
    }
}

/// Simple structure representing an ID for a benchmark. The ID must be unique within a benchmark
/// group.
#[derive(Clone, Eq, PartialEq, Hash)]
pub struct BenchmarkId {
    pub(crate) function_name: Option<String>,
    pub(crate) parameter: Option<String>,
}

File: criterion.rs/src/benchmark_group.rs
Start Line: 407
End Line: 446
Chunks:
impl BenchmarkId {
    /// Construct a new benchmark ID from a string function name and a parameter value.
    ///
    /// Note that the parameter value need not be the same as the parameter passed to your
    /// actual benchmark. For instance, you might have a benchmark that takes a 1MB string as
    /// input. It would be impractical to embed the whole string in the benchmark ID, so instead
    /// your parameter value might be a descriptive string like "1MB Alphanumeric".
    ///
    /// # Examples
    /// ```
    /// # use criterion::{BenchmarkId, Criterion};
    /// // A basic benchmark ID is typically constructed from a constant string and a simple
    /// // parameter
    /// let basic_id = BenchmarkId::new("my_id", 5);
    ///
    /// // The function name can be a string
    /// let function_name = "test_string".to_string();
    /// let string_id = BenchmarkId::new(function_name, 12);
    ///
    /// // Benchmark IDs are passed to benchmark groups:
    /// let mut criterion = Criterion::default();
    /// let mut group = criterion.benchmark_group("My Group");
    /// // Generate a very large input
    /// let input : String = ::std::iter::repeat("X").take(1024 * 1024).collect();
    ///
    /// // Note that we don't have to use the input as the parameter in the ID
    /// group.bench_with_input(BenchmarkId::new("Test long string", "1MB X's"), &input, |b, i| {
    ///     b.iter(|| i.len())
    /// });
    /// ```
    pub fn new<S: Into<String>, P: ::std::fmt::Display>(
        function_name: S,
        parameter: P,
    ) -> BenchmarkId {
        BenchmarkId {
            function_name: Some(function_name.into()),
            parameter: Some(format!("{}", parameter)),
        }
    }

File: criterion.rs/src/benchmark_group.rs
Start Line: 446
End Line: 470
Chunks:

    /// Construct a new benchmark ID from just a parameter value. Use this when benchmarking a
    /// single function with a variety of different inputs.
    pub fn from_parameter<P: ::std::fmt::Display>(parameter: P) -> BenchmarkId {
        BenchmarkId {
            function_name: None,
            parameter: Some(format!("{}", parameter)),
        }
    }

    pub(crate) fn no_function() -> BenchmarkId {
        BenchmarkId {
            function_name: None,
            parameter: None,
        }
    }

    pub(crate) fn no_function_with_input<P: ::std::fmt::Display>(parameter: P) -> BenchmarkId {
        BenchmarkId {
            function_name: None,
            parameter: Some(format!("{}", parameter)),
        }
    }
}

File: criterion.rs/src/benchmark_group.rs
Start Line: 470
End Line: 500
Chunks:

mod private {
    pub trait Sealed {}
    impl Sealed for super::BenchmarkId {}
    impl<S: Into<String>> Sealed for S {}
}

/// Sealed trait which allows users to automatically convert strings to benchmark IDs.
pub trait IntoBenchmarkId: private::Sealed {
    fn into_benchmark_id(self) -> BenchmarkId;
}
impl IntoBenchmarkId for BenchmarkId {
    fn into_benchmark_id(self) -> BenchmarkId {
        self
    }
}
impl<S: Into<String>> IntoBenchmarkId for S {
    fn into_benchmark_id(self) -> BenchmarkId {
        let function_name = self.into();
        assert!(
            !function_name.is_empty(),
            "Function name must not be empty."
        );

        BenchmarkId {
            function_name: Some(function_name),
            parameter: None,
        }
    }
}

Ripgrep filtered Lines: [0, 48, 82]
File: criterion.rs/src/error.rs
Start Line: 0
End Line: 47
Chunks:
#[cfg(feature = "csv_output")]
use csv::Error as CsvError;
use serde_json::Error as SerdeError;
use std::error::Error as StdError;
use std::fmt;
use std::io;
use std::path::PathBuf;

#[allow(clippy::enum_variant_names)]
#[derive(Debug)]
pub enum Error {
    AccessError {
        path: PathBuf,
        inner: io::Error,
    },
    CopyError {
        from: PathBuf,
        to: PathBuf,
        inner: io::Error,
    },
    SerdeError {
        path: PathBuf,
        inner: SerdeError,
    },
    #[cfg(feature = "csv_output")]
    /// This API requires the following crate features to be activated: csv_output
    CsvError(CsvError),
}
impl fmt::Display for Error {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        match self {
            Error::AccessError { path, inner } => {
                write!(f, "Failed to access file {:?}: {}", path, inner)
            }
            Error::CopyError { from, to, inner } => {
                write!(f, "Failed to copy file {:?} to {:?}: {}", from, to, inner)
            }
            Error::SerdeError { path, inner } => write!(
                f,
                "Failed to read or write file {:?} due to serialization error: {}",
                path, inner
            ),
            #[cfg(feature = "csv_output")]
            Error::CsvError(inner) => write!(f, "CSV error: {}", inner),
        }
    }
}

File: criterion.rs/src/error.rs
Start Line: 47
End Line: 81
Chunks:
impl StdError for Error {
    fn description(&self) -> &str {
        match self {
            Error::AccessError { .. } => "AccessError",
            Error::CopyError { .. } => "CopyError",
            Error::SerdeError { .. } => "SerdeError",
            #[cfg(feature = "csv_output")]
            Error::CsvError(_) => "CsvError",
        }
    }

    fn cause(&self) -> Option<&dyn StdError> {
        match self {
            Error::AccessError { inner, .. } => Some(inner),
            Error::CopyError { inner, .. } => Some(inner),
            Error::SerdeError { inner, .. } => Some(inner),
            #[cfg(feature = "csv_output")]
            Error::CsvError(inner) => Some(inner),
        }
    }
}

#[cfg(feature = "csv_output")]
impl From<CsvError> for Error {
    fn from(other: CsvError) -> Error {
        Error::CsvError(other)
    }
}

pub type Result<T> = ::std::result::Result<T, Error>;

pub(crate) fn log_error(e: &Error) {
    error!("error: {}", e);
}

Ripgrep filtered Lines: [0, 50, 87, 113]
File: criterion.rs/src/fs.rs
Start Line: 0
End Line: 49
Chunks:
use serde::de::DeserializeOwned;
use serde::Serialize;
use std::ffi::OsStr;
use std::fs::{self, File};
use std::io::Read;
use std::path::Path;
use walkdir::{DirEntry, WalkDir};

use crate::error::{Error, Result};
use crate::report::BenchmarkId;

pub fn load<A, P: ?Sized>(path: &P) -> Result<A>
where
    A: DeserializeOwned,
    P: AsRef<Path>,
{
    let path = path.as_ref();
    let mut f = File::open(path).map_err(|inner| Error::AccessError {
        inner,
        path: path.to_owned(),
    })?;
    let mut string = String::new();
    let _ = f.read_to_string(&mut string);
    let result: A = serde_json::from_str(string.as_str()).map_err(|inner| Error::SerdeError {
        inner,
        path: path.to_owned(),
    })?;

    Ok(result)
}

pub fn is_dir<P>(path: &P) -> bool
where
    P: AsRef<Path>,
{
    let path: &Path = path.as_ref();
    path.is_dir()
}

pub fn mkdirp<P>(path: &P) -> Result<()>
where
    P: AsRef<Path>,
{
    fs::create_dir_all(path.as_ref()).map_err(|inner| Error::AccessError {
        inner,
        path: path.as_ref().to_owned(),
    })?;
    Ok(())
}

File: criterion.rs/src/fs.rs
Start Line: 49
End Line: 86
Chunks:

pub fn cp(from: &Path, to: &Path) -> Result<()> {
    fs::copy(from, to).map_err(|inner| Error::CopyError {
        inner,
        from: from.to_owned(),
        to: to.to_owned(),
    })?;
    Ok(())
}

pub fn save<D, P>(data: &D, path: &P) -> Result<()>
where
    D: Serialize,
    P: AsRef<Path>,
{
    let buf = serde_json::to_string(&data).map_err(|inner| Error::SerdeError {
        path: path.as_ref().to_owned(),
        inner,
    })?;
    save_string(&buf, path)
}

pub fn save_string<P>(data: &str, path: &P) -> Result<()>
where
    P: AsRef<Path>,
{
    use std::io::Write;

    File::create(path)
        .and_then(|mut f| f.write_all(data.as_bytes()))
        .map_err(|inner| Error::AccessError {
            inner,
            path: path.as_ref().to_owned(),
        })?;

    Ok(())
}

File: criterion.rs/src/fs.rs
Start Line: 86
End Line: 112
Chunks:

pub fn list_existing_benchmarks<P>(directory: &P) -> Result<Vec<BenchmarkId>>
where
    P: AsRef<Path>,
{
    fn is_benchmark(entry: &DirEntry) -> bool {
        // Look for benchmark.json files inside folders named "new" (because we want to ignore
        // the baselines)
        entry.file_name() == OsStr::new("benchmark.json")
            && entry.path().parent().unwrap().file_name().unwrap() == OsStr::new("new")
    }

    let mut ids = vec![];

    for entry in WalkDir::new(directory)
        .into_iter()
        // Ignore errors.
        .filter_map(::std::result::Result::ok)
        .filter(is_benchmark)
    {
        let id: BenchmarkId = load(entry.path())?;
        ids.push(id);
    }

    Ok(ids)
}

Ripgrep filtered Lines: [0, 49, 81, 103, 132, 179, 229, 256, 284]
File: criterion.rs/src/routine.rs
Start Line: 0
End Line: 48
Chunks:
use crate::benchmark::BenchmarkConfig;
use crate::connection::OutgoingMessage;
use crate::measurement::Measurement;
use crate::report::{BenchmarkId, Report, ReportContext};
use crate::{black_box, ActualSamplingMode, Bencher, Criterion};
use std::marker::PhantomData;
use std::time::Duration;

/// PRIVATE
pub(crate) trait Routine<M: Measurement, T: ?Sized> {
    /// PRIVATE
    fn bench(&mut self, m: &M, iters: &[u64], parameter: &T) -> Vec<f64>;
    /// PRIVATE
    fn warm_up(&mut self, m: &M, how_long: Duration, parameter: &T) -> (u64, u64);

    /// PRIVATE
    fn test(&mut self, m: &M, parameter: &T) {
        self.bench(m, &[1u64], parameter);
    }

    /// Iterates the benchmarked function for a fixed length of time, but takes no measurements.
    /// This keeps the overall benchmark suite runtime constant-ish even when running under a
    /// profiler with an unknown amount of overhead. Since no measurements are taken, it also
    /// reduces the amount of time the execution spends in Criterion.rs code, which should help
    /// show the performance of the benchmarked code more clearly as well.
    fn profile(
        &mut self,
        measurement: &M,
        id: &BenchmarkId,
        criterion: &Criterion<M>,
        report_context: &ReportContext,
        time: Duration,
        parameter: &T,
    ) {
        criterion
            .report
            .profile(id, report_context, time.as_nanos() as f64);

        let mut profile_path = report_context.output_directory.clone();
        if (*crate::CARGO_CRITERION_CONNECTION).is_some() {
            // If connected to cargo-criterion, generate a cargo-criterion-style path.
            // This is kind of a hack.
            profile_path.push("profile");
            profile_path.push(id.as_directory_name());
        } else {
            profile_path.push(id.as_directory_name());
            profile_path.push("profile");
        }

File: criterion.rs/src/routine.rs
Start Line: 48
End Line: 80
Chunks:
        criterion
            .profiler
            .borrow_mut()
            .start_profiling(id.id(), &profile_path);

        let time = time.as_nanos() as u64;

        // TODO: Some profilers will show the two batches of iterations as
        // being different code-paths even though they aren't really.

        // Get the warmup time for one second
        let (wu_elapsed, wu_iters) = self.warm_up(measurement, Duration::from_secs(1), parameter);
        if wu_elapsed < time {
            // Initial guess for the mean execution time
            let met = wu_elapsed as f64 / wu_iters as f64;

            // Guess how many iterations will be required for the remaining time
            let remaining = (time - wu_elapsed) as f64;

            let iters = remaining / met;
            let iters = iters as u64;

            self.bench(measurement, &[iters], parameter);
        }

        criterion
            .profiler
            .borrow_mut()
            .stop_profiling(id.id(), &profile_path);

        criterion.report.terminated(id, report_context);
    }

File: criterion.rs/src/routine.rs
Start Line: 80
End Line: 102
Chunks:

    fn sample(
        &mut self,
        measurement: &M,
        id: &BenchmarkId,
        config: &BenchmarkConfig,
        criterion: &Criterion<M>,
        report_context: &ReportContext,
        parameter: &T,
    ) -> (ActualSamplingMode, Box<[f64]>, Box<[f64]>) {
        if config.quick_mode {
            let minimum_bench_duration = Duration::from_millis(100);
            let maximum_bench_duration = config.measurement_time; // default: 5 seconds
            let target_rel_stdev = config.significance_level; // default: 5%, 0.05

            use std::time::Instant;
            let time_start = Instant::now();

            let sq = |val| val * val;
            let mut n = 1;
            let mut t_prev = *self.bench(measurement, &[n], parameter).first().unwrap();


File: criterion.rs/src/routine.rs
Start Line: 102
End Line: 131
Chunks:
            // Early exit for extremely long running benchmarks:
            if time_start.elapsed() > maximum_bench_duration {
                let iters = vec![n as f64, n as f64].into_boxed_slice();
                // prevent gnuplot bug when all values are equal
                let elapsed = vec![t_prev, t_prev + 0.000001].into_boxed_slice();
                return (ActualSamplingMode::Flat, iters, elapsed);
            }

            // Main data collection loop.
            loop {
                let t_now = *self
                    .bench(measurement, &[n * 2], parameter)
                    .first()
                    .unwrap();
                let t = (t_prev + 2. * t_now) / 5.;
                let stdev = (sq(t_prev - t) + sq(t_now - 2. * t)).sqrt();
                // println!("Sample: {} {:.2}", n, stdev / t);
                let elapsed = time_start.elapsed();
                if (stdev < target_rel_stdev * t && elapsed > minimum_bench_duration)
                    || elapsed > maximum_bench_duration
                {
                    let iters = vec![n as f64, (n * 2) as f64].into_boxed_slice();
                    let elapsed = vec![t_prev, t_now].into_boxed_slice();
                    return (ActualSamplingMode::Linear, iters, elapsed);
                }
                n *= 2;
                t_prev = t_now;
            }
        }

File: criterion.rs/src/routine.rs
Start Line: 131
End Line: 178
Chunks:
        let wu = config.warm_up_time;
        let m_ns = config.measurement_time.as_nanos();

        criterion
            .report
            .warmup(id, report_context, wu.as_nanos() as f64);

        if let Some(conn) = &criterion.connection {
            conn.send(&OutgoingMessage::Warmup {
                id: id.into(),
                nanos: wu.as_nanos() as f64,
            })
            .unwrap();
        }

        let (wu_elapsed, wu_iters) = self.warm_up(measurement, wu, parameter);
        if crate::debug_enabled() {
            println!(
                "\nCompleted {} iterations in {} nanoseconds, estimated execution time is {} ns",
                wu_iters,
                wu_elapsed,
                wu_elapsed as f64 / wu_iters as f64
            );
        }

        // Initial guess for the mean execution time
        let met = wu_elapsed as f64 / wu_iters as f64;

        let n = config.sample_size as u64;

        let actual_sampling_mode = config
            .sampling_mode
            .choose_sampling_mode(met, n, m_ns as f64);

        let m_iters = actual_sampling_mode.iteration_counts(met, n, &config.measurement_time);

        let expected_ns = m_iters
            .iter()
            .copied()
            .map(|count| count as f64 * met)
            .sum();

        // Use saturating_add to handle overflow.
        let mut total_iters = 0u64;
        for count in m_iters.iter().copied() {
            total_iters = total_iters.saturating_add(count);
        }

File: criterion.rs/src/routine.rs
Start Line: 178
End Line: 228
Chunks:

        criterion
            .report
            .measurement_start(id, report_context, n, expected_ns, total_iters);

        if let Some(conn) = &criterion.connection {
            conn.send(&OutgoingMessage::MeasurementStart {
                id: id.into(),
                sample_count: n,
                estimate_ns: expected_ns,
                iter_count: total_iters,
            })
            .unwrap();
        }

        let m_elapsed = self.bench(measurement, &m_iters, parameter);

        let m_iters_f: Vec<f64> = m_iters.iter().map(|&x| x as f64).collect();

        (
            actual_sampling_mode,
            m_iters_f.into_boxed_slice(),
            m_elapsed.into_boxed_slice(),
        )
    }
}

pub struct Function<M: Measurement, F, T>
where
    F: FnMut(&mut Bencher<'_, M>, &T),
    T: ?Sized,
{
    f: F,
    // TODO: Is there some way to remove these?
    _phantom: PhantomData<T>,
    _phamtom2: PhantomData<M>,
}
impl<M: Measurement, F, T> Function<M, F, T>
where
    F: FnMut(&mut Bencher<'_, M>, &T),
    T: ?Sized,
{
    pub fn new(f: F) -> Function<M, F, T> {
        Function {
            f,
            _phantom: PhantomData,
            _phamtom2: PhantomData,
        }
    }
}

File: criterion.rs/src/routine.rs
Start Line: 228
End Line: 255
Chunks:

impl<M: Measurement, F, T> Routine<M, T> for Function<M, F, T>
where
    F: FnMut(&mut Bencher<'_, M>, &T),
    T: ?Sized,
{
    fn bench(&mut self, m: &M, iters: &[u64], parameter: &T) -> Vec<f64> {
        let f = &mut self.f;

        let mut b = Bencher {
            iterated: false,
            iters: 0,
            value: m.zero(),
            measurement: m,
            elapsed_time: Duration::from_millis(0),
        };

        iters
            .iter()
            .map(|iters| {
                b.iters = *iters;
                (*f)(&mut b, black_box(parameter));
                b.assert_iterated();
                m.to_f64(&b.value)
            })
            .collect()
    }

File: criterion.rs/src/routine.rs
Start Line: 255
End Line: 283
Chunks:

    fn warm_up(&mut self, m: &M, how_long: Duration, parameter: &T) -> (u64, u64) {
        let f = &mut self.f;
        let mut b = Bencher {
            iterated: false,
            iters: 1,
            value: m.zero(),
            measurement: m,
            elapsed_time: Duration::from_millis(0),
        };

        let mut total_iters = 0;
        let mut elapsed_time = Duration::from_millis(0);
        loop {
            (*f)(&mut b, black_box(parameter));

            b.assert_iterated();

            total_iters += b.iters;
            elapsed_time += b.elapsed_time;
            if elapsed_time > how_long {
                return (elapsed_time.as_nanos() as u64, total_iters);
            }

            b.iters = b.iters.wrapping_mul(2);
        }
    }
}

Ripgrep filtered Lines: [0, 35, 65, 104, 126, 172, 213, 240]
File: criterion.rs/src/measurement.rs
Start Line: 0
End Line: 34
Chunks:
//! This module defines a set of traits that can be used to plug different measurements (eg.
//! Unix's Processor Time, CPU or GPU performance counters, etc.) into Criterion.rs. It also
//! includes the [WallTime](struct.WallTime.html) struct which defines the default wall-clock time
//! measurement.

use crate::format::short;
use crate::Throughput;
use std::time::{Duration, Instant};

/// Trait providing functions to format measured values to string so that they can be displayed on
/// the command line or in the reports. The functions of this trait take measured values in f64
/// form; implementors can assume that the values are of the same scale as those produced by the
/// associated [MeasuredValue](trait.MeasuredValue.html) (eg. if your measurement produces values in
/// nanoseconds, the values passed to the formatter will be in nanoseconds).
///
/// Implementors are encouraged to format the values in a way that is intuitive for humans and
/// uses the SI prefix system. For example, the format used by [WallTime](struct.WallTime.html)
/// can display the value in units ranging from picoseconds to seconds depending on the magnitude
/// of the elapsed time in nanoseconds.
pub trait ValueFormatter {
    /// Format the value (with appropriate unit) and return it as a string.
    fn format_value(&self, value: f64) -> String {
        let mut values = [value];
        let unit = self.scale_values(value, &mut values);
        format!("{:>6} {}", short(values[0]), unit)
    }

    /// Format the value as a throughput measurement. The value represents the measurement value;
    /// the implementor will have to calculate bytes per second, iterations per cycle, etc.
    fn format_throughput(&self, throughput: &Throughput, value: f64) -> String {
        let mut values = [value];
        let unit = self.scale_throughputs(value, throughput, &mut values);
        format!("{:>6} {}", short(values[0]), unit)
    }

File: criterion.rs/src/measurement.rs
Start Line: 34
End Line: 64
Chunks:

    /// Scale the given values to some appropriate unit and return the unit string.
    ///
    /// The given typical value should be used to choose the unit. This function may be called
    /// multiple times with different datasets; the typical value will remain the same to ensure
    /// that the units remain consistent within a graph. The typical value will not be NaN.
    /// Values will not contain NaN as input, and the transformed values must not contain NaN.
    fn scale_values(&self, typical_value: f64, values: &mut [f64]) -> &'static str;

    /// Convert the given measured values into throughput numbers based on the given throughput
    /// value, scale them to some appropriate unit, and return the unit string.
    ///
    /// The given typical value should be used to choose the unit. This function may be called
    /// multiple times with different datasets; the typical value will remain the same to ensure
    /// that the units remain consistent within a graph. The typical value will not be NaN.
    /// Values will not contain NaN as input, and the transformed values must not contain NaN.
    fn scale_throughputs(
        &self,
        typical_value: f64,
        throughput: &Throughput,
        values: &mut [f64],
    ) -> &'static str;

    /// Scale the values and return a unit string designed for machines.
    ///
    /// For example, this is used for the CSV file output. Implementations should modify the given
    /// values slice to apply the desired scaling (if any) and return a string representing the unit
    /// the modified values are in.
    fn scale_for_machines(&self, values: &mut [f64]) -> &'static str;
}

File: criterion.rs/src/measurement.rs
Start Line: 64
End Line: 103
Chunks:

/// Trait for all types which define something Criterion.rs can measure. The only measurement
/// currently provided is [WallTime](struct.WallTime.html), but third party crates or benchmarks
/// may define more.
///
/// This trait defines two core methods, `start` and `end`. `start` is called at the beginning of
/// a measurement to produce some intermediate value (for example, the wall-clock time at the start
/// of that set of iterations) and `end` is called at the end of the measurement with the value
/// returned by `start`.
///
pub trait Measurement {
    /// This type represents an intermediate value for the measurements. It will be produced by the
    /// start function and passed to the end function. An example might be the wall-clock time as
    /// of the `start` call.
    type Intermediate;

    /// This type is the measured value. An example might be the elapsed wall-clock time between the
    /// `start` and `end` calls.
    type Value;

    /// Criterion.rs will call this before iterating the benchmark.
    fn start(&self) -> Self::Intermediate;

    /// Criterion.rs will call this after iterating the benchmark to get the measured value.
    fn end(&self, i: Self::Intermediate) -> Self::Value;

    /// Combine two values. Criterion.rs sometimes needs to perform measurements in multiple batches
    /// of iterations, so the value from one batch must be added to the sum of the previous batches.
    fn add(&self, v1: &Self::Value, v2: &Self::Value) -> Self::Value;

    /// Return a "zero" value for the Value type which can be added to another value.
    fn zero(&self) -> Self::Value;

    /// Converts the measured value to f64 so that it can be used in statistical analysis.
    fn to_f64(&self, value: &Self::Value) -> f64;

    /// Return a trait-object reference to the value formatter for this measurement.
    fn formatter(&self) -> &dyn ValueFormatter;
}

File: criterion.rs/src/measurement.rs
Start Line: 103
End Line: 125
Chunks:

pub(crate) struct DurationFormatter;
impl DurationFormatter {
    fn bytes_per_second(&self, bytes: f64, typical: f64, values: &mut [f64]) -> &'static str {
        let bytes_per_second = bytes * (1e9 / typical);
        let (denominator, unit) = if bytes_per_second < 1024.0 {
            (1.0, "  B/s")
        } else if bytes_per_second < 1024.0 * 1024.0 {
            (1024.0, "KiB/s")
        } else if bytes_per_second < 1024.0 * 1024.0 * 1024.0 {
            (1024.0 * 1024.0, "MiB/s")
        } else {
            (1024.0 * 1024.0 * 1024.0, "GiB/s")
        };

        for val in values {
            let bytes_per_second = bytes * (1e9 / *val);
            *val = bytes_per_second / denominator;
        }

        unit
    }

File: criterion.rs/src/measurement.rs
Start Line: 125
End Line: 171
Chunks:

    fn bytes_per_second_decimal(
        &self,
        bytes: f64,
        typical: f64,
        values: &mut [f64],
    ) -> &'static str {
        let bytes_per_second = bytes * (1e9 / typical);
        let (denominator, unit) = if bytes_per_second < 1000.0 {
            (1.0, "  B/s")
        } else if bytes_per_second < 1000.0 * 1000.0 {
            (1000.0, "KB/s")
        } else if bytes_per_second < 1000.0 * 1000.0 * 1000.0 {
            (1000.0 * 1000.0, "MB/s")
        } else {
            (1000.0 * 1000.0 * 1000.0, "GB/s")
        };

        for val in values {
            let bytes_per_second = bytes * (1e9 / *val);
            *val = bytes_per_second / denominator;
        }

        unit
    }

    fn elements_per_second(&self, elems: f64, typical: f64, values: &mut [f64]) -> &'static str {
        let elems_per_second = elems * (1e9 / typical);
        let (denominator, unit) = if elems_per_second < 1000.0 {
            (1.0, " elem/s")
        } else if elems_per_second < 1000.0 * 1000.0 {
            (1000.0, "Kelem/s")
        } else if elems_per_second < 1000.0 * 1000.0 * 1000.0 {
            (1000.0 * 1000.0, "Melem/s")
        } else {
            (1000.0 * 1000.0 * 1000.0, "Gelem/s")
        };

        for val in values {
            let elems_per_second = elems * (1e9 / *val);
            *val = elems_per_second / denominator;
        }

        unit
    }
}

File: criterion.rs/src/measurement.rs
Start Line: 171
End Line: 212
Chunks:
impl ValueFormatter for DurationFormatter {
    fn scale_throughputs(
        &self,
        typical: f64,
        throughput: &Throughput,
        values: &mut [f64],
    ) -> &'static str {
        match *throughput {
            Throughput::Bytes(bytes) => self.bytes_per_second(bytes as f64, typical, values),
            Throughput::BytesDecimal(bytes) => {
                self.bytes_per_second_decimal(bytes as f64, typical, values)
            }
            Throughput::Elements(elems) => self.elements_per_second(elems as f64, typical, values),
        }
    }

    fn scale_values(&self, ns: f64, values: &mut [f64]) -> &'static str {
        let (factor, unit) = if ns < 10f64.powi(0) {
            (10f64.powi(3), "ps")
        } else if ns < 10f64.powi(3) {
            (10f64.powi(0), "ns")
        } else if ns < 10f64.powi(6) {
            (10f64.powi(-3), "s")
        } else if ns < 10f64.powi(9) {
            (10f64.powi(-6), "ms")
        } else {
            (10f64.powi(-9), "s")
        };

        for val in values {
            *val *= factor;
        }

        unit
    }

    fn scale_for_machines(&self, _values: &mut [f64]) -> &'static str {
        // no scaling is needed
        "ns"
    }
}

File: criterion.rs/src/measurement.rs
Start Line: 212
End Line: 239
Chunks:

/// `WallTime` is the default measurement in Criterion.rs. It measures the elapsed time from the
/// beginning of a series of iterations to the end.
pub struct WallTime;
impl Measurement for WallTime {
    type Intermediate = Instant;
    type Value = Duration;

    fn start(&self) -> Self::Intermediate {
        Instant::now()
    }
    fn end(&self, i: Self::Intermediate) -> Self::Value {
        i.elapsed()
    }
    fn add(&self, v1: &Self::Value, v2: &Self::Value) -> Self::Value {
        *v1 + *v2
    }
    fn zero(&self) -> Self::Value {
        Duration::from_secs(0)
    }
    fn to_f64(&self, val: &Self::Value) -> f64 {
        val.as_nanos() as f64
    }
    fn formatter(&self) -> &dyn ValueFormatter {
        &DurationFormatter
    }
}

Ripgrep filtered Lines: [0, 35, 62, 111, 158, 182, 220, 249, 298, 338, 371]
File: criterion.rs/src/analysis/mod.rs
Start Line: 0
End Line: 34
Chunks:
use std::path::Path;

use crate::stats::bivariate::regression::Slope;
use crate::stats::bivariate::Data;
use crate::stats::univariate::outliers::tukey;
use crate::stats::univariate::Sample;
use crate::stats::{Distribution, Tails};

use crate::benchmark::BenchmarkConfig;
use crate::connection::OutgoingMessage;
use crate::estimate::{
    build_estimates, ConfidenceInterval, Distributions, Estimate, Estimates, PointEstimates,
};
use crate::fs;
use crate::measurement::Measurement;
use crate::report::{BenchmarkId, Report, ReportContext};
use crate::routine::Routine;
use crate::{Baseline, Criterion, SavedSample, Throughput};

macro_rules! elapsed {
    ($msg:expr, $block:expr) => {{
        let start = ::std::time::Instant::now();
        let out = $block;
        let elapsed = &start.elapsed();

        info!(
            "{} took {}",
            $msg,
            crate::format::time(elapsed.as_nanos() as f64)
        );

        out
    }};
}

File: criterion.rs/src/analysis/mod.rs
Start Line: 34
End Line: 61
Chunks:

mod compare;

// Common analysis procedure
pub(crate) fn common<M: Measurement, T: ?Sized>(
    id: &BenchmarkId,
    routine: &mut dyn Routine<M, T>,
    config: &BenchmarkConfig,
    criterion: &Criterion<M>,
    report_context: &ReportContext,
    parameter: &T,
    throughput: Option<Throughput>,
) {
    criterion.report.benchmark_start(id, report_context);

    if let Baseline::CompareStrict = criterion.baseline {
        if !base_dir_exists(
            id,
            &criterion.baseline_directory,
            &criterion.output_directory,
        ) {
            panic!(
                "Baseline '{base}' must exist before comparison is allowed; try --save-baseline {base}",
                base=criterion.baseline_directory,
            );
        }
    }

File: criterion.rs/src/analysis/mod.rs
Start Line: 61
End Line: 110
Chunks:

    let (sampling_mode, iters, times);
    if let Some(baseline) = &criterion.load_baseline {
        let mut sample_path = criterion.output_directory.clone();
        sample_path.push(id.as_directory_name());
        sample_path.push(baseline);
        sample_path.push("sample.json");
        let loaded = fs::load::<SavedSample, _>(&sample_path);

        match loaded {
            Err(err) => panic!(
                "Baseline '{base}' must exist before it can be loaded; try --save-baseline {base}. Error: {err}",
                base = baseline, err = err
            ),
            Ok(samples) => {
                sampling_mode = samples.sampling_mode;
                iters = samples.iters.into_boxed_slice();
                times = samples.times.into_boxed_slice();
            }
        }
    } else {
        let sample = routine.sample(
            &criterion.measurement,
            id,
            config,
            criterion,
            report_context,
            parameter,
        );
        sampling_mode = sample.0;
        iters = sample.1;
        times = sample.2;

        if let Some(conn) = &criterion.connection {
            conn.send(&OutgoingMessage::MeasurementComplete {
                id: id.into(),
                iters: &iters,
                times: &times,
                plot_config: (&report_context.plot_config).into(),
                sampling_method: sampling_mode.into(),
                benchmark_config: config.into(),
            })
            .unwrap();

            conn.serve_value_formatter(criterion.measurement.formatter())
                .unwrap();
            return;
        }
    }

File: criterion.rs/src/analysis/mod.rs
Start Line: 110
End Line: 157
Chunks:

    criterion.report.analysis(id, report_context);

    if times.iter().any(|&f| f == 0.0) {
        error!(
            "At least one measurement of benchmark {} took zero time per \
            iteration. This should not be possible. If using iter_custom, please verify \
            that your routine is correctly measured.",
            id.as_title()
        );
        return;
    }

    let avg_times = iters
        .iter()
        .zip(times.iter())
        .map(|(&iters, &elapsed)| elapsed / iters)
        .collect::<Vec<f64>>();
    let avg_times = Sample::new(&avg_times);

    if criterion.should_save_baseline() {
        log_if_err!({
            let mut new_dir = criterion.output_directory.clone();
            new_dir.push(id.as_directory_name());
            new_dir.push("new");
            fs::mkdirp(&new_dir)
        });
    }

    let data = Data::new(&iters, &times);
    let labeled_sample = tukey::classify(avg_times);
    if criterion.should_save_baseline() {
        log_if_err!({
            let mut tukey_file = criterion.output_directory.to_owned();
            tukey_file.push(id.as_directory_name());
            tukey_file.push("new");
            tukey_file.push("tukey.json");
            fs::save(&labeled_sample.fences(), &tukey_file)
        });
    }
    let (mut distributions, mut estimates) = estimates(avg_times, config);
    if sampling_mode.is_linear() {
        let (distribution, slope) = regression(&data, config);

        estimates.slope = Some(slope);
        distributions.slope = Some(distribution);
    }

File: criterion.rs/src/analysis/mod.rs
Start Line: 157
End Line: 181
Chunks:

    if criterion.should_save_baseline() {
        log_if_err!({
            let mut sample_file = criterion.output_directory.clone();
            sample_file.push(id.as_directory_name());
            sample_file.push("new");
            sample_file.push("sample.json");
            fs::save(
                &SavedSample {
                    sampling_mode,
                    iters: data.x().as_ref().to_vec(),
                    times: data.y().as_ref().to_vec(),
                },
                &sample_file,
            )
        });
        log_if_err!({
            let mut estimates_file = criterion.output_directory.clone();
            estimates_file.push(id.as_directory_name());
            estimates_file.push("new");
            estimates_file.push("estimates.json");
            fs::save(&estimates, &estimates_file)
        });
    }

File: criterion.rs/src/analysis/mod.rs
Start Line: 181
End Line: 219
Chunks:

    let compare_data = if base_dir_exists(
        id,
        &criterion.baseline_directory,
        &criterion.output_directory,
    ) {
        let result = compare::common(id, avg_times, config, criterion);
        match result {
            Ok((
                t_value,
                t_distribution,
                relative_estimates,
                relative_distributions,
                base_iter_counts,
                base_sample_times,
                base_avg_times,
                base_estimates,
            )) => {
                let p_value = t_distribution.p_value(t_value, &Tails::Two);
                Some(crate::report::ComparisonData {
                    p_value,
                    t_distribution,
                    t_value,
                    relative_estimates,
                    relative_distributions,
                    significance_threshold: config.significance_level,
                    noise_threshold: config.noise_threshold,
                    base_iter_counts,
                    base_sample_times,
                    base_avg_times,
                    base_estimates,
                })
            }
            Err(e) => {
                crate::error::log_error(&e);
                None
            }
        }

File: criterion.rs/src/analysis/mod.rs
Start Line: 219
End Line: 248
Chunks:
    } else {
        None
    };

    let measurement_data = crate::report::MeasurementData {
        data: Data::new(&iters, &times),
        avg_times: labeled_sample,
        absolute_estimates: estimates,
        distributions,
        comparison: compare_data,
        throughput,
    };

    criterion.report.measurement_complete(
        id,
        report_context,
        &measurement_data,
        criterion.measurement.formatter(),
    );

    if criterion.should_save_baseline() {
        log_if_err!({
            let mut benchmark_file = criterion.output_directory.clone();
            benchmark_file.push(id.as_directory_name());
            benchmark_file.push("new");
            benchmark_file.push("benchmark.json");
            fs::save(&id, &benchmark_file)
        });
    }

File: criterion.rs/src/analysis/mod.rs
Start Line: 248
End Line: 297
Chunks:

    if criterion.connection.is_none() {
        if let Baseline::Save = criterion.baseline {
            copy_new_dir_to_base(
                id.as_directory_name(),
                &criterion.baseline_directory,
                &criterion.output_directory,
            );
        }
    }
}

fn base_dir_exists(id: &BenchmarkId, baseline: &str, output_directory: &Path) -> bool {
    let mut base_dir = output_directory.to_owned();
    base_dir.push(id.as_directory_name());
    base_dir.push(baseline);
    base_dir.exists()
}

// Performs a simple linear regression on the sample
fn regression(
    data: &Data<'_, f64, f64>,
    config: &BenchmarkConfig,
) -> (Distribution<f64>, Estimate) {
    let cl = config.confidence_level;

    let distribution = elapsed!(
        "Bootstrapped linear regression",
        data.bootstrap(config.nresamples, |d| (Slope::fit(&d).0,))
    )
    .0;

    let point = Slope::fit(data);
    let (lb, ub) = distribution.confidence_interval(config.confidence_level);
    let se = distribution.std_dev(None);

    (
        distribution,
        Estimate {
            confidence_interval: ConfidenceInterval {
                confidence_level: cl,
                lower_bound: lb,
                upper_bound: ub,
            },
            point_estimate: point.0,
            standard_error: se,
        },
    )
}

File: criterion.rs/src/analysis/mod.rs
Start Line: 297
End Line: 337
Chunks:

// Estimates the statistics of the population from the sample
fn estimates(avg_times: &Sample<f64>, config: &BenchmarkConfig) -> (Distributions, Estimates) {
    fn stats(sample: &Sample<f64>) -> (f64, f64, f64, f64) {
        let mean = sample.mean();
        let std_dev = sample.std_dev(Some(mean));
        let median = sample.percentiles().median();
        let mad = sample.median_abs_dev(Some(median));

        (mean, std_dev, median, mad)
    }

    let cl = config.confidence_level;
    let nresamples = config.nresamples;

    let (mean, std_dev, median, mad) = stats(avg_times);
    let points = PointEstimates {
        mean,
        median,
        std_dev,
        median_abs_dev: mad,
    };

    let (dist_mean, dist_stddev, dist_median, dist_mad) = elapsed!(
        "Bootstrapping the absolute statistics.",
        avg_times.bootstrap(nresamples, stats)
    );

    let distributions = Distributions {
        mean: dist_mean,
        slope: None,
        median: dist_median,
        median_abs_dev: dist_mad,
        std_dev: dist_stddev,
    };

    let estimates = build_estimates(&distributions, &points, cl);

    (distributions, estimates)
}

File: criterion.rs/src/analysis/mod.rs
Start Line: 337
End Line: 370
Chunks:

fn copy_new_dir_to_base(id: &str, baseline: &str, output_directory: &Path) {
    let root_dir = Path::new(output_directory).join(id);
    let base_dir = root_dir.join(baseline);
    let new_dir = root_dir.join("new");

    if !new_dir.exists() {
        return;
    };
    if !base_dir.exists() {
        try_else_return!(fs::mkdirp(&base_dir));
    }

    // TODO: consider using walkdir or similar to generically copy.
    try_else_return!(fs::cp(
        &new_dir.join("estimates.json"),
        &base_dir.join("estimates.json")
    ));
    try_else_return!(fs::cp(
        &new_dir.join("sample.json"),
        &base_dir.join("sample.json")
    ));
    try_else_return!(fs::cp(
        &new_dir.join("tukey.json"),
        &base_dir.join("tukey.json")
    ));
    try_else_return!(fs::cp(
        &new_dir.join("benchmark.json"),
        &base_dir.join("benchmark.json")
    ));
    #[cfg(feature = "csv_output")]
    try_else_return!(fs::cp(&new_dir.join("raw.csv"), &base_dir.join("raw.csv")));
}

Ripgrep filtered Lines: [0, 10, 51, 99, 144]
File: criterion.rs/src/analysis/compare.rs
Start Line: 0
End Line: 9
Chunks:
use crate::stats::univariate::Sample;
use crate::stats::univariate::{self, mixed};
use crate::stats::Distribution;

use crate::benchmark::BenchmarkConfig;
use crate::error::Result;
use crate::estimate::{
    build_change_estimates, ChangeDistributions, ChangeEstimates, ChangePointEstimates, Estimates,
};

File: criterion.rs/src/analysis/compare.rs
Start Line: 9
End Line: 50
Chunks:
use crate::measurement::Measurement;
use crate::report::BenchmarkId;
use crate::{fs, Criterion, SavedSample};

// Common comparison procedure
#[cfg_attr(feature = "cargo-clippy", allow(clippy::type_complexity))]
pub(crate) fn common<M: Measurement>(
    id: &BenchmarkId,
    avg_times: &Sample<f64>,
    config: &BenchmarkConfig,
    criterion: &Criterion<M>,
) -> Result<(
    f64,
    Distribution<f64>,
    ChangeEstimates,
    ChangeDistributions,
    Vec<f64>,
    Vec<f64>,
    Vec<f64>,
    Estimates,
)> {
    let mut sample_file = criterion.output_directory.clone();
    sample_file.push(id.as_directory_name());
    sample_file.push(&criterion.baseline_directory);
    sample_file.push("sample.json");
    let sample: SavedSample = fs::load(&sample_file)?;
    let SavedSample { iters, times, .. } = sample;

    let mut estimates_file = criterion.output_directory.clone();
    estimates_file.push(id.as_directory_name());
    estimates_file.push(&criterion.baseline_directory);
    estimates_file.push("estimates.json");
    let base_estimates: Estimates = fs::load(&estimates_file)?;

    let base_avg_times: Vec<f64> = iters
        .iter()
        .zip(times.iter())
        .map(|(iters, elapsed)| elapsed / iters)
        .collect();
    let base_avg_time_sample = Sample::new(&base_avg_times);


File: criterion.rs/src/analysis/compare.rs
Start Line: 50
End Line: 98
Chunks:
    let mut change_dir = criterion.output_directory.clone();
    change_dir.push(id.as_directory_name());
    change_dir.push("change");
    fs::mkdirp(&change_dir)?;
    let (t_statistic, t_distribution) = t_test(avg_times, base_avg_time_sample, config);

    let (estimates, relative_distributions) =
        estimates(id, avg_times, base_avg_time_sample, config, criterion);
    Ok((
        t_statistic,
        t_distribution,
        estimates,
        relative_distributions,
        iters,
        times,
        base_avg_times.clone(),
        base_estimates,
    ))
}

// Performs a two sample t-test
fn t_test(
    avg_times: &Sample<f64>,
    base_avg_times: &Sample<f64>,
    config: &BenchmarkConfig,
) -> (f64, Distribution<f64>) {
    let nresamples = config.nresamples;

    let t_statistic = avg_times.t(base_avg_times);
    let t_distribution = elapsed!(
        "Bootstrapping the T distribution",
        mixed::bootstrap(avg_times, base_avg_times, nresamples, |a, b| (a.t(b),))
    )
    .0;

    // HACK: Filter out non-finite numbers, which can happen sometimes when sample size is very small.
    // Downstream code doesn't like non-finite values here.
    let t_distribution = Distribution::from(
        t_distribution
            .iter()
            .filter(|a| a.is_finite())
            .cloned()
            .collect::<Vec<_>>()
            .into_boxed_slice(),
    );

    (t_statistic, t_distribution)
}

File: criterion.rs/src/analysis/compare.rs
Start Line: 98
End Line: 143
Chunks:

// Estimates the relative change in the statistics of the population
fn estimates<M: Measurement>(
    id: &BenchmarkId,
    avg_times: &Sample<f64>,
    base_avg_times: &Sample<f64>,
    config: &BenchmarkConfig,
    criterion: &Criterion<M>,
) -> (ChangeEstimates, ChangeDistributions) {
    fn stats(a: &Sample<f64>, b: &Sample<f64>) -> (f64, f64) {
        (
            a.mean() / b.mean() - 1.,
            a.percentiles().median() / b.percentiles().median() - 1.,
        )
    }

    let cl = config.confidence_level;
    let nresamples = config.nresamples;

    let (dist_mean, dist_median) = elapsed!(
        "Bootstrapping the relative statistics",
        univariate::bootstrap(avg_times, base_avg_times, nresamples, stats)
    );

    let distributions = ChangeDistributions {
        mean: dist_mean,
        median: dist_median,
    };

    let (mean, median) = stats(avg_times, base_avg_times);
    let points = ChangePointEstimates { mean, median };

    let estimates = build_change_estimates(&distributions, &points, cl);

    {
        log_if_err!({
            let mut estimates_path = criterion.output_directory.clone();
            estimates_path.push(id.as_directory_name());
            estimates_path.push("change");
            estimates_path.push("estimates.json");
            fs::save(&estimates, &estimates_path)
        });
    }
    (estimates, distributions)
}

Ripgrep filtered Lines: [0, 42]
File: criterion.rs/src/kde.rs
Start Line: 0
End Line: 41
Chunks:
use crate::stats::univariate::kde::kernel::Gaussian;
use crate::stats::univariate::kde::{Bandwidth, Kde};
use crate::stats::univariate::Sample;

pub fn sweep(
    sample: &Sample<f64>,
    npoints: usize,
    range: Option<(f64, f64)>,
) -> (Box<[f64]>, Box<[f64]>) {
    let (xs, ys, _) = sweep_and_estimate(sample, npoints, range, sample[0]);
    (xs, ys)
}

pub fn sweep_and_estimate(
    sample: &Sample<f64>,
    npoints: usize,
    range: Option<(f64, f64)>,
    point_to_estimate: f64,
) -> (Box<[f64]>, Box<[f64]>, f64) {
    let x_min = sample.min();
    let x_max = sample.max();

    let kde = Kde::new(sample, Gaussian, Bandwidth::Silverman);
    let h = kde.bandwidth();

    let (start, end) = match range {
        Some((start, end)) => (start, end),
        None => (x_min - 3. * h, x_max + 3. * h),
    };

    let mut xs: Vec<f64> = Vec::with_capacity(npoints);
    let step_size = (end - start) / (npoints - 1) as f64;
    for n in 0..npoints {
        xs.push(start + (step_size * n as f64));
    }

    let ys = kde.map(&xs);
    let point_estimate = kde.estimate(point_to_estimate);

    (xs.into_boxed_slice(), ys, point_estimate)
}

Ripgrep filtered Lines: [0, 24, 60, 92]
File: criterion.rs/src/csv_report.rs
Start Line: 0
End Line: 23
Chunks:
use crate::error::Result;
use crate::measurement::ValueFormatter;
use crate::report::{BenchmarkId, MeasurementData, Report, ReportContext};
use crate::Throughput;
use csv::Writer;
use std::io::Write;
use std::path::Path;

#[derive(Serialize)]
struct CsvRow<'a> {
    group: &'a str,
    function: Option<&'a str>,
    value: Option<&'a str>,
    throughput_num: Option<&'a str>,
    throughput_type: Option<&'a str>,
    sample_measured_value: f64,
    unit: &'static str,
    iteration_count: u64,
}

struct CsvReportWriter<W: Write> {
    writer: Writer<W>,
}

File: criterion.rs/src/csv_report.rs
Start Line: 23
End Line: 59
Chunks:
impl<W: Write> CsvReportWriter<W> {
    fn write_data(
        &mut self,
        id: &BenchmarkId,
        data: &MeasurementData<'_>,
        formatter: &dyn ValueFormatter,
    ) -> Result<()> {
        let mut data_scaled: Vec<f64> = data.sample_times().as_ref().into();
        let unit = formatter.scale_for_machines(&mut data_scaled);
        let group = id.group_id.as_str();
        let function = id.function_id.as_deref();
        let value = id.value_str.as_deref();
        let (throughput_num, throughput_type) = match id.throughput {
            Some(Throughput::Bytes(bytes)) => (Some(format!("{}", bytes)), Some("bytes")),
            Some(Throughput::BytesDecimal(bytes)) => (Some(format!("{}", bytes)), Some("bytes")),
            Some(Throughput::Elements(elems)) => (Some(format!("{}", elems)), Some("elements")),
            None => (None, None),
        };
        let throughput_num = throughput_num.as_deref();

        for (count, measured_value) in data.iter_counts().iter().zip(data_scaled) {
            let row = CsvRow {
                group,
                function,
                value,
                throughput_num,
                throughput_type,
                sample_measured_value: measured_value,
                unit,
                iteration_count: (*count) as u64,
            };
            self.writer.serialize(row)?;
        }
        Ok(())
    }
}

File: criterion.rs/src/csv_report.rs
Start Line: 59
End Line: 91
Chunks:

pub struct FileCsvReport;
impl FileCsvReport {
    fn write_file(
        &self,
        path: &Path,
        id: &BenchmarkId,
        measurements: &MeasurementData<'_>,
        formatter: &dyn ValueFormatter,
    ) -> Result<()> {
        let writer = Writer::from_path(path)?;
        let mut writer = CsvReportWriter { writer };
        writer.write_data(id, measurements, formatter)?;
        Ok(())
    }
}

impl Report for FileCsvReport {
    fn measurement_complete(
        &self,
        id: &BenchmarkId,
        context: &ReportContext,
        measurements: &MeasurementData<'_>,
        formatter: &dyn ValueFormatter,
    ) {
        let mut path = context.output_directory.clone();
        path.push(id.as_directory_name());
        path.push("new");
        path.push("raw.csv");
        log_if_err!(self.write_file(&path, id, measurements, formatter));
    }
}

Ripgrep filtered Lines: [0, 36, 74, 105, 138]
File: criterion.rs/src/format.rs
Start Line: 0
End Line: 35
Chunks:
pub fn change(pct: f64, signed: bool) -> String {
    if signed {
        format!("{:>+6}%", signed_short(pct * 1e2))
    } else {
        format!("{:>6}%", short(pct * 1e2))
    }
}

pub fn time(ns: f64) -> String {
    if ns < 1.0 {
        format!("{:>6} ps", short(ns * 1e3))
    } else if ns < 10f64.powi(3) {
        format!("{:>6} ns", short(ns))
    } else if ns < 10f64.powi(6) {
        format!("{:>6} s", short(ns / 1e3))
    } else if ns < 10f64.powi(9) {
        format!("{:>6} ms", short(ns / 1e6))
    } else {
        format!("{:>6} s", short(ns / 1e9))
    }
}

pub fn short(n: f64) -> String {
    if n < 10.0 {
        format!("{:.4}", n)
    } else if n < 100.0 {
        format!("{:.3}", n)
    } else if n < 1000.0 {
        format!("{:.2}", n)
    } else if n < 10000.0 {
        format!("{:.1}", n)
    } else {
        format!("{:.0}", n)
    }
}

File: criterion.rs/src/format.rs
Start Line: 35
End Line: 73
Chunks:

fn signed_short(n: f64) -> String {
    let n_abs = n.abs();

    if n_abs < 10.0 {
        format!("{:+.4}", n)
    } else if n_abs < 100.0 {
        format!("{:+.3}", n)
    } else if n_abs < 1000.0 {
        format!("{:+.2}", n)
    } else if n_abs < 10000.0 {
        format!("{:+.1}", n)
    } else {
        format!("{:+.0}", n)
    }
}

pub fn iter_count(iterations: u64) -> String {
    if iterations < 10_000 {
        format!("{} iterations", iterations)
    } else if iterations < 1_000_000 {
        format!("{:.0}k iterations", (iterations as f64) / 1000.0)
    } else if iterations < 10_000_000 {
        format!("{:.1}M iterations", (iterations as f64) / (1000.0 * 1000.0))
    } else if iterations < 1_000_000_000 {
        format!("{:.0}M iterations", (iterations as f64) / (1000.0 * 1000.0))
    } else if iterations < 10_000_000_000 {
        format!(
            "{:.1}B iterations",
            (iterations as f64) / (1000.0 * 1000.0 * 1000.0)
        )
    } else {
        format!(
            "{:.0}B iterations",
            (iterations as f64) / (1000.0 * 1000.0 * 1000.0)
        )
    }
}

File: criterion.rs/src/format.rs
Start Line: 73
End Line: 104
Chunks:

/// Format a number with thousands separators.
// Based on the corresponding libtest functionality, see
// https://github.com/rust-lang/rust/blob/557359f92512ca88b62a602ebda291f17a953002/library/test/src/bench.rs#L87-L109
fn thousands_sep(mut n: u64, sep: char) -> String {
    use std::fmt::Write;
    let mut output = String::new();
    let mut trailing = false;
    for &pow in &[9, 6, 3, 0] {
        let base = 10_u64.pow(pow);
        if pow == 0 || trailing || n / base != 0 {
            if !trailing {
                write!(output, "{}", n / base).unwrap();
            } else {
                write!(output, "{:03}", n / base).unwrap();
            }
            if pow != 0 {
                output.push(sep);
            }
            trailing = true;
        }
        n %= base;
    }

    output
}

/// Format a value as an integer, including thousands-separators.
pub fn integer(n: f64) -> String {
    thousands_sep(n as u64, ',')
}

File: criterion.rs/src/format.rs
Start Line: 104
End Line: 137
Chunks:

#[cfg(test)]
mod test {
    use super::*;

    #[test]
    fn short_max_len() {
        let mut float = 1.0;
        while float < 999_999.9 {
            let string = short(float);
            println!("{}", string);
            assert!(string.len() <= 6);
            float *= 2.0;
        }
    }

    #[test]
    fn signed_short_max_len() {
        let mut float = -1.0;
        while float > -999_999.9 {
            let string = signed_short(float);
            println!("{}", string);
            assert!(string.len() <= 7);
            float *= 2.0;
        }
    }

    #[test]
    fn integer_thousands_sep() {
        let n = 140352319.0;
        assert_eq!(integer(n), "140,352,319");
    }
}

Ripgrep filtered Lines: [0, 48, 93, 135, 185, 235]
File: criterion.rs/src/plot/plotters_backend/regression.rs
Start Line: 0
End Line: 47
Chunks:
use super::*;

use std::path::Path;

use crate::estimate::{ConfidenceInterval, Estimate};
use crate::stats::bivariate::regression::Slope;
use crate::stats::bivariate::Data;

pub(crate) fn regression_figure(
    title: Option<&str>,
    path: &Path,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<(u32, u32)>,
) {
    let slope_estimate = measurements.absolute_estimates.slope.as_ref().unwrap();
    let slope_dist = measurements.distributions.slope.as_ref().unwrap();
    let (lb, ub) =
        slope_dist.confidence_interval(slope_estimate.confidence_interval.confidence_level);

    let data = &measurements.data;
    let (max_iters, typical) = (data.x().max(), data.y().max());
    let mut scaled_y: Vec<f64> = data.y().iter().cloned().collect();
    let unit = formatter.scale_values(typical, &mut scaled_y);
    let scaled_y = Sample::new(&scaled_y);

    let point_estimate = Slope::fit(&measurements.data).0;
    let mut scaled_points = [point_estimate * max_iters, lb * max_iters, ub * max_iters];
    let _ = formatter.scale_values(typical, &mut scaled_points);
    let [point, lb, ub] = scaled_points;

    let exponent = (max_iters.log10() / 3.).floor() as i32 * 3;

    let x_scale = 10f64.powi(-exponent);
    let x_label = if exponent == 0 {
        "Iterations".to_owned()
    } else {
        format!("Iterations (x 10^{})", exponent)
    };

    let size = size.unwrap_or(SIZE);
    let root_area = SVGBackend::new(path, size).into_drawing_area();

    let mut cb = ChartBuilder::on(&root_area);
    if let Some(title) = title {
        cb.caption(title, (DEFAULT_FONT, 20));
    }

File: criterion.rs/src/plot/plotters_backend/regression.rs
Start Line: 47
End Line: 92
Chunks:

    let x_range = plotters::data::fitting_range(data.x().iter());
    let y_range = plotters::data::fitting_range(scaled_y.iter());

    let mut chart = cb
        .margin((5).percent())
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(x_range, y_range)
        .unwrap();

    chart
        .configure_mesh()
        .x_desc(x_label)
        .y_desc(format!("Total sample time ({})", unit))
        .x_label_formatter(&|x| pretty_print_float(x * x_scale, true))
        .light_line_style(TRANSPARENT)
        .draw()
        .unwrap();

    chart
        .draw_series(
            data.x()
                .iter()
                .zip(scaled_y.iter())
                .map(|(x, y)| Circle::new((*x, *y), POINT_SIZE, DARK_BLUE.filled())),
        )
        .unwrap()
        .label("Sample")
        .legend(|(x, y)| Circle::new((x + 10, y), POINT_SIZE, DARK_BLUE.filled()));

    chart
        .draw_series(std::iter::once(PathElement::new(
            vec![(0.0, 0.0), (max_iters, point)],
            DARK_BLUE,
        )))
        .unwrap()
        .label("Linear regression")
        .legend(|(x, y)| {
            PathElement::new(
                vec![(x, y), (x + 20, y)],
                DARK_BLUE.filled().stroke_width(2),
            )
        });


File: criterion.rs/src/plot/plotters_backend/regression.rs
Start Line: 92
End Line: 134
Chunks:
    chart
        .draw_series(std::iter::once(Polygon::new(
            vec![(0.0, 0.0), (max_iters, lb), (max_iters, ub)],
            DARK_BLUE.mix(0.25).filled(),
        )))
        .unwrap()
        .label("Confidence interval")
        .legend(|(x, y)| {
            Rectangle::new([(x, y - 5), (x + 20, y + 5)], DARK_BLUE.mix(0.25).filled())
        });

    if title.is_some() {
        chart
            .configure_series_labels()
            .position(SeriesLabelPosition::UpperLeft)
            .draw()
            .unwrap();
    }
}

pub(crate) fn regression_comparison_figure(
    title: Option<&str>,
    path: &Path,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    base_data: &Data<'_, f64, f64>,
    size: Option<(u32, u32)>,
) {
    let data = &measurements.data;
    let max_iters = base_data.x().max().max(data.x().max());
    let typical = base_data.y().max().max(data.y().max());

    let exponent = (max_iters.log10() / 3.).floor() as i32 * 3;
    let x_scale = 10f64.powi(-exponent);

    let x_label = if exponent == 0 {
        "Iterations".to_owned()
    } else {
        format!("Iterations (x 10^{})", exponent)
    };


File: criterion.rs/src/plot/plotters_backend/regression.rs
Start Line: 134
End Line: 184
Chunks:
    let Estimate {
        confidence_interval:
            ConfidenceInterval {
                lower_bound: base_lb,
                upper_bound: base_ub,
                ..
            },
        point_estimate: base_point,
        ..
    } = comparison.base_estimates.slope.as_ref().unwrap();

    let Estimate {
        confidence_interval:
            ConfidenceInterval {
                lower_bound: lb,
                upper_bound: ub,
                ..
            },
        point_estimate: point,
        ..
    } = measurements.absolute_estimates.slope.as_ref().unwrap();

    let mut points = [
        base_lb * max_iters,
        base_point * max_iters,
        base_ub * max_iters,
        lb * max_iters,
        point * max_iters,
        ub * max_iters,
    ];
    let unit = formatter.scale_values(typical, &mut points);
    let [base_lb, base_point, base_ub, lb, point, ub] = points;

    let y_max = point.max(base_point);

    let size = size.unwrap_or(SIZE);
    let root_area = SVGBackend::new(path, size).into_drawing_area();

    let mut cb = ChartBuilder::on(&root_area);
    if let Some(title) = title {
        cb.caption(title, (DEFAULT_FONT, 20));
    }

    let mut chart = cb
        .margin((5).percent())
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(0.0..max_iters, 0.0..y_max)
        .unwrap();


File: criterion.rs/src/plot/plotters_backend/regression.rs
Start Line: 184
End Line: 234
Chunks:
    chart
        .configure_mesh()
        .x_desc(x_label)
        .y_desc(format!("Total sample time ({})", unit))
        .x_label_formatter(&|x| pretty_print_float(x * x_scale, true))
        .light_line_style(TRANSPARENT)
        .draw()
        .unwrap();

    chart
        .draw_series(vec![
            PathElement::new(vec![(0.0, 0.0), (max_iters, base_point)], DARK_RED).into_dyn(),
            Polygon::new(
                vec![(0.0, 0.0), (max_iters, base_lb), (max_iters, base_ub)],
                DARK_RED.mix(0.25).filled(),
            )
            .into_dyn(),
        ])
        .unwrap()
        .label("Base Sample")
        .legend(|(x, y)| {
            PathElement::new(vec![(x, y), (x + 20, y)], DARK_RED.filled().stroke_width(2))
        });

    chart
        .draw_series(vec![
            PathElement::new(vec![(0.0, 0.0), (max_iters, point)], DARK_BLUE).into_dyn(),
            Polygon::new(
                vec![(0.0, 0.0), (max_iters, lb), (max_iters, ub)],
                DARK_BLUE.mix(0.25).filled(),
            )
            .into_dyn(),
        ])
        .unwrap()
        .label("New Sample")
        .legend(|(x, y)| {
            PathElement::new(
                vec![(x, y), (x + 20, y)],
                DARK_BLUE.filled().stroke_width(2),
            )
        });

    if title.is_some() {
        chart
            .configure_series_labels()
            .position(SeriesLabelPosition::UpperLeft)
            .draw()
            .unwrap();
    }
}

Ripgrep filtered Lines: [0, 8, 56, 94, 126, 174, 219, 265, 310]
File: criterion.rs/src/plot/plotters_backend/distributions.rs
Start Line: 0
End Line: 7
Chunks:
use super::*;
use crate::estimate::Estimate;
use crate::estimate::Statistic;
use crate::measurement::ValueFormatter;
use crate::report::{BenchmarkId, MeasurementData, ReportContext};
use crate::stats::Distribution;


File: criterion.rs/src/plot/plotters_backend/distributions.rs
Start Line: 7
End Line: 55
Chunks:
fn abs_distribution(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    statistic: Statistic,
    distribution: &Distribution<f64>,
    estimate: &Estimate,
    size: Option<(u32, u32)>,
) {
    let ci = &estimate.confidence_interval;
    let typical = ci.upper_bound;
    let mut ci_values = [ci.lower_bound, ci.upper_bound, estimate.point_estimate];
    let unit = formatter.scale_values(typical, &mut ci_values);
    let (lb, ub, point) = (ci_values[0], ci_values[1], ci_values[2]);

    let start = lb - (ub - lb) / 9.;
    let end = ub + (ub - lb) / 9.;
    let mut scaled_xs: Vec<f64> = distribution.iter().cloned().collect();
    let _ = formatter.scale_values(typical, &mut scaled_xs);
    let scaled_xs_sample = Sample::new(&scaled_xs);
    let (kde_xs, ys) = kde::sweep(scaled_xs_sample, KDE_POINTS, Some((start, end)));

    // interpolate between two points of the KDE sweep to find the Y position at the point estimate.
    let n_point = kde_xs
        .iter()
        .position(|&x| x >= point)
        .unwrap_or(kde_xs.len() - 1)
        .max(1); // Must be at least the second element or this will panic
    let slope = (ys[n_point] - ys[n_point - 1]) / (kde_xs[n_point] - kde_xs[n_point - 1]);
    let y_point = ys[n_point - 1] + (slope * (point - kde_xs[n_point - 1]));

    let start = kde_xs
        .iter()
        .enumerate()
        .find(|&(_, &x)| x >= lb)
        .unwrap()
        .0;
    let end = kde_xs
        .iter()
        .enumerate()
        .rev()
        .find(|&(_, &x)| x <= ub)
        .unwrap()
        .0;
    let len = end - start;

    let kde_xs_sample = Sample::new(&kde_xs);


File: criterion.rs/src/plot/plotters_backend/distributions.rs
Start Line: 55
End Line: 93
Chunks:
    let path = context.report_path(id, &format!("{}.svg", statistic));
    let root_area = SVGBackend::new(&path, size.unwrap_or(SIZE)).into_drawing_area();

    let x_range = plotters::data::fitting_range(kde_xs_sample.iter());
    let mut y_range = plotters::data::fitting_range(ys.iter());

    y_range.end *= 1.1;

    let mut chart = ChartBuilder::on(&root_area)
        .margin((5).percent())
        .caption(
            format!("{}:{}", id.as_title(), statistic),
            (DEFAULT_FONT, 20),
        )
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(x_range, y_range)
        .unwrap();

    chart
        .configure_mesh()
        .disable_mesh()
        .x_desc(format!("Average time ({})", unit))
        .y_desc("Density (a.u.)")
        .x_label_formatter(&|&v| pretty_print_float(v, true))
        .y_label_formatter(&|&v| pretty_print_float(v, true))
        .draw()
        .unwrap();

    chart
        .draw_series(LineSeries::new(
            kde_xs.iter().zip(ys.iter()).map(|(&x, &y)| (x, y)),
            DARK_BLUE,
        ))
        .unwrap()
        .label("Bootstrap distribution")
        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], DARK_BLUE));


File: criterion.rs/src/plot/plotters_backend/distributions.rs
Start Line: 93
End Line: 125
Chunks:
    chart
        .draw_series(AreaSeries::new(
            kde_xs
                .iter()
                .zip(ys.iter())
                .skip(start)
                .take(len)
                .map(|(&x, &y)| (x, y)),
            0.0,
            DARK_BLUE.mix(0.25).filled().stroke_width(3),
        ))
        .unwrap()
        .label("Confidence interval")
        .legend(|(x, y)| {
            Rectangle::new([(x, y - 5), (x + 20, y + 5)], DARK_BLUE.mix(0.25).filled())
        });

    chart
        .draw_series(std::iter::once(PathElement::new(
            vec![(point, 0.0), (point, y_point)],
            DARK_BLUE.filled().stroke_width(3),
        )))
        .unwrap()
        .label("Point estimate")
        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], DARK_BLUE));

    chart
        .configure_series_labels()
        .position(SeriesLabelPosition::UpperRight)
        .draw()
        .unwrap();
}

File: criterion.rs/src/plot/plotters_backend/distributions.rs
Start Line: 125
End Line: 173
Chunks:

pub(crate) fn abs_distributions(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<(u32, u32)>,
) {
    crate::plot::REPORT_STATS
        .iter()
        .filter_map(|stat| {
            measurements.distributions.get(*stat).and_then(|dist| {
                measurements
                    .absolute_estimates
                    .get(*stat)
                    .map(|est| (*stat, dist, est))
            })
        })
        .for_each(|(statistic, distribution, estimate)| {
            abs_distribution(
                id,
                context,
                formatter,
                statistic,
                distribution,
                estimate,
                size,
            )
        })
}

fn rel_distribution(
    id: &BenchmarkId,
    context: &ReportContext,
    statistic: Statistic,
    distribution: &Distribution<f64>,
    estimate: &Estimate,
    noise_threshold: f64,
    size: Option<(u32, u32)>,
) {
    let ci = &estimate.confidence_interval;
    let (lb, ub) = (ci.lower_bound, ci.upper_bound);

    let start = lb - (ub - lb) / 9.;
    let end = ub + (ub - lb) / 9.;
    let (xs, ys) = kde::sweep(distribution, KDE_POINTS, Some((start, end)));
    let xs_ = Sample::new(&xs);


File: criterion.rs/src/plot/plotters_backend/distributions.rs
Start Line: 173
End Line: 218
Chunks:
    // interpolate between two points of the KDE sweep to find the Y position at the point estimate.
    let point = estimate.point_estimate;
    let n_point = xs
        .iter()
        .position(|&x| x >= point)
        .unwrap_or(ys.len() - 1)
        .max(1);
    let slope = (ys[n_point] - ys[n_point - 1]) / (xs[n_point] - xs[n_point - 1]);
    let y_point = ys[n_point - 1] + (slope * (point - xs[n_point - 1]));

    let start = xs.iter().enumerate().find(|&(_, &x)| x >= lb).unwrap().0;
    let end = xs
        .iter()
        .enumerate()
        .rev()
        .find(|&(_, &x)| x <= ub)
        .unwrap()
        .0;
    let len = end - start;

    let x_min = xs_.min();
    let x_max = xs_.max();

    let (fc_start, fc_end) = if noise_threshold < x_min || -noise_threshold > x_max {
        let middle = (x_min + x_max) / 2.;

        (middle, middle)
    } else {
        (
            if -noise_threshold < x_min {
                x_min
            } else {
                -noise_threshold
            },
            if noise_threshold > x_max {
                x_max
            } else {
                noise_threshold
            },
        )
    };
    let y_range = plotters::data::fitting_range(ys.iter());
    let path = context.report_path(id, &format!("change/{}.svg", statistic));
    let root_area = SVGBackend::new(&path, size.unwrap_or(SIZE)).into_drawing_area();


File: criterion.rs/src/plot/plotters_backend/distributions.rs
Start Line: 218
End Line: 264
Chunks:
    let mut chart = ChartBuilder::on(&root_area)
        .margin((5).percent())
        .caption(
            format!("{}:{}", id.as_title(), statistic),
            (DEFAULT_FONT, 20),
        )
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(x_min..x_max, y_range.clone())
        .unwrap();

    chart
        .configure_mesh()
        .disable_mesh()
        .x_desc("Relative change (%)")
        .y_desc("Density (a.u.)")
        .x_label_formatter(&|&v| pretty_print_float(v, true))
        .y_label_formatter(&|&v| pretty_print_float(v, true))
        .draw()
        .unwrap();

    chart
        .draw_series(LineSeries::new(
            xs.iter().zip(ys.iter()).map(|(x, y)| (*x, *y)),
            DARK_BLUE,
        ))
        .unwrap()
        .label("Bootstrap distribution")
        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], DARK_BLUE));

    chart
        .draw_series(AreaSeries::new(
            xs.iter()
                .zip(ys.iter())
                .skip(start)
                .take(len)
                .map(|(x, y)| (*x, *y)),
            0.0,
            DARK_BLUE.mix(0.25).filled().stroke_width(3),
        ))
        .unwrap()
        .label("Confidence interval")
        .legend(|(x, y)| {
            Rectangle::new([(x, y - 5), (x + 20, y + 5)], DARK_BLUE.mix(0.25).filled())
        });


File: criterion.rs/src/plot/plotters_backend/distributions.rs
Start Line: 264
End Line: 309
Chunks:
    chart
        .draw_series(std::iter::once(PathElement::new(
            vec![(point, 0.0), (point, y_point)],
            DARK_BLUE.filled().stroke_width(3),
        )))
        .unwrap()
        .label("Point estimate")
        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], DARK_BLUE));

    chart
        .draw_series(std::iter::once(Rectangle::new(
            [(fc_start, y_range.start), (fc_end, y_range.end)],
            DARK_RED.mix(0.1).filled(),
        )))
        .unwrap()
        .label("Noise threshold")
        .legend(|(x, y)| {
            Rectangle::new([(x, y - 5), (x + 20, y + 5)], DARK_RED.mix(0.25).filled())
        });
    chart
        .configure_series_labels()
        .position(SeriesLabelPosition::UpperRight)
        .draw()
        .unwrap();
}

pub(crate) fn rel_distributions(
    id: &BenchmarkId,
    context: &ReportContext,
    _measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<(u32, u32)>,
) {
    crate::plot::CHANGE_STATS.iter().for_each(|&statistic| {
        rel_distribution(
            id,
            context,
            statistic,
            comparison.relative_distributions.get(statistic),
            comparison.relative_estimates.get(statistic),
            comparison.noise_threshold,
            size,
        )
    });
}

Ripgrep filtered Lines: [0, 48, 98, 144, 194, 243, 274, 308]
File: criterion.rs/src/plot/plotters_backend/pdf.rs
Start Line: 0
End Line: 47
Chunks:
use super::*;
use crate::measurement::ValueFormatter;
use crate::report::{BenchmarkId, ComparisonData, MeasurementData, ReportContext};
use plotters::data;
use plotters::style::RGBAColor;
use std::path::Path;

pub(crate) fn pdf_comparison_figure(
    path: &Path,
    title: Option<&str>,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<(u32, u32)>,
) {
    let base_avg_times = Sample::new(&comparison.base_avg_times);
    let typical = base_avg_times.max().max(measurements.avg_times.max());
    let mut scaled_base_avg_times: Vec<f64> = comparison.base_avg_times.clone();
    let unit = formatter.scale_values(typical, &mut scaled_base_avg_times);
    let scaled_base_avg_times = Sample::new(&scaled_base_avg_times);

    let mut scaled_new_avg_times: Vec<f64> = (&measurements.avg_times as &Sample<f64>)
        .iter()
        .cloned()
        .collect();
    let _ = formatter.scale_values(typical, &mut scaled_new_avg_times);
    let scaled_new_avg_times = Sample::new(&scaled_new_avg_times);

    let base_mean = scaled_base_avg_times.mean();
    let new_mean = scaled_new_avg_times.mean();

    let (base_xs, base_ys, base_y_mean) =
        kde::sweep_and_estimate(scaled_base_avg_times, KDE_POINTS, None, base_mean);
    let (xs, ys, y_mean) =
        kde::sweep_and_estimate(scaled_new_avg_times, KDE_POINTS, None, new_mean);

    let x_range = data::fitting_range(base_xs.iter().chain(xs.iter()));
    let y_range = data::fitting_range(base_ys.iter().chain(ys.iter()));

    let size = size.unwrap_or(SIZE);
    let root_area = SVGBackend::new(&path, (size.0, size.1)).into_drawing_area();

    let mut cb = ChartBuilder::on(&root_area);

    if let Some(title) = title {
        cb.caption(title, (DEFAULT_FONT, 20));
    }

File: criterion.rs/src/plot/plotters_backend/pdf.rs
Start Line: 47
End Line: 97
Chunks:

    let mut chart = cb
        .margin((5).percent())
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(x_range, y_range.clone())
        .unwrap();

    chart
        .configure_mesh()
        .disable_mesh()
        .y_desc("Density (a.u.)")
        .x_desc(format!("Average Time ({})", unit))
        .x_label_formatter(&|&x| pretty_print_float(x, true))
        .y_label_formatter(&|&y| pretty_print_float(y, true))
        .x_labels(5)
        .draw()
        .unwrap();

    chart
        .draw_series(AreaSeries::new(
            base_xs.iter().zip(base_ys.iter()).map(|(x, y)| (*x, *y)),
            y_range.start,
            DARK_RED.mix(0.5).filled(),
        ))
        .unwrap()
        .label("Base PDF")
        .legend(|(x, y)| Rectangle::new([(x, y - 5), (x + 20, y + 5)], DARK_RED.mix(0.5).filled()));

    chart
        .draw_series(AreaSeries::new(
            xs.iter().zip(ys.iter()).map(|(x, y)| (*x, *y)),
            y_range.start,
            DARK_BLUE.mix(0.5).filled(),
        ))
        .unwrap()
        .label("New PDF")
        .legend(|(x, y)| {
            Rectangle::new([(x, y - 5), (x + 20, y + 5)], DARK_BLUE.mix(0.5).filled())
        });

    chart
        .draw_series(std::iter::once(PathElement::new(
            vec![(base_mean, 0.0), (base_mean, base_y_mean)],
            DARK_RED.filled().stroke_width(2),
        )))
        .unwrap()
        .label("Base Mean")
        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], DARK_RED));


File: criterion.rs/src/plot/plotters_backend/pdf.rs
Start Line: 97
End Line: 143
Chunks:
    chart
        .draw_series(std::iter::once(PathElement::new(
            vec![(new_mean, 0.0), (new_mean, y_mean)],
            DARK_BLUE.filled().stroke_width(2),
        )))
        .unwrap()
        .label("New Mean")
        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], DARK_BLUE));

    if title.is_some() {
        chart.configure_series_labels().draw().unwrap();
    }
}

pub(crate) fn pdf_small(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<(u32, u32)>,
) {
    let avg_times = &*measurements.avg_times;
    let typical = avg_times.max();
    let mut scaled_avg_times: Vec<f64> = (avg_times as &Sample<f64>).iter().cloned().collect();
    let unit = formatter.scale_values(typical, &mut scaled_avg_times);
    let scaled_avg_times = Sample::new(&scaled_avg_times);
    let mean = scaled_avg_times.mean();

    let (xs, ys, mean_y) = kde::sweep_and_estimate(scaled_avg_times, KDE_POINTS, None, mean);
    let xs_ = Sample::new(&xs);
    let ys_ = Sample::new(&ys);

    let y_limit = ys_.max() * 1.1;

    let path = context.report_path(id, "pdf_small.svg");

    let size = size.unwrap_or(SIZE);
    let root_area = SVGBackend::new(&path, (size.0, size.1)).into_drawing_area();

    let mut chart = ChartBuilder::on(&root_area)
        .margin((5).percent())
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(xs_.min()..xs_.max(), 0.0..y_limit)
        .unwrap();


File: criterion.rs/src/plot/plotters_backend/pdf.rs
Start Line: 143
End Line: 193
Chunks:
    chart
        .configure_mesh()
        .disable_mesh()
        .y_desc("Density (a.u.)")
        .x_desc(format!("Average Time ({})", unit))
        .x_label_formatter(&|&x| pretty_print_float(x, true))
        .y_label_formatter(&|&y| pretty_print_float(y, true))
        .x_labels(5)
        .draw()
        .unwrap();

    chart
        .draw_series(AreaSeries::new(
            xs.iter().zip(ys.iter()).map(|(x, y)| (*x, *y)),
            0.0,
            DARK_BLUE.mix(0.25).filled(),
        ))
        .unwrap();

    chart
        .draw_series(std::iter::once(PathElement::new(
            vec![(mean, 0.0), (mean, mean_y)],
            DARK_BLUE.filled().stroke_width(2),
        )))
        .unwrap();
}

pub(crate) fn pdf(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<(u32, u32)>,
) {
    let avg_times = &measurements.avg_times;
    let typical = avg_times.max();
    let mut scaled_avg_times: Vec<f64> = (avg_times as &Sample<f64>).iter().cloned().collect();
    let unit = formatter.scale_values(typical, &mut scaled_avg_times);
    let scaled_avg_times = Sample::new(&scaled_avg_times);

    let mean = scaled_avg_times.mean();

    let iter_counts = measurements.iter_counts();
    let &max_iters = iter_counts
        .iter()
        .max_by_key(|&&iters| iters as u64)
        .unwrap();
    let exponent = (max_iters.log10() / 3.).floor() as i32 * 3;
    let y_scale = 10f64.powi(-exponent);


File: criterion.rs/src/plot/plotters_backend/pdf.rs
Start Line: 193
End Line: 242
Chunks:
    let y_label = if exponent == 0 {
        "Iterations".to_owned()
    } else {
        format!("Iterations (x 10^{})", exponent)
    };

    let (xs, ys) = kde::sweep(scaled_avg_times, KDE_POINTS, None);
    let (lost, lomt, himt, hist) = avg_times.fences();
    let mut fences = [lost, lomt, himt, hist];
    let _ = formatter.scale_values(typical, &mut fences);
    let [lost, lomt, himt, hist] = fences;

    let path = context.report_path(id, "pdf.svg");

    let xs_ = Sample::new(&xs);

    let size = size.unwrap_or(SIZE);
    let root_area = SVGBackend::new(&path, (size.0, size.1)).into_drawing_area();

    let range = data::fitting_range(ys.iter());

    let mut chart = ChartBuilder::on(&root_area)
        .margin((5).percent())
        .caption(id.as_title(), (DEFAULT_FONT, 20))
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Right, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(xs_.min()..xs_.max(), 0.0..max_iters)
        .unwrap()
        .set_secondary_coord(xs_.min()..xs_.max(), 0.0..range.end);

    chart
        .configure_mesh()
        .disable_mesh()
        .y_desc(y_label)
        .x_desc(format!("Average Time ({})", unit))
        .x_label_formatter(&|&x| pretty_print_float(x, true))
        .y_label_formatter(&|&y| pretty_print_float(y * y_scale, true))
        .draw()
        .unwrap();

    chart
        .configure_secondary_axes()
        .y_desc("Density (a.u.)")
        .x_label_formatter(&|&x| pretty_print_float(x, true))
        .y_label_formatter(&|&y| pretty_print_float(y, true))
        .draw()
        .unwrap();


File: criterion.rs/src/plot/plotters_backend/pdf.rs
Start Line: 242
End Line: 273
Chunks:
    chart
        .draw_secondary_series(AreaSeries::new(
            xs.iter().zip(ys.iter()).map(|(x, y)| (*x, *y)),
            0.0,
            DARK_BLUE.mix(0.5).filled(),
        ))
        .unwrap()
        .label("PDF")
        .legend(|(x, y)| {
            Rectangle::new([(x, y - 5), (x + 20, y + 5)], DARK_BLUE.mix(0.5).filled())
        });

    chart
        .draw_series(std::iter::once(PathElement::new(
            vec![(mean, 0.0), (mean, max_iters)],
            DARK_BLUE,
        )))
        .unwrap()
        .label("Mean")
        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], DARK_BLUE));

    chart
        .draw_series(vec![
            PathElement::new(vec![(lomt, 0.0), (lomt, max_iters)], DARK_ORANGE),
            PathElement::new(vec![(himt, 0.0), (himt, max_iters)], DARK_ORANGE),
            PathElement::new(vec![(lost, 0.0), (lost, max_iters)], DARK_RED),
            PathElement::new(vec![(hist, 0.0), (hist, max_iters)], DARK_RED),
        ])
        .unwrap();
    use crate::stats::univariate::outliers::tukey::Label;


File: criterion.rs/src/plot/plotters_backend/pdf.rs
Start Line: 273
End Line: 307
Chunks:
    let mut draw_data_point_series =
        |filter: &dyn Fn(&Label) -> bool, color: RGBAColor, name: &str| {
            chart
                .draw_series(
                    avg_times
                        .iter()
                        .zip(scaled_avg_times.iter())
                        .zip(iter_counts.iter())
                        .filter_map(|(((_, label), t), i)| {
                            if filter(&label) {
                                Some(Circle::new((*t, *i), POINT_SIZE, color.filled()))
                            } else {
                                None
                            }
                        }),
                )
                .unwrap()
                .label(name)
                .legend(move |(x, y)| Circle::new((x + 10, y), POINT_SIZE, color.filled()));
        };

    draw_data_point_series(
        &|l| !l.is_outlier(),
        DARK_BLUE.to_rgba(),
        "\"Clean\" sample",
    );
    draw_data_point_series(
        &|l| l.is_mild(),
        RGBColor(255, 127, 0).to_rgba(),
        "Mild outliers",
    );
    draw_data_point_series(&|l| l.is_severe(), DARK_RED.to_rgba(), "Severe outliers");
    chart.configure_series_labels().draw().unwrap();
}

Ripgrep filtered Lines: [0, 25, 62, 91, 139]
File: criterion.rs/src/plot/plotters_backend/iteration_times.rs
Start Line: 0
End Line: 24
Chunks:
use super::*;

use std::path::Path;

pub(crate) fn iteration_times_figure(
    title: Option<&str>,
    path: &Path,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<(u32, u32)>,
) {
    let data = &measurements.avg_times;
    let max_avg_time = data.max();
    let mut scaled_y: Vec<_> = data.iter().map(|(f, _)| f).collect();
    let unit = formatter.scale_values(max_avg_time, &mut scaled_y);
    let scaled_y = Sample::new(&scaled_y);

    let size = size.unwrap_or(SIZE);
    let root_area = SVGBackend::new(path, size).into_drawing_area();

    let mut cb = ChartBuilder::on(&root_area);
    if let Some(title) = title {
        cb.caption(title, (DEFAULT_FONT, 20));
    }

File: criterion.rs/src/plot/plotters_backend/iteration_times.rs
Start Line: 24
End Line: 61
Chunks:

    let x_range = (1.0)..((data.len() + 1) as f64);
    let y_range = plotters::data::fitting_range(scaled_y.iter());

    let mut chart = cb
        .margin((5).percent())
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(x_range, y_range)
        .unwrap();

    chart
        .configure_mesh()
        .y_desc(format!("Average Iteration Time ({})", unit))
        .x_label_formatter(&|x| pretty_print_float(*x, true))
        .light_line_style(TRANSPARENT)
        .draw()
        .unwrap();

    chart
        .draw_series(
            (1..=data.len())
                .zip(scaled_y.iter())
                .map(|(x, y)| Circle::new((x as f64, *y), POINT_SIZE, DARK_BLUE.filled())),
        )
        .unwrap()
        .label("Sample")
        .legend(|(x, y)| Circle::new((x + 10, y), POINT_SIZE, DARK_BLUE.filled()));

    if title.is_some() {
        chart
            .configure_series_labels()
            .position(SeriesLabelPosition::UpperLeft)
            .draw()
            .unwrap();
    }
}

File: criterion.rs/src/plot/plotters_backend/iteration_times.rs
Start Line: 61
End Line: 90
Chunks:

pub(crate) fn iteration_times_comparison_figure(
    title: Option<&str>,
    path: &Path,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<(u32, u32)>,
) {
    let current_data = &measurements.avg_times;
    let base_data = &comparison.base_avg_times;

    let mut all_data: Vec<f64> = current_data.iter().map(|(f, _)| f).collect();
    all_data.extend_from_slice(base_data);

    let typical_value = Sample::new(&all_data).max();
    let unit = formatter.scale_values(typical_value, &mut all_data);

    let (scaled_current_y, scaled_base_y) = all_data.split_at(current_data.len());
    let scaled_current_y = Sample::new(scaled_current_y);
    let scaled_base_y = Sample::new(scaled_base_y);

    let size = size.unwrap_or(SIZE);
    let root_area = SVGBackend::new(path, size).into_drawing_area();

    let mut cb = ChartBuilder::on(&root_area);
    if let Some(title) = title {
        cb.caption(title, (DEFAULT_FONT, 20));
    }

File: criterion.rs/src/plot/plotters_backend/iteration_times.rs
Start Line: 90
End Line: 138
Chunks:

    let max_samples = current_data.len().max(base_data.len()) as f64;

    let y_range = plotters::data::fitting_range(all_data.iter());

    let mut chart = cb
        .margin((5).percent())
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(0.0..max_samples, y_range)
        .unwrap();

    chart
        .configure_mesh()
        .y_desc(format!("Average Iteration Time ({})", unit))
        .x_label_formatter(&|x| pretty_print_float(*x, true))
        .light_line_style(TRANSPARENT)
        .draw()
        .unwrap();

    chart
        .draw_series(
            (1..=current_data.len())
                .zip(scaled_current_y.iter())
                .map(|(x, y)| Circle::new((x as f64, *y), POINT_SIZE, DARK_BLUE.filled())),
        )
        .unwrap()
        .label("Current")
        .legend(|(x, y)| Circle::new((x + 10, y), POINT_SIZE, DARK_BLUE.filled()));

    chart
        .draw_series(
            (1..=base_data.len())
                .zip(scaled_base_y.iter())
                .map(|(x, y)| Circle::new((x as f64, *y), POINT_SIZE, DARK_RED.filled())),
        )
        .unwrap()
        .label("Base")
        .legend(|(x, y)| Circle::new((x + 10, y), POINT_SIZE, DARK_RED.filled()));

    if title.is_some() {
        chart
            .configure_series_labels()
            .position(SeriesLabelPosition::UpperLeft)
            .draw()
            .unwrap();
    }
}

Ripgrep filtered Lines: [0, 8, 57, 107, 153, 192, 216, 266]
File: criterion.rs/src/plot/plotters_backend/summary.rs
Start Line: 0
End Line: 7
Chunks:
use super::*;
use crate::AxisScale;
use itertools::Itertools;
use plotters::coord::{
    ranged1d::{AsRangedCoord, ValueFormatter as PlottersValueFormatter},
    Shift,
};

File: criterion.rs/src/plot/plotters_backend/summary.rs
Start Line: 7
End Line: 56
Chunks:
use std::cmp::Ordering;
use std::path::Path;

const NUM_COLORS: usize = 8;
static COMPARISON_COLORS: [RGBColor; NUM_COLORS] = [
    RGBColor(178, 34, 34),
    RGBColor(46, 139, 87),
    RGBColor(0, 139, 139),
    RGBColor(255, 215, 0),
    RGBColor(0, 0, 139),
    RGBColor(220, 20, 60),
    RGBColor(139, 0, 139),
    RGBColor(0, 255, 127),
];

pub fn line_comparison(
    formatter: &dyn ValueFormatter,
    title: &str,
    all_curves: &[&(&BenchmarkId, Vec<f64>)],
    path: &Path,
    value_type: ValueType,
    axis_scale: AxisScale,
) {
    let (unit, series_data) = line_comparison_series_data(formatter, all_curves);

    let x_range =
        plotters::data::fitting_range(series_data.iter().flat_map(|(_, xs, _)| xs.iter()));
    let y_range =
        plotters::data::fitting_range(series_data.iter().flat_map(|(_, _, ys)| ys.iter()));
    let root_area = SVGBackend::new(&path, SIZE)
        .into_drawing_area()
        .titled(&format!("{}: Comparison", title), (DEFAULT_FONT, 20))
        .unwrap();

    match axis_scale {
        AxisScale::Linear => {
            draw_line_comarision_figure(root_area, unit, x_range, y_range, value_type, series_data)
        }
        AxisScale::Logarithmic => draw_line_comarision_figure(
            root_area,
            unit,
            x_range.log_scale(),
            y_range.log_scale(),
            value_type,
            series_data,
        ),
    }
}


File: criterion.rs/src/plot/plotters_backend/summary.rs
Start Line: 56
End Line: 106
Chunks:
fn draw_line_comarision_figure<XR: AsRangedCoord<Value = f64>, YR: AsRangedCoord<Value = f64>>(
    root_area: DrawingArea<SVGBackend, Shift>,
    y_unit: &str,
    x_range: XR,
    y_range: YR,
    value_type: ValueType,
    data: Vec<(Option<&String>, Vec<f64>, Vec<f64>)>,
) where
    XR::CoordDescType: PlottersValueFormatter<f64>,
    YR::CoordDescType: PlottersValueFormatter<f64>,
{
    let input_suffix = match value_type {
        ValueType::Bytes => " Size (Bytes)",
        ValueType::Elements => " Size (Elements)",
        ValueType::Value => "",
    };

    let mut chart = ChartBuilder::on(&root_area)
        .margin((5).percent())
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(x_range, y_range)
        .unwrap();

    chart
        .configure_mesh()
        .disable_mesh()
        .x_desc(format!("Input{}", input_suffix))
        .y_desc(format!("Average time ({})", y_unit))
        .draw()
        .unwrap();

    for (id, (name, xs, ys)) in (0..).zip(data) {
        let series = chart
            .draw_series(
                LineSeries::new(
                    xs.into_iter().zip(ys),
                    COMPARISON_COLORS[id % NUM_COLORS].filled(),
                )
                .point_size(POINT_SIZE),
            )
            .unwrap();
        if let Some(name) = name {
            series.label(name).legend(move |(x, y)| {
                Rectangle::new(
                    [(x, y - 5), (x + 20, y + 5)],
                    COMPARISON_COLORS[id % NUM_COLORS].filled(),
                )
            });
        }

File: criterion.rs/src/plot/plotters_backend/summary.rs
Start Line: 106
End Line: 152
Chunks:
    }

    chart
        .configure_series_labels()
        .position(SeriesLabelPosition::UpperLeft)
        .draw()
        .unwrap();
}

#[allow(clippy::type_complexity)]
fn line_comparison_series_data<'a>(
    formatter: &dyn ValueFormatter,
    all_curves: &[&(&'a BenchmarkId, Vec<f64>)],
) -> (&'static str, Vec<(Option<&'a String>, Vec<f64>, Vec<f64>)>) {
    let max = all_curves
        .iter()
        .map(|&(_, data)| Sample::new(data).mean())
        .fold(::std::f64::NAN, f64::max);

    let mut dummy = [1.0];
    let unit = formatter.scale_values(max, &mut dummy);

    let mut series_data = vec![];

    // This assumes the curves are sorted. It also assumes that the benchmark IDs all have numeric
    // values or throughputs and that value is sensible (ie. not a mix of bytes and elements
    // or whatnot)
    for (key, group) in &all_curves.iter().group_by(|&&&(id, _)| &id.function_id) {
        let mut tuples: Vec<_> = group
            .map(|&&(id, ref sample)| {
                // Unwrap is fine here because it will only fail if the assumptions above are not true
                // ie. programmer error.
                let x = id.as_number().unwrap();
                let y = Sample::new(sample).mean();

                (x, y)
            })
            .collect();
        tuples.sort_by(|&(ax, _), &(bx, _)| (ax.partial_cmp(&bx).unwrap_or(Ordering::Less)));
        let function_name = key.as_ref();
        let (xs, mut ys): (Vec<_>, Vec<_>) = tuples.into_iter().unzip();
        formatter.scale_values(max, &mut ys);
        series_data.push((function_name, xs, ys));
    }
    (unit, series_data)
}

File: criterion.rs/src/plot/plotters_backend/summary.rs
Start Line: 152
End Line: 191
Chunks:

pub fn violin(
    formatter: &dyn ValueFormatter,
    title: &str,
    all_curves: &[&(&BenchmarkId, Vec<f64>)],
    path: &Path,
    axis_scale: AxisScale,
) {
    let all_curves_vec = all_curves.iter().rev().cloned().collect::<Vec<_>>();
    let all_curves: &[&(&BenchmarkId, Vec<f64>)] = &all_curves_vec;

    let mut kdes = all_curves
        .iter()
        .map(|&&(id, ref sample)| {
            let (x, mut y) = kde::sweep(Sample::new(sample), KDE_POINTS, None);
            let y_max = Sample::new(&y).max();
            for y in y.iter_mut() {
                *y /= y_max;
            }

            (id.as_title(), x, y)
        })
        .collect::<Vec<_>>();

    let mut xs = kdes
        .iter()
        .flat_map(|(_, x, _)| x.iter())
        .filter(|&&x| x > 0.);
    let (mut min, mut max) = {
        let &first = xs.next().unwrap();
        (first, first)
    };
    for &e in xs {
        if e < min {
            min = e;
        } else if e > max {
            max = e;
        }
    }

File: criterion.rs/src/plot/plotters_backend/summary.rs
Start Line: 191
End Line: 215
Chunks:
    let mut dummy = [1.0];
    let unit = formatter.scale_values(max, &mut dummy);
    kdes.iter_mut().for_each(|&mut (_, ref mut xs, _)| {
        formatter.scale_values(max, xs);
    });

    let mut x_range = plotters::data::fitting_range(kdes.iter().flat_map(|(_, xs, _)| xs.iter()));
    x_range.start = 0.0;
    let y_range = -0.5..all_curves.len() as f64 - 0.5;

    let size = (960, 150 + (18 * all_curves.len() as u32));

    let root_area = SVGBackend::new(&path, size)
        .into_drawing_area()
        .titled(&format!("{}: Violin plot", title), (DEFAULT_FONT, 20))
        .unwrap();

    match axis_scale {
        AxisScale::Linear => draw_violin_figure(root_area, unit, x_range, y_range, kdes),
        AxisScale::Logarithmic => {
            draw_violin_figure(root_area, unit, x_range.log_scale(), y_range, kdes)
        }
    }
}

File: criterion.rs/src/plot/plotters_backend/summary.rs
Start Line: 215
End Line: 265
Chunks:

#[allow(clippy::type_complexity)]
fn draw_violin_figure<XR: AsRangedCoord<Value = f64>, YR: AsRangedCoord<Value = f64>>(
    root_area: DrawingArea<SVGBackend, Shift>,
    unit: &'static str,
    x_range: XR,
    y_range: YR,
    data: Vec<(&str, Box<[f64]>, Box<[f64]>)>,
) where
    XR::CoordDescType: PlottersValueFormatter<f64>,
    YR::CoordDescType: PlottersValueFormatter<f64>,
{
    let mut chart = ChartBuilder::on(&root_area)
        .margin((5).percent())
        .set_label_area_size(LabelAreaPosition::Left, (10).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_width().min(40))
        .build_cartesian_2d(x_range, y_range)
        .unwrap();

    chart
        .configure_mesh()
        .disable_mesh()
        .y_desc("Input")
        .x_desc(format!("Average time ({})", unit))
        .y_label_style((DEFAULT_FONT, 10))
        .y_label_formatter(&|v: &f64| data[v.round() as usize].0.to_string())
        .y_labels(data.len())
        .draw()
        .unwrap();

    for (i, (_, x, y)) in data.into_iter().enumerate() {
        let base = i as f64;

        chart
            .draw_series(AreaSeries::new(
                x.iter().zip(y.iter()).map(|(x, y)| (*x, base + *y / 2.0)),
                base,
                DARK_BLUE,
            ))
            .unwrap();

        chart
            .draw_series(AreaSeries::new(
                x.iter().zip(y.iter()).map(|(x, y)| (*x, base - *y / 2.0)),
                base,
                DARK_BLUE,
            ))
            .unwrap();
    }
}

Ripgrep filtered Lines: [0, 33, 79, 122, 164, 202, 233]
File: criterion.rs/src/plot/plotters_backend/mod.rs
Start Line: 0
End Line: 32
Chunks:
use super::{PlotContext, PlotData, Plotter};
use crate::measurement::ValueFormatter;
use crate::report::{BenchmarkId, ComparisonData, MeasurementData, ValueType};
use plotters::data::float::pretty_print_float;
use plotters::prelude::*;

use crate::kde;
use crate::stats::bivariate::Data;
use crate::stats::univariate::Sample;

static DEFAULT_FONT: FontFamily = FontFamily::SansSerif;
static KDE_POINTS: usize = 500;
static SIZE: (u32, u32) = (960, 540);
static POINT_SIZE: u32 = 3;

const DARK_BLUE: RGBColor = RGBColor(31, 120, 180);
const DARK_ORANGE: RGBColor = RGBColor(255, 127, 0);
const DARK_RED: RGBColor = RGBColor(227, 26, 28);

mod distributions;
mod iteration_times;
mod pdf;
mod regression;
mod summary;
mod t_test;

fn convert_size(size: Option<(usize, usize)>) -> Option<(u32, u32)> {
    if let Some((w, h)) = size {
        return Some((w as u32, h as u32));
    }
    None
}

File: criterion.rs/src/plot/plotters_backend/mod.rs
Start Line: 32
End Line: 78
Chunks:
#[derive(Default)]
pub struct PlottersBackend;

#[allow(unused_variables)]
impl Plotter for PlottersBackend {
    fn pdf(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        if let Some(cmp) = data.comparison {
            let (path, title) = if ctx.is_thumbnail {
                (
                    ctx.context.report_path(ctx.id, "relative_pdf_small.svg"),
                    None,
                )
            } else {
                (
                    ctx.context.report_path(ctx.id, "both/pdf.svg"),
                    Some(ctx.id.as_title()),
                )
            };
            pdf::pdf_comparison_figure(
                path.as_ref(),
                title,
                data.formatter,
                data.measurements,
                cmp,
                convert_size(ctx.size),
            );
            return;
        }
        if ctx.is_thumbnail {
            pdf::pdf_small(
                ctx.id,
                ctx.context,
                data.formatter,
                data.measurements,
                convert_size(ctx.size),
            );
        } else {
            pdf::pdf(
                ctx.id,
                ctx.context,
                data.formatter,
                data.measurements,
                convert_size(ctx.size),
            );
        }
    }

File: criterion.rs/src/plot/plotters_backend/mod.rs
Start Line: 78
End Line: 121
Chunks:

    fn regression(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        let (title, path) = match (data.comparison.is_some(), ctx.is_thumbnail) {
            (true, true) => (
                None,
                ctx.context
                    .report_path(ctx.id, "relative_regression_small.svg"),
            ),
            (true, false) => (
                Some(ctx.id.as_title()),
                ctx.context.report_path(ctx.id, "both/regression.svg"),
            ),
            (false, true) => (
                None,
                ctx.context.report_path(ctx.id, "regression_small.svg"),
            ),
            (false, false) => (
                Some(ctx.id.as_title()),
                ctx.context.report_path(ctx.id, "regression.svg"),
            ),
        };

        if let Some(cmp) = data.comparison {
            let base_data = Data::new(&cmp.base_iter_counts, &cmp.base_sample_times);
            regression::regression_comparison_figure(
                title,
                path.as_path(),
                data.formatter,
                data.measurements,
                cmp,
                &base_data,
                convert_size(ctx.size),
            );
        } else {
            regression::regression_figure(
                title,
                path.as_path(),
                data.formatter,
                data.measurements,
                convert_size(ctx.size),
            );
        }
    }

File: criterion.rs/src/plot/plotters_backend/mod.rs
Start Line: 121
End Line: 163
Chunks:

    fn iteration_times(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        let (title, path) = match (data.comparison.is_some(), ctx.is_thumbnail) {
            (true, true) => (
                None,
                ctx.context
                    .report_path(ctx.id, "relative_iteration_times_small.svg"),
            ),
            (true, false) => (
                Some(ctx.id.as_title()),
                ctx.context.report_path(ctx.id, "both/iteration_times.svg"),
            ),
            (false, true) => (
                None,
                ctx.context.report_path(ctx.id, "iteration_times_small.svg"),
            ),
            (false, false) => (
                Some(ctx.id.as_title()),
                ctx.context.report_path(ctx.id, "iteration_times.svg"),
            ),
        };

        if let Some(cmp) = data.comparison {
            let base_data = Data::new(&cmp.base_iter_counts, &cmp.base_sample_times);
            iteration_times::iteration_times_comparison_figure(
                title,
                path.as_path(),
                data.formatter,
                data.measurements,
                cmp,
                convert_size(ctx.size),
            );
        } else {
            iteration_times::iteration_times_figure(
                title,
                path.as_path(),
                data.formatter,
                data.measurements,
                convert_size(ctx.size),
            );
        }
    }

File: criterion.rs/src/plot/plotters_backend/mod.rs
Start Line: 163
End Line: 201
Chunks:

    fn abs_distributions(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        distributions::abs_distributions(
            ctx.id,
            ctx.context,
            data.formatter,
            data.measurements,
            convert_size(ctx.size),
        );
    }

    fn rel_distributions(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        distributions::rel_distributions(
            ctx.id,
            ctx.context,
            data.measurements,
            data.comparison.unwrap(),
            convert_size(ctx.size),
        );
    }

    fn line_comparison(
        &mut self,
        ctx: PlotContext<'_>,
        formatter: &dyn ValueFormatter,
        all_curves: &[&(&BenchmarkId, Vec<f64>)],
        value_type: ValueType,
    ) {
        let path = ctx.line_comparison_path();
        summary::line_comparison(
            formatter,
            ctx.id.as_title(),
            all_curves,
            &path,
            value_type,
            ctx.context.plot_config.summary_scale,
        );
    }

File: criterion.rs/src/plot/plotters_backend/mod.rs
Start Line: 201
End Line: 232
Chunks:

    fn violin(
        &mut self,
        ctx: PlotContext<'_>,
        formatter: &dyn ValueFormatter,
        all_curves: &[&(&BenchmarkId, Vec<f64>)],
    ) {
        let violin_path = ctx.violin_path();

        summary::violin(
            formatter,
            ctx.id.as_title(),
            all_curves,
            &violin_path,
            ctx.context.plot_config.summary_scale,
        );
    }

    fn t_test(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        let title = ctx.id.as_title();
        let path = ctx.context.report_path(ctx.id, "change/t-test.svg");
        t_test::t_test(
            path.as_path(),
            title,
            data.comparison.unwrap(),
            convert_size(ctx.size),
        );
    }

    fn wait(&mut self) {}
}

Ripgrep filtered Lines: [0, 49, 60]
File: criterion.rs/src/plot/plotters_backend/t_test.rs
Start Line: 0
End Line: 48
Chunks:
use super::*;
use crate::report::ComparisonData;
use std::path::Path;

pub(crate) fn t_test(
    path: &Path,
    title: &str,
    comparison: &ComparisonData,
    size: Option<(u32, u32)>,
) {
    let t = comparison.t_value;
    let (xs, ys) = kde::sweep(&comparison.t_distribution, KDE_POINTS, None);

    let x_range = plotters::data::fitting_range(xs.iter());
    let mut y_range = plotters::data::fitting_range(ys.iter());
    y_range.start = 0.0;
    y_range.end *= 1.1;

    let root_area = SVGBackend::new(&path, size.unwrap_or(SIZE)).into_drawing_area();

    let mut chart = ChartBuilder::on(&root_area)
        .margin((5).percent())
        .caption(format!("{}: Welch t test", title), (DEFAULT_FONT, 20))
        .set_label_area_size(LabelAreaPosition::Left, (5).percent_width().min(60))
        .set_label_area_size(LabelAreaPosition::Bottom, (5).percent_height().min(40))
        .build_cartesian_2d(x_range, y_range.clone())
        .unwrap();

    chart
        .configure_mesh()
        .disable_mesh()
        .y_desc("Density")
        .x_desc("t score")
        .draw()
        .unwrap();

    chart
        .draw_series(AreaSeries::new(
            xs.iter().zip(ys.iter()).map(|(x, y)| (*x, *y)),
            0.0,
            DARK_BLUE.mix(0.25),
        ))
        .unwrap()
        .label("t distribution")
        .legend(|(x, y)| {
            Rectangle::new([(x, y - 5), (x + 20, y + 5)], DARK_BLUE.mix(0.25).filled())
        });


File: criterion.rs/src/plot/plotters_backend/t_test.rs
Start Line: 48
End Line: 59
Chunks:
    chart
        .draw_series(std::iter::once(PathElement::new(
            vec![(t, 0.0), (t, y_range.end)],
            DARK_BLUE.filled().stroke_width(2),
        )))
        .unwrap()
        .label("t statistic")
        .legend(|(x, y)| PathElement::new(vec![(x, y), (x + 20, y)], DARK_BLUE));

    chart.configure_series_labels().draw().unwrap();
}

Ripgrep filtered Lines: [0, 31, 75, 106]
File: criterion.rs/src/plot/mod.rs
Start Line: 0
End Line: 30
Chunks:
mod gnuplot_backend;
#[cfg(feature = "plotters")]
mod plotters_backend;

pub(crate) use gnuplot_backend::Gnuplot;
#[cfg(feature = "plotters")]
pub(crate) use plotters_backend::PlottersBackend;

use crate::estimate::Statistic;
use crate::measurement::ValueFormatter;
use crate::report::{BenchmarkId, ComparisonData, MeasurementData, ReportContext, ValueType};
use std::path::PathBuf;

const REPORT_STATS: [Statistic; 7] = [
    Statistic::Typical,
    Statistic::Slope,
    Statistic::Mean,
    Statistic::Median,
    Statistic::MedianAbsDev,
    Statistic::MedianAbsDev,
    Statistic::StdDev,
];
const CHANGE_STATS: [Statistic; 2] = [Statistic::Mean, Statistic::Median];
#[derive(Clone, Copy)]
pub(crate) struct PlotContext<'a> {
    pub(crate) id: &'a BenchmarkId,
    pub(crate) context: &'a ReportContext,
    pub(crate) size: Option<(usize, usize)>,
    pub(crate) is_thumbnail: bool,
}

File: criterion.rs/src/plot/mod.rs
Start Line: 30
End Line: 74
Chunks:

impl<'a> PlotContext<'a> {
    pub fn size(mut self, s: Option<criterion_plot::Size>) -> PlotContext<'a> {
        if let Some(s) = s {
            self.size = Some((s.0, s.1));
        }
        self
    }

    pub fn thumbnail(mut self, value: bool) -> PlotContext<'a> {
        self.is_thumbnail = value;
        self
    }

    pub fn line_comparison_path(&self) -> PathBuf {
        let mut path = self.context.output_directory.clone();
        path.push(self.id.as_directory_name());
        path.push("report");
        path.push("lines.svg");
        path
    }

    pub fn violin_path(&self) -> PathBuf {
        let mut path = self.context.output_directory.clone();
        path.push(self.id.as_directory_name());
        path.push("report");
        path.push("violin.svg");
        path
    }
}

#[derive(Clone, Copy)]
pub(crate) struct PlotData<'a> {
    pub(crate) formatter: &'a dyn ValueFormatter,
    pub(crate) measurements: &'a MeasurementData<'a>,
    pub(crate) comparison: Option<&'a ComparisonData>,
}

impl<'a> PlotData<'a> {
    pub fn comparison(mut self, comp: &'a ComparisonData) -> PlotData<'a> {
        self.comparison = Some(comp);
        self
    }
}

File: criterion.rs/src/plot/mod.rs
Start Line: 74
End Line: 105
Chunks:

pub(crate) trait Plotter {
    fn pdf(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>);

    fn regression(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>);

    fn iteration_times(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>);

    fn abs_distributions(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>);

    fn rel_distributions(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>);

    fn line_comparison(
        &mut self,
        ctx: PlotContext<'_>,
        formatter: &dyn ValueFormatter,
        all_curves: &[&(&BenchmarkId, Vec<f64>)],
        value_type: ValueType,
    );

    fn violin(
        &mut self,
        ctx: PlotContext<'_>,
        formatter: &dyn ValueFormatter,
        all_curves: &[&(&BenchmarkId, Vec<f64>)],
    );

    fn t_test(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>);

    fn wait(&mut self);
}

Ripgrep filtered Lines: [0, 44, 69, 95, 145, 184, 214, 244, 280]
File: criterion.rs/src/plot/gnuplot_backend/regression.rs
Start Line: 0
End Line: 43
Chunks:
use std::process::Child;

use crate::stats::bivariate::regression::Slope;
use criterion_plot::prelude::*;

use super::*;
use crate::report::{BenchmarkId, ComparisonData, MeasurementData, ReportContext};
use crate::stats::bivariate::Data;

use crate::estimate::{ConfidenceInterval, Estimate};

use crate::measurement::ValueFormatter;

fn regression_figure(
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<Size>,
) -> Figure {
    let slope_estimate = measurements.absolute_estimates.slope.as_ref().unwrap();
    let slope_dist = measurements.distributions.slope.as_ref().unwrap();
    let (lb, ub) =
        slope_dist.confidence_interval(slope_estimate.confidence_interval.confidence_level);

    let data = &measurements.data;
    let (max_iters, typical) = (data.x().max(), data.y().max());
    let mut scaled_y: Vec<f64> = data.y().iter().cloned().collect();
    let unit = formatter.scale_values(typical, &mut scaled_y);
    let scaled_y = Sample::new(&scaled_y);

    let point_estimate = Slope::fit(&measurements.data).0;
    let mut scaled_points = [point_estimate * max_iters, lb * max_iters, ub * max_iters];
    let _ = formatter.scale_values(typical, &mut scaled_points);
    let [point, lb, ub] = scaled_points;

    let exponent = (max_iters.log10() / 3.).floor() as i32 * 3;
    let x_scale = 10f64.powi(-exponent);

    let x_label = if exponent == 0 {
        "Iterations".to_owned()
    } else {
        format!("Iterations (x 10^{})", exponent)
    };


File: criterion.rs/src/plot/gnuplot_backend/regression.rs
Start Line: 43
End Line: 68
Chunks:
    let mut figure = Figure::new();
    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .configure(Axis::BottomX, |a| {
            a.configure(Grid::Major, |g| g.show())
                .set(Label(x_label))
                .set(ScaleFactor(x_scale))
        })
        .configure(Axis::LeftY, |a| {
            a.configure(Grid::Major, |g| g.show())
                .set(Label(format!("Total sample time ({})", unit)))
        })
        .plot(
            Points {
                x: data.x().as_ref(),
                y: scaled_y.as_ref(),
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(Label("Sample"))
                    .set(PointSize(0.5))
                    .set(PointType::FilledCircle)
            },
        )

File: criterion.rs/src/plot/gnuplot_backend/regression.rs
Start Line: 68
End Line: 94
Chunks:
        .plot(
            Lines {
                x: &[0., max_iters],
                y: &[0., point],
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(LINEWIDTH)
                    .set(Label("Linear regression"))
                    .set(LineType::Solid)
            },
        )
        .plot(
            FilledCurve {
                x: &[0., max_iters],
                y1: &[0., lb],
                y2: &[0., ub],
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(Label("Confidence interval"))
                    .set(Opacity(0.25))
            },
        );
    figure
}

File: criterion.rs/src/plot/gnuplot_backend/regression.rs
Start Line: 94
End Line: 144
Chunks:

pub(crate) fn regression(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<Size>,
) -> Child {
    let mut figure = regression_figure(formatter, measurements, size);
    figure.set(Title(gnuplot_escape(id.as_title())));
    figure.configure(Key, |k| {
        k.set(Justification::Left)
            .set(Order::SampleText)
            .set(Position::Inside(Vertical::Top, Horizontal::Left))
    });

    let path = context.report_path(id, "regression.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

pub(crate) fn regression_small(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<Size>,
) -> Child {
    let mut figure = regression_figure(formatter, measurements, size);
    figure.configure(Key, |k| k.hide());

    let path = context.report_path(id, "regression_small.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

fn regression_comparison_figure(
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    base_data: &Data<'_, f64, f64>,
    size: Option<Size>,
) -> Figure {
    let data = &measurements.data;
    let max_iters = base_data.x().max().max(data.x().max());
    let typical = base_data.y().max().max(data.y().max());

    let exponent = (max_iters.log10() / 3.).floor() as i32 * 3;
    let x_scale = 10f64.powi(-exponent);


File: criterion.rs/src/plot/gnuplot_backend/regression.rs
Start Line: 144
End Line: 183
Chunks:
    let x_label = if exponent == 0 {
        "Iterations".to_owned()
    } else {
        format!("Iterations (x 10^{})", exponent)
    };

    let Estimate {
        confidence_interval:
            ConfidenceInterval {
                lower_bound: base_lb,
                upper_bound: base_ub,
                ..
            },
        point_estimate: base_point,
        ..
    } = comparison.base_estimates.slope.as_ref().unwrap();

    let Estimate {
        confidence_interval:
            ConfidenceInterval {
                lower_bound: lb,
                upper_bound: ub,
                ..
            },
        point_estimate: point,
        ..
    } = measurements.absolute_estimates.slope.as_ref().unwrap();

    let mut points = [
        base_lb * max_iters,
        base_point * max_iters,
        base_ub * max_iters,
        lb * max_iters,
        point * max_iters,
        ub * max_iters,
    ];
    let unit = formatter.scale_values(typical, &mut points);
    let [base_lb, base_point, base_ub, lb, point, ub] = points;


File: criterion.rs/src/plot/gnuplot_backend/regression.rs
Start Line: 183
End Line: 213
Chunks:
    let mut figure = Figure::new();
    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .configure(Axis::BottomX, |a| {
            a.configure(Grid::Major, |g| g.show())
                .set(Label(x_label))
                .set(ScaleFactor(x_scale))
        })
        .configure(Axis::LeftY, |a| {
            a.configure(Grid::Major, |g| g.show())
                .set(Label(format!("Total sample time ({})", unit)))
        })
        .configure(Key, |k| {
            k.set(Justification::Left)
                .set(Order::SampleText)
                .set(Position::Inside(Vertical::Top, Horizontal::Left))
        })
        .plot(
            FilledCurve {
                x: &[0., max_iters],
                y1: &[0., base_lb],
                y2: &[0., base_ub],
            },
            |c| c.set(DARK_RED).set(Opacity(0.25)),
        )
        .plot(
            FilledCurve {
                x: &[0., max_iters],
                y1: &[0., lb],

File: criterion.rs/src/plot/gnuplot_backend/regression.rs
Start Line: 213
End Line: 243
Chunks:
                y2: &[0., ub],
            },
            |c| c.set(DARK_BLUE).set(Opacity(0.25)),
        )
        .plot(
            Lines {
                x: &[0., max_iters],
                y: &[0., base_point],
            },
            |c| {
                c.set(DARK_RED)
                    .set(LINEWIDTH)
                    .set(Label("Base sample"))
                    .set(LineType::Solid)
            },
        )
        .plot(
            Lines {
                x: &[0., max_iters],
                y: &[0., point],
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(LINEWIDTH)
                    .set(Label("New sample"))
                    .set(LineType::Solid)
            },
        );
    figure
}

File: criterion.rs/src/plot/gnuplot_backend/regression.rs
Start Line: 243
End Line: 279
Chunks:

pub(crate) fn regression_comparison(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    base_data: &Data<'_, f64, f64>,
    size: Option<Size>,
) -> Child {
    let mut figure =
        regression_comparison_figure(formatter, measurements, comparison, base_data, size);
    figure.set(Title(gnuplot_escape(id.as_title())));

    let path = context.report_path(id, "both/regression.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

pub(crate) fn regression_comparison_small(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    base_data: &Data<'_, f64, f64>,
    size: Option<Size>,
) -> Child {
    let mut figure =
        regression_comparison_figure(formatter, measurements, comparison, base_data, size);
    figure.configure(Key, |k| k.hide());

    let path = context.report_path(id, "relative_regression_small.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

Ripgrep filtered Lines: [0, 48, 93, 121, 169, 219, 252, 284, 311]
File: criterion.rs/src/plot/gnuplot_backend/distributions.rs
Start Line: 0
End Line: 47
Chunks:
use std::iter;
use std::process::Child;

use crate::stats::univariate::Sample;
use crate::stats::Distribution;
use criterion_plot::prelude::*;

use super::*;
use crate::estimate::Estimate;
use crate::estimate::Statistic;
use crate::kde;
use crate::measurement::ValueFormatter;
use crate::report::{BenchmarkId, ComparisonData, MeasurementData, ReportContext};

fn abs_distribution(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    statistic: Statistic,
    distribution: &Distribution<f64>,
    estimate: &Estimate,
    size: Option<Size>,
) -> Child {
    let ci = &estimate.confidence_interval;
    let typical = ci.upper_bound;
    let mut ci_values = [ci.lower_bound, ci.upper_bound, estimate.point_estimate];
    let unit = formatter.scale_values(typical, &mut ci_values);
    let (lb, ub, point) = (ci_values[0], ci_values[1], ci_values[2]);

    let start = lb - (ub - lb) / 9.;
    let end = ub + (ub - lb) / 9.;
    let mut scaled_xs: Vec<f64> = distribution.iter().cloned().collect();
    let _ = formatter.scale_values(typical, &mut scaled_xs);
    let scaled_xs_sample = Sample::new(&scaled_xs);
    let (kde_xs, ys) = kde::sweep(scaled_xs_sample, KDE_POINTS, Some((start, end)));

    // interpolate between two points of the KDE sweep to find the Y position at the point estimate.
    let n_point = kde_xs
        .iter()
        .position(|&x| x >= point)
        .unwrap_or(kde_xs.len() - 1)
        .max(1); // Must be at least the second element or this will panic
    let slope = (ys[n_point] - ys[n_point - 1]) / (kde_xs[n_point] - kde_xs[n_point - 1]);
    let y_point = ys[n_point - 1] + (slope * (point - kde_xs[n_point - 1]));

    let zero = iter::repeat(0);


File: criterion.rs/src/plot/gnuplot_backend/distributions.rs
Start Line: 47
End Line: 92
Chunks:
    let start = kde_xs
        .iter()
        .enumerate()
        .find(|&(_, &x)| x >= lb)
        .unwrap()
        .0;
    let end = kde_xs
        .iter()
        .enumerate()
        .rev()
        .find(|&(_, &x)| x <= ub)
        .unwrap()
        .0;
    let len = end - start;

    let kde_xs_sample = Sample::new(&kde_xs);

    let mut figure = Figure::new();
    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .set(Title(format!(
            "{}: {}",
            gnuplot_escape(id.as_title()),
            statistic
        )))
        .configure(Axis::BottomX, |a| {
            a.set(Label(format!("Average time ({})", unit)))
                .set(Range::Limits(kde_xs_sample.min(), kde_xs_sample.max()))
        })
        .configure(Axis::LeftY, |a| a.set(Label("Density (a.u.)")))
        .configure(Key, |k| {
            k.set(Justification::Left)
                .set(Order::SampleText)
                .set(Position::Outside(Vertical::Top, Horizontal::Right))
        })
        .plot(
            Lines {
                x: &*kde_xs,
                y: &*ys,
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(LINEWIDTH)
                    .set(Label("Bootstrap distribution"))

File: criterion.rs/src/plot/gnuplot_backend/distributions.rs
Start Line: 92
End Line: 120
Chunks:
                    .set(LineType::Solid)
            },
        )
        .plot(
            FilledCurve {
                x: kde_xs.iter().skip(start).take(len),
                y1: ys.iter().skip(start),
                y2: zero,
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(Label("Confidence interval"))
                    .set(Opacity(0.25))
            },
        )
        .plot(
            Lines {
                x: &[point, point],
                y: &[0., y_point],
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(LINEWIDTH)
                    .set(Label("Point estimate"))
                    .set(LineType::Dash)
            },
        );


File: criterion.rs/src/plot/gnuplot_backend/distributions.rs
Start Line: 120
End Line: 168
Chunks:
    let path = context.report_path(id, &format!("{}.svg", statistic));
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

pub(crate) fn abs_distributions(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<Size>,
) -> Vec<Child> {
    crate::plot::REPORT_STATS
        .iter()
        .filter_map(|stat| {
            measurements.distributions.get(*stat).and_then(|dist| {
                measurements
                    .absolute_estimates
                    .get(*stat)
                    .map(|est| (*stat, dist, est))
            })
        })
        .map(|(statistic, distribution, estimate)| {
            abs_distribution(
                id,
                context,
                formatter,
                statistic,
                distribution,
                estimate,
                size,
            )
        })
        .collect::<Vec<_>>()
}

fn rel_distribution(
    id: &BenchmarkId,
    context: &ReportContext,
    statistic: Statistic,
    distribution: &Distribution<f64>,
    estimate: &Estimate,
    noise_threshold: f64,
    size: Option<Size>,
) -> Child {
    let ci = &estimate.confidence_interval;
    let (lb, ub) = (ci.lower_bound, ci.upper_bound);


File: criterion.rs/src/plot/gnuplot_backend/distributions.rs
Start Line: 168
End Line: 218
Chunks:
    let start = lb - (ub - lb) / 9.;
    let end = ub + (ub - lb) / 9.;
    let (xs, ys) = kde::sweep(distribution, KDE_POINTS, Some((start, end)));
    let xs_ = Sample::new(&xs);

    // interpolate between two points of the KDE sweep to find the Y position at the point estimate.
    let point = estimate.point_estimate;
    let n_point = xs
        .iter()
        .position(|&x| x >= point)
        .unwrap_or(ys.len() - 1)
        .max(1);
    let slope = (ys[n_point] - ys[n_point - 1]) / (xs[n_point] - xs[n_point - 1]);
    let y_point = ys[n_point - 1] + (slope * (point - xs[n_point - 1]));

    let one = iter::repeat(1);
    let zero = iter::repeat(0);

    let start = xs.iter().enumerate().find(|&(_, &x)| x >= lb).unwrap().0;
    let end = xs
        .iter()
        .enumerate()
        .rev()
        .find(|&(_, &x)| x <= ub)
        .unwrap()
        .0;
    let len = end - start;

    let x_min = xs_.min();
    let x_max = xs_.max();

    let (fc_start, fc_end) = if noise_threshold < x_min || -noise_threshold > x_max {
        let middle = (x_min + x_max) / 2.;

        (middle, middle)
    } else {
        (
            if -noise_threshold < x_min {
                x_min
            } else {
                -noise_threshold
            },
            if noise_threshold > x_max {
                x_max
            } else {
                noise_threshold
            },
        )
    };


File: criterion.rs/src/plot/gnuplot_backend/distributions.rs
Start Line: 218
End Line: 251
Chunks:
    let mut figure = Figure::new();

    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .configure(Axis::LeftY, |a| a.set(Label("Density (a.u.)")))
        .configure(Key, |k| {
            k.set(Justification::Left)
                .set(Order::SampleText)
                .set(Position::Outside(Vertical::Top, Horizontal::Right))
        })
        .set(Title(format!(
            "{}: {}",
            gnuplot_escape(id.as_title()),
            statistic
        )))
        .configure(Axis::BottomX, |a| {
            a.set(Label("Relative change (%)"))
                .set(Range::Limits(x_min * 100., x_max * 100.))
                .set(ScaleFactor(100.))
        })
        .plot(Lines { x: &*xs, y: &*ys }, |c| {
            c.set(DARK_BLUE)
                .set(LINEWIDTH)
                .set(Label("Bootstrap distribution"))
                .set(LineType::Solid)
        })
        .plot(
            FilledCurve {
                x: xs.iter().skip(start).take(len),
                y1: ys.iter().skip(start),
                y2: zero.clone(),
            },

File: criterion.rs/src/plot/gnuplot_backend/distributions.rs
Start Line: 251
End Line: 283
Chunks:
            |c| {
                c.set(DARK_BLUE)
                    .set(Label("Confidence interval"))
                    .set(Opacity(0.25))
            },
        )
        .plot(
            Lines {
                x: &[point, point],
                y: &[0., y_point],
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(LINEWIDTH)
                    .set(Label("Point estimate"))
                    .set(LineType::Dash)
            },
        )
        .plot(
            FilledCurve {
                x: &[fc_start, fc_end],
                y1: one,
                y2: zero,
            },
            |c| {
                c.set(Axes::BottomXRightY)
                    .set(DARK_RED)
                    .set(Label("Noise threshold"))
                    .set(Opacity(0.1))
            },
        );


File: criterion.rs/src/plot/gnuplot_backend/distributions.rs
Start Line: 283
End Line: 310
Chunks:
    let path = context.report_path(id, &format!("change/{}.svg", statistic));
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

pub(crate) fn rel_distributions(
    id: &BenchmarkId,
    context: &ReportContext,
    _measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<Size>,
) -> Vec<Child> {
    crate::plot::CHANGE_STATS
        .iter()
        .map(|&statistic| {
            rel_distribution(
                id,
                context,
                statistic,
                comparison.relative_distributions.get(statistic),
                comparison.relative_estimates.get(statistic),
                comparison.noise_threshold,
                size,
            )
        })
        .collect::<Vec<_>>()
}

Ripgrep filtered Lines: [0, 45, 89, 133, 177, 222, 248, 288, 317, 363, 393]
File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 0
End Line: 44
Chunks:
use super::*;
use crate::kde;
use crate::measurement::ValueFormatter;
use crate::report::{BenchmarkId, ComparisonData, MeasurementData, ReportContext};
use std::process::Child;

pub(crate) fn pdf(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<Size>,
) -> Child {
    let avg_times = &measurements.avg_times;
    let typical = avg_times.max();
    let mut scaled_avg_times: Vec<f64> = (avg_times as &Sample<f64>).iter().cloned().collect();
    let unit = formatter.scale_values(typical, &mut scaled_avg_times);
    let scaled_avg_times = Sample::new(&scaled_avg_times);

    let mean = scaled_avg_times.mean();

    let iter_counts = measurements.iter_counts();
    let &max_iters = iter_counts
        .iter()
        .max_by_key(|&&iters| iters as u64)
        .unwrap();
    let exponent = (max_iters.log10() / 3.).floor() as i32 * 3;
    let y_scale = 10f64.powi(-exponent);

    let y_label = if exponent == 0 {
        "Iterations".to_owned()
    } else {
        format!("Iterations (x 10^{})", exponent)
    };

    let (xs, ys) = kde::sweep(scaled_avg_times, KDE_POINTS, None);
    let (lost, lomt, himt, hist) = avg_times.fences();
    let mut fences = [lost, lomt, himt, hist];
    let _ = formatter.scale_values(typical, &mut fences);
    let [lost, lomt, himt, hist] = fences;

    let vertical = &[0., max_iters];
    let zeros = iter::repeat(0);


File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 44
End Line: 88
Chunks:
    let mut figure = Figure::new();
    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .configure(Axis::BottomX, |a| {
            let xs_ = Sample::new(&xs);
            a.set(Label(format!("Average time ({})", unit)))
                .set(Range::Limits(xs_.min(), xs_.max()))
        })
        .configure(Axis::LeftY, |a| {
            a.set(Label(y_label))
                .set(Range::Limits(0., max_iters * y_scale))
                .set(ScaleFactor(y_scale))
        })
        .configure(Axis::RightY, |a| a.set(Label("Density (a.u.)")))
        .configure(Key, |k| {
            k.set(Justification::Left)
                .set(Order::SampleText)
                .set(Position::Outside(Vertical::Top, Horizontal::Right))
        })
        .plot(
            FilledCurve {
                x: &*xs,
                y1: &*ys,
                y2: zeros,
            },
            |c| {
                c.set(Axes::BottomXRightY)
                    .set(DARK_BLUE)
                    .set(Label("PDF"))
                    .set(Opacity(0.25))
            },
        )
        .plot(
            Lines {
                x: &[mean, mean],
                y: vertical,
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(LINEWIDTH)
                    .set(LineType::Dash)
                    .set(Label("Mean"))
            },

File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 88
End Line: 132
Chunks:
        )
        .plot(
            Points {
                x: avg_times
                    .iter()
                    .zip(scaled_avg_times.iter())
                    .filter_map(
                        |((_, label), t)| {
                            if label.is_outlier() {
                                None
                            } else {
                                Some(t)
                            }
                        },
                    ),
                y: avg_times
                    .iter()
                    .zip(iter_counts.iter())
                    .filter_map(
                        |((_, label), i)| {
                            if label.is_outlier() {
                                None
                            } else {
                                Some(i)
                            }
                        },
                    ),
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(Label("\"Clean\" sample"))
                    .set(PointType::FilledCircle)
                    .set(POINT_SIZE)
            },
        )
        .plot(
            Points {
                x: avg_times
                    .iter()
                    .zip(scaled_avg_times.iter())
                    .filter_map(
                        |((_, label), t)| {
                            if label.is_mild() {
                                Some(t)

File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 132
End Line: 176
Chunks:
                            } else {
                                None
                            }
                        },
                    ),
                y: avg_times
                    .iter()
                    .zip(iter_counts.iter())
                    .filter_map(
                        |((_, label), i)| {
                            if label.is_mild() {
                                Some(i)
                            } else {
                                None
                            }
                        },
                    ),
            },
            |c| {
                c.set(DARK_ORANGE)
                    .set(Label("Mild outliers"))
                    .set(POINT_SIZE)
                    .set(PointType::FilledCircle)
            },
        )
        .plot(
            Points {
                x: avg_times
                    .iter()
                    .zip(scaled_avg_times.iter())
                    .filter_map(
                        |((_, label), t)| {
                            if label.is_severe() {
                                Some(t)
                            } else {
                                None
                            }
                        },
                    ),
                y: avg_times
                    .iter()
                    .zip(iter_counts.iter())
                    .filter_map(
                        |((_, label), i)| {

File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 176
End Line: 221
Chunks:
                            if label.is_severe() {
                                Some(i)
                            } else {
                                None
                            }
                        },
                    ),
            },
            |c| {
                c.set(DARK_RED)
                    .set(Label("Severe outliers"))
                    .set(POINT_SIZE)
                    .set(PointType::FilledCircle)
            },
        )
        .plot(
            Lines {
                x: &[lomt, lomt],
                y: vertical,
            },
            |c| c.set(DARK_ORANGE).set(LINEWIDTH).set(LineType::Dash),
        )
        .plot(
            Lines {
                x: &[himt, himt],
                y: vertical,
            },
            |c| c.set(DARK_ORANGE).set(LINEWIDTH).set(LineType::Dash),
        )
        .plot(
            Lines {
                x: &[lost, lost],
                y: vertical,
            },
            |c| c.set(DARK_RED).set(LINEWIDTH).set(LineType::Dash),
        )
        .plot(
            Lines {
                x: &[hist, hist],
                y: vertical,
            },
            |c| c.set(DARK_RED).set(LINEWIDTH).set(LineType::Dash),
        );
    figure.set(Title(gnuplot_escape(id.as_title())));


File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 221
End Line: 247
Chunks:
    let path = context.report_path(id, "pdf.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

pub(crate) fn pdf_small(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<Size>,
) -> Child {
    let avg_times = &*measurements.avg_times;
    let typical = avg_times.max();
    let mut scaled_avg_times: Vec<f64> = (avg_times as &Sample<f64>).iter().cloned().collect();
    let unit = formatter.scale_values(typical, &mut scaled_avg_times);
    let scaled_avg_times = Sample::new(&scaled_avg_times);
    let mean = scaled_avg_times.mean();

    let (xs, ys, mean_y) = kde::sweep_and_estimate(scaled_avg_times, KDE_POINTS, None, mean);
    let xs_ = Sample::new(&xs);
    let ys_ = Sample::new(&ys);

    let y_limit = ys_.max() * 1.1;
    let zeros = iter::repeat(0);


File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 247
End Line: 287
Chunks:
    let mut figure = Figure::new();
    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .configure(Axis::BottomX, |a| {
            a.set(Label(format!("Average time ({})", unit)))
                .set(Range::Limits(xs_.min(), xs_.max()))
        })
        .configure(Axis::LeftY, |a| {
            a.set(Label("Density (a.u.)"))
                .set(Range::Limits(0., y_limit))
        })
        .configure(Axis::RightY, |a| a.hide())
        .configure(Key, |k| k.hide())
        .plot(
            FilledCurve {
                x: &*xs,
                y1: &*ys,
                y2: zeros,
            },
            |c| {
                c.set(Axes::BottomXRightY)
                    .set(DARK_BLUE)
                    .set(Label("PDF"))
                    .set(Opacity(0.25))
            },
        )
        .plot(
            Lines {
                x: &[mean, mean],
                y: &[0., mean_y],
            },
            |c| c.set(DARK_BLUE).set(LINEWIDTH).set(Label("Mean")),
        );

    let path = context.report_path(id, "pdf_small.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}


File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 287
End Line: 316
Chunks:
fn pdf_comparison_figure(
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<Size>,
) -> Figure {
    let base_avg_times = Sample::new(&comparison.base_avg_times);
    let typical = base_avg_times.max().max(measurements.avg_times.max());
    let mut scaled_base_avg_times: Vec<f64> = comparison.base_avg_times.clone();
    let unit = formatter.scale_values(typical, &mut scaled_base_avg_times);
    let scaled_base_avg_times = Sample::new(&scaled_base_avg_times);

    let mut scaled_new_avg_times: Vec<f64> = (&measurements.avg_times as &Sample<f64>)
        .iter()
        .cloned()
        .collect();
    let _ = formatter.scale_values(typical, &mut scaled_new_avg_times);
    let scaled_new_avg_times = Sample::new(&scaled_new_avg_times);

    let base_mean = scaled_base_avg_times.mean();
    let new_mean = scaled_new_avg_times.mean();

    let (base_xs, base_ys, base_y_mean) =
        kde::sweep_and_estimate(scaled_base_avg_times, KDE_POINTS, None, base_mean);
    let (xs, ys, y_mean) =
        kde::sweep_and_estimate(scaled_new_avg_times, KDE_POINTS, None, new_mean);

    let zeros = iter::repeat(0);


File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 316
End Line: 362
Chunks:
    let mut figure = Figure::new();
    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .configure(Axis::BottomX, |a| {
            a.set(Label(format!("Average time ({})", unit)))
        })
        .configure(Axis::LeftY, |a| a.set(Label("Density (a.u.)")))
        .configure(Axis::RightY, |a| a.hide())
        .configure(Key, |k| {
            k.set(Justification::Left)
                .set(Order::SampleText)
                .set(Position::Outside(Vertical::Top, Horizontal::Right))
        })
        .plot(
            FilledCurve {
                x: &*base_xs,
                y1: &*base_ys,
                y2: zeros.clone(),
            },
            |c| c.set(DARK_RED).set(Label("Base PDF")).set(Opacity(0.5)),
        )
        .plot(
            Lines {
                x: &[base_mean, base_mean],
                y: &[0., base_y_mean],
            },
            |c| c.set(DARK_RED).set(Label("Base Mean")).set(LINEWIDTH),
        )
        .plot(
            FilledCurve {
                x: &*xs,
                y1: &*ys,
                y2: zeros,
            },
            |c| c.set(DARK_BLUE).set(Label("New PDF")).set(Opacity(0.5)),
        )
        .plot(
            Lines {
                x: &[new_mean, new_mean],
                y: &[0., y_mean],
            },
            |c| c.set(DARK_BLUE).set(Label("New Mean")).set(LINEWIDTH),
        );
    figure
}

File: criterion.rs/src/plot/gnuplot_backend/pdf.rs
Start Line: 362
End Line: 392
Chunks:

pub(crate) fn pdf_comparison(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<Size>,
) -> Child {
    let mut figure = pdf_comparison_figure(formatter, measurements, comparison, size);
    figure.set(Title(gnuplot_escape(id.as_title())));
    let path = context.report_path(id, "both/pdf.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

pub(crate) fn pdf_comparison_small(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<Size>,
) -> Child {
    let mut figure = pdf_comparison_figure(formatter, measurements, comparison, size);
    figure.configure(Key, |k| k.hide());
    let path = context.report_path(id, "relative_pdf_small.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

Ripgrep filtered Lines: [0, 45, 80, 96, 142, 174]
File: criterion.rs/src/plot/gnuplot_backend/iteration_times.rs
Start Line: 0
End Line: 44
Chunks:
use std::process::Child;

use criterion_plot::prelude::*;

use super::*;
use crate::report::{BenchmarkId, ComparisonData, MeasurementData, ReportContext};

use crate::measurement::ValueFormatter;

fn iteration_times_figure(
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<Size>,
) -> Figure {
    let data = &measurements.avg_times;
    let max_avg_time = data.max();
    let mut scaled_y: Vec<_> = data.iter().map(|(f, _)| f).collect();
    let unit = formatter.scale_values(max_avg_time, &mut scaled_y);
    let scaled_y = Sample::new(&scaled_y);

    let mut figure = Figure::new();
    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .configure(Axis::BottomX, |a| {
            a.configure(Grid::Major, |g| g.show()).set(Label("Sample"))
        })
        .configure(Axis::LeftY, |a| {
            a.configure(Grid::Major, |g| g.show())
                .set(Label(format!("Average Iteration Time ({})", unit)))
        })
        .plot(
            Points {
                x: 1..(data.len() + 1),
                y: scaled_y.as_ref(),
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(PointSize(0.5))
                    .set(PointType::FilledCircle)
            },
        );
    figure
}

File: criterion.rs/src/plot/gnuplot_backend/iteration_times.rs
Start Line: 44
End Line: 79
Chunks:

pub(crate) fn iteration_times(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<Size>,
) -> Child {
    let mut figure = iteration_times_figure(formatter, measurements, size);
    figure.set(Title(gnuplot_escape(id.as_title())));
    figure.configure(Key, |k| {
        k.set(Justification::Left)
            .set(Order::SampleText)
            .set(Position::Inside(Vertical::Top, Horizontal::Left))
    });

    let path = context.report_path(id, "iteration_times.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

pub(crate) fn iteration_times_small(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    size: Option<Size>,
) -> Child {
    let mut figure = iteration_times_figure(formatter, measurements, size);
    figure.configure(Key, |k| k.hide());

    let path = context.report_path(id, "iteration_times_small.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

File: criterion.rs/src/plot/gnuplot_backend/iteration_times.rs
Start Line: 79
End Line: 95
Chunks:

fn iteration_times_comparison_figure(
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<Size>,
) -> Figure {
    let current_data = &measurements.avg_times;
    let base_data = &comparison.base_avg_times;

    let mut all_data: Vec<f64> = current_data.iter().map(|(f, _)| f).collect();
    all_data.extend_from_slice(base_data);

    let typical_value = Sample::new(&all_data).max();
    let unit = formatter.scale_values(typical_value, &mut all_data);


File: criterion.rs/src/plot/gnuplot_backend/iteration_times.rs
Start Line: 95
End Line: 141
Chunks:
    let (scaled_current_y, scaled_base_y) = all_data.split_at(current_data.len());
    let scaled_current_y = Sample::new(scaled_current_y);
    let scaled_base_y = Sample::new(scaled_base_y);

    let mut figure = Figure::new();
    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .configure(Axis::BottomX, |a| {
            a.configure(Grid::Major, |g| g.show()).set(Label("Sample"))
        })
        .configure(Axis::LeftY, |a| {
            a.configure(Grid::Major, |g| g.show())
                .set(Label(format!("Average Iteration Time ({})", unit)))
        })
        .configure(Key, |k| {
            k.set(Justification::Left)
                .set(Order::SampleText)
                .set(Position::Inside(Vertical::Top, Horizontal::Left))
        })
        .plot(
            Points {
                x: 1..(current_data.len() + 1),
                y: scaled_base_y.as_ref(),
            },
            |c| {
                c.set(DARK_RED)
                    .set(Label("Base"))
                    .set(PointSize(0.5))
                    .set(PointType::FilledCircle)
            },
        )
        .plot(
            Points {
                x: 1..(current_data.len() + 1),
                y: scaled_current_y.as_ref(),
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(Label("Current"))
                    .set(PointSize(0.5))
                    .set(PointType::FilledCircle)
            },
        );
    figure
}

File: criterion.rs/src/plot/gnuplot_backend/iteration_times.rs
Start Line: 141
End Line: 173
Chunks:

pub(crate) fn iteration_times_comparison(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<Size>,
) -> Child {
    let mut figure = iteration_times_comparison_figure(formatter, measurements, comparison, size);
    figure.set(Title(gnuplot_escape(id.as_title())));

    let path = context.report_path(id, "both/iteration_times.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

pub(crate) fn iteration_times_comparison_small(
    id: &BenchmarkId,
    context: &ReportContext,
    formatter: &dyn ValueFormatter,
    measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<Size>,
) -> Child {
    let mut figure = iteration_times_comparison_figure(formatter, measurements, comparison, size);
    figure.configure(Key, |k| k.hide());

    let path = context.report_path(id, "relative_iteration_times_small.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

Ripgrep filtered Lines: [0, 34, 53, 103, 119, 159, 207, 210]
File: criterion.rs/src/plot/gnuplot_backend/summary.rs
Start Line: 0
End Line: 33
Chunks:
use super::{debug_script, gnuplot_escape};
use super::{DARK_BLUE, DEFAULT_FONT, KDE_POINTS, LINEWIDTH, POINT_SIZE, SIZE};
use crate::kde;
use crate::measurement::ValueFormatter;
use crate::report::{BenchmarkId, ValueType};
use crate::stats::univariate::Sample;
use crate::AxisScale;
use criterion_plot::prelude::*;
use itertools::Itertools;
use std::cmp::Ordering;
use std::path::{Path, PathBuf};
use std::process::Child;

const NUM_COLORS: usize = 8;
static COMPARISON_COLORS: [Color; NUM_COLORS] = [
    Color::Rgb(178, 34, 34),
    Color::Rgb(46, 139, 87),
    Color::Rgb(0, 139, 139),
    Color::Rgb(255, 215, 0),
    Color::Rgb(0, 0, 139),
    Color::Rgb(220, 20, 60),
    Color::Rgb(139, 0, 139),
    Color::Rgb(0, 255, 127),
];

impl AxisScale {
    fn to_gnuplot(self) -> Scale {
        match self {
            AxisScale::Linear => Scale::Linear,
            AxisScale::Logarithmic => Scale::Logarithmic,
        }
    }
}

File: criterion.rs/src/plot/gnuplot_backend/summary.rs
Start Line: 33
End Line: 52
Chunks:

#[cfg_attr(feature = "cargo-clippy", allow(clippy::explicit_counter_loop))]
pub fn line_comparison(
    formatter: &dyn ValueFormatter,
    title: &str,
    all_curves: &[&(&BenchmarkId, Vec<f64>)],
    path: &Path,
    value_type: ValueType,
    axis_scale: AxisScale,
) -> Child {
    let path = PathBuf::from(path);
    let mut f = Figure::new();

    let input_suffix = match value_type {
        ValueType::Bytes => " Size (Bytes)",
        ValueType::Elements => " Size (Elements)",
        ValueType::Value => "",
    };


File: criterion.rs/src/plot/gnuplot_backend/summary.rs
Start Line: 52
End Line: 102
Chunks:
    f.set(Font(DEFAULT_FONT))
        .set(SIZE)
        .configure(Key, |k| {
            k.set(Justification::Left)
                .set(Order::SampleText)
                .set(Position::Outside(Vertical::Top, Horizontal::Right))
        })
        .set(Title(format!("{}: Comparison", gnuplot_escape(title))))
        .configure(Axis::BottomX, |a| {
            a.set(Label(format!("Input{}", input_suffix)))
                .set(axis_scale.to_gnuplot())
        });

    let mut i = 0;

    let max = all_curves
        .iter()
        .map(|&(_, data)| Sample::new(data).mean())
        .fold(::std::f64::NAN, f64::max);

    let mut dummy = [1.0];
    let unit = formatter.scale_values(max, &mut dummy);

    f.configure(Axis::LeftY, |a| {
        a.configure(Grid::Major, |g| g.show())
            .configure(Grid::Minor, |g| g.hide())
            .set(Label(format!("Average time ({})", unit)))
            .set(axis_scale.to_gnuplot())
    });

    // This assumes the curves are sorted. It also assumes that the benchmark IDs all have numeric
    // values or throughputs and that value is sensible (ie. not a mix of bytes and elements
    // or whatnot)
    for (key, group) in &all_curves.iter().group_by(|&&&(id, _)| &id.function_id) {
        let mut tuples: Vec<_> = group
            .map(|&&(id, ref sample)| {
                // Unwrap is fine here because it will only fail if the assumptions above are not true
                // ie. programmer error.
                let x = id.as_number().unwrap();
                let y = Sample::new(sample).mean();

                (x, y)
            })
            .collect();
        tuples.sort_by(|&(ax, _), &(bx, _)| (ax.partial_cmp(&bx).unwrap_or(Ordering::Less)));
        let (xs, mut ys): (Vec<_>, Vec<_>) = tuples.into_iter().unzip();
        formatter.scale_values(max, &mut ys);

        let function_name = key.as_ref().map(|string| gnuplot_escape(string));


File: criterion.rs/src/plot/gnuplot_backend/summary.rs
Start Line: 102
End Line: 118
Chunks:
        f.plot(Lines { x: &xs, y: &ys }, |c| {
            if let Some(name) = function_name {
                c.set(Label(name));
            }
            c.set(LINEWIDTH)
                .set(LineType::Solid)
                .set(COMPARISON_COLORS[i % NUM_COLORS])
        })
        .plot(Points { x: &xs, y: &ys }, |p| {
            p.set(PointType::FilledCircle)
                .set(POINT_SIZE)
                .set(COMPARISON_COLORS[i % NUM_COLORS])
        });

        i += 1;
    }

File: criterion.rs/src/plot/gnuplot_backend/summary.rs
Start Line: 118
End Line: 158
Chunks:

    debug_script(&path, &f);
    f.set(Output(path)).draw().unwrap()
}

pub fn violin(
    formatter: &dyn ValueFormatter,
    title: &str,
    all_curves: &[&(&BenchmarkId, Vec<f64>)],
    path: &Path,
    axis_scale: AxisScale,
) -> Child {
    let path = PathBuf::from(&path);
    let all_curves_vec = all_curves.iter().rev().cloned().collect::<Vec<_>>();
    let all_curves: &[&(&BenchmarkId, Vec<f64>)] = &all_curves_vec;

    let kdes = all_curves
        .iter()
        .map(|&(_, sample)| {
            let (x, mut y) = kde::sweep(Sample::new(sample), KDE_POINTS, None);
            let y_max = Sample::new(&y).max();
            for y in y.iter_mut() {
                *y /= y_max;
            }

            (x, y)
        })
        .collect::<Vec<_>>();
    let mut xs = kdes.iter().flat_map(|(x, _)| x.iter()).filter(|&&x| x > 0.);
    let (mut min, mut max) = {
        let &first = xs.next().unwrap();
        (first, first)
    };
    for &e in xs {
        if e < min {
            min = e;
        } else if e > max {
            max = e;
        }
    }

File: criterion.rs/src/plot/gnuplot_backend/summary.rs
Start Line: 158
End Line: 206
Chunks:
    let mut one = [1.0];
    // Scale the X axis units. Use the middle as a "typical value". E.g. if
    // it is 0.002 s then this function will decide that milliseconds are an
    // appropriate unit. It will multiple `one` by 1000, and return "ms".
    let unit = formatter.scale_values((min + max) / 2.0, &mut one);

    let tics = || (0..).map(|x| (f64::from(x)) + 0.5);
    let size = Size(1280, 200 + (25 * all_curves.len()));
    let mut f = Figure::new();
    f.set(Font(DEFAULT_FONT))
        .set(size)
        .set(Title(format!("{}: Violin plot", gnuplot_escape(title))))
        .configure(Axis::BottomX, |a| {
            a.configure(Grid::Major, |g| g.show())
                .configure(Grid::Minor, |g| g.hide())
                .set(Range::Limits(0., max * one[0]))
                .set(Label(format!("Average time ({})", unit)))
                .set(axis_scale.to_gnuplot())
        })
        .configure(Axis::LeftY, |a| {
            a.set(Label("Input"))
                .set(Range::Limits(0., all_curves.len() as f64))
                .set(TicLabels {
                    positions: tics(),
                    labels: all_curves
                        .iter()
                        .map(|&&(id, _)| gnuplot_escape(id.as_title())),
                })
        });

    let mut is_first = true;
    for (i, (x, y)) in kdes.iter().enumerate() {
        let i = i as f64 + 0.5;
        let y1: Vec<_> = y.iter().map(|&y| i + y * 0.45).collect();
        let y2: Vec<_> = y.iter().map(|&y| i - y * 0.45).collect();

        let x: Vec<_> = x.iter().map(|&x| x * one[0]).collect();

        f.plot(FilledCurve { x, y1, y2 }, |c| {
            if is_first {
                is_first = false;

                c.set(DARK_BLUE).set(Label("PDF"))
            } else {
                c.set(DARK_BLUE)
            }
        });
    }

File: criterion.rs/src/plot/gnuplot_backend/summary.rs
Start Line: 206
End Line: 209
Chunks:
    debug_script(&path, &f);
    f.set(Output(path)).draw().unwrap()
}

Ripgrep filtered Lines: [0, 31, 73, 103, 136, 176, 219, 255]
File: criterion.rs/src/plot/gnuplot_backend/mod.rs
Start Line: 0
End Line: 30
Chunks:
use std::iter;
use std::path::Path;
use std::process::Child;

use crate::stats::univariate::Sample;
use criterion_plot::prelude::*;

mod distributions;
mod iteration_times;
mod pdf;
mod regression;
mod summary;
mod t_test;
use self::distributions::*;
use self::iteration_times::*;
use self::pdf::*;
use self::regression::*;
use self::summary::*;
use self::t_test::*;

use crate::measurement::ValueFormatter;
use crate::report::{BenchmarkId, ValueType};
use crate::stats::bivariate::Data;

use super::{PlotContext, PlotData, Plotter};
use crate::format;

fn gnuplot_escape(string: &str) -> String {
    string.replace('_', "\\_").replace('\'', "''")
}

File: criterion.rs/src/plot/gnuplot_backend/mod.rs
Start Line: 30
End Line: 72
Chunks:

static DEFAULT_FONT: &str = "Helvetica";
static KDE_POINTS: usize = 500;
static SIZE: Size = Size(1280, 720);

const LINEWIDTH: LineWidth = LineWidth(2.);
const POINT_SIZE: PointSize = PointSize(0.75);

const DARK_BLUE: Color = Color::Rgb(31, 120, 180);
const DARK_ORANGE: Color = Color::Rgb(255, 127, 0);
const DARK_RED: Color = Color::Rgb(227, 26, 28);

fn debug_script(path: &Path, figure: &Figure) {
    if crate::debug_enabled() {
        let mut script_path = path.to_path_buf();
        script_path.set_extension("gnuplot");
        info!("Writing gnuplot script to {:?}", script_path);
        let result = figure.save(script_path.as_path());
        if let Err(e) = result {
            error!("Failed to write debug output: {}", e);
        }
    }
}

/// Private
trait Append<T> {
    /// Private
    fn append_(self, item: T) -> Self;
}

// NB I wish this was in the standard library
impl<T> Append<T> for Vec<T> {
    fn append_(mut self, item: T) -> Vec<T> {
        self.push(item);
        self
    }
}

#[derive(Default)]
pub(crate) struct Gnuplot {
    process_list: Vec<Child>,
}

File: criterion.rs/src/plot/gnuplot_backend/mod.rs
Start Line: 72
End Line: 102
Chunks:

impl Plotter for Gnuplot {
    fn pdf(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        let size = ctx.size.map(|(w, h)| Size(w, h));
        self.process_list.push(if ctx.is_thumbnail {
            if let Some(cmp) = data.comparison {
                pdf_comparison_small(
                    ctx.id,
                    ctx.context,
                    data.formatter,
                    data.measurements,
                    cmp,
                    size,
                )
            } else {
                pdf_small(ctx.id, ctx.context, data.formatter, data.measurements, size)
            }
        } else if let Some(cmp) = data.comparison {
            pdf_comparison(
                ctx.id,
                ctx.context,
                data.formatter,
                data.measurements,
                cmp,
                size,
            )
        } else {
            pdf(ctx.id, ctx.context, data.formatter, data.measurements, size)
        });
    }

File: criterion.rs/src/plot/gnuplot_backend/mod.rs
Start Line: 102
End Line: 135
Chunks:

    fn regression(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        let size = ctx.size.map(|(w, h)| Size(w, h));
        self.process_list.push(if ctx.is_thumbnail {
            if let Some(cmp) = data.comparison {
                let base_data = Data::new(&cmp.base_iter_counts, &cmp.base_sample_times);
                regression_comparison_small(
                    ctx.id,
                    ctx.context,
                    data.formatter,
                    data.measurements,
                    cmp,
                    &base_data,
                    size,
                )
            } else {
                regression_small(ctx.id, ctx.context, data.formatter, data.measurements, size)
            }
        } else if let Some(cmp) = data.comparison {
            let base_data = Data::new(&cmp.base_iter_counts, &cmp.base_sample_times);
            regression_comparison(
                ctx.id,
                ctx.context,
                data.formatter,
                data.measurements,
                cmp,
                &base_data,
                size,
            )
        } else {
            regression(ctx.id, ctx.context, data.formatter, data.measurements, size)
        });
    }

File: criterion.rs/src/plot/gnuplot_backend/mod.rs
Start Line: 135
End Line: 175
Chunks:

    fn iteration_times(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        let size = ctx.size.map(|(w, h)| Size(w, h));
        self.process_list.push(if ctx.is_thumbnail {
            if let Some(cmp) = data.comparison {
                iteration_times_comparison_small(
                    ctx.id,
                    ctx.context,
                    data.formatter,
                    data.measurements,
                    cmp,
                    size,
                )
            } else {
                iteration_times_small(ctx.id, ctx.context, data.formatter, data.measurements, size)
            }
        } else if let Some(cmp) = data.comparison {
            iteration_times_comparison(
                ctx.id,
                ctx.context,
                data.formatter,
                data.measurements,
                cmp,
                size,
            )
        } else {
            iteration_times(ctx.id, ctx.context, data.formatter, data.measurements, size)
        });
    }

    fn abs_distributions(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        let size = ctx.size.map(|(w, h)| Size(w, h));
        self.process_list.extend(abs_distributions(
            ctx.id,
            ctx.context,
            data.formatter,
            data.measurements,
            size,
        ));
    }

File: criterion.rs/src/plot/gnuplot_backend/mod.rs
Start Line: 175
End Line: 218
Chunks:

    fn rel_distributions(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        let size = ctx.size.map(|(w, h)| Size(w, h));
        if let Some(cmp) = data.comparison {
            self.process_list.extend(rel_distributions(
                ctx.id,
                ctx.context,
                data.measurements,
                cmp,
                size,
            ));
        } else {
            error!("Comparison data is not provided for a relative distribution figure");
        }
    }

    fn t_test(&mut self, ctx: PlotContext<'_>, data: PlotData<'_>) {
        let size = ctx.size.map(|(w, h)| Size(w, h));
        if let Some(cmp) = data.comparison {
            self.process_list
                .push(t_test(ctx.id, ctx.context, data.measurements, cmp, size));
        } else {
            error!("Comparison data is not provided for t_test plot");
        }
    }

    fn line_comparison(
        &mut self,
        ctx: PlotContext<'_>,
        formatter: &dyn ValueFormatter,
        all_curves: &[&(&BenchmarkId, Vec<f64>)],
        value_type: ValueType,
    ) {
        let path = ctx.line_comparison_path();
        self.process_list.push(line_comparison(
            formatter,
            ctx.id.as_title(),
            all_curves,
            &path,
            value_type,
            ctx.context.plot_config.summary_scale,
        ));
    }

File: criterion.rs/src/plot/gnuplot_backend/mod.rs
Start Line: 218
End Line: 254
Chunks:

    fn violin(
        &mut self,
        ctx: PlotContext<'_>,
        formatter: &dyn ValueFormatter,
        all_curves: &[&(&BenchmarkId, Vec<f64>)],
    ) {
        let violin_path = ctx.violin_path();

        self.process_list.push(violin(
            formatter,
            ctx.id.as_title(),
            all_curves,
            &violin_path,
            ctx.context.plot_config.summary_scale,
        ));
    }

    fn wait(&mut self) {
        let start = std::time::Instant::now();
        let child_count = self.process_list.len();
        for child in self.process_list.drain(..) {
            match child.wait_with_output() {
                Ok(ref out) if out.status.success() => {}
                Ok(out) => error!("Error in Gnuplot: {}", String::from_utf8_lossy(&out.stderr)),
                Err(e) => error!("Got IO error while waiting for Gnuplot to complete: {}", e),
            }
        }
        let elapsed = &start.elapsed();
        info!(
            "Waiting for {} gnuplot processes took {}",
            child_count,
            format::time(elapsed.as_nanos() as f64)
        );
    }
}

Ripgrep filtered Lines: [0, 21, 66]
File: criterion.rs/src/plot/gnuplot_backend/t_test.rs
Start Line: 0
End Line: 20
Chunks:
use std::iter;
use std::process::Child;

use criterion_plot::prelude::*;

use super::*;
use crate::kde;
use crate::report::{BenchmarkId, ComparisonData, MeasurementData, ReportContext};

pub(crate) fn t_test(
    id: &BenchmarkId,
    context: &ReportContext,
    _measurements: &MeasurementData<'_>,
    comparison: &ComparisonData,
    size: Option<Size>,
) -> Child {
    let t = comparison.t_value;
    let (xs, ys) = kde::sweep(&comparison.t_distribution, KDE_POINTS, None);
    let zero = iter::repeat(0);


File: criterion.rs/src/plot/gnuplot_backend/t_test.rs
Start Line: 20
End Line: 65
Chunks:
    let mut figure = Figure::new();
    figure
        .set(Font(DEFAULT_FONT))
        .set(size.unwrap_or(SIZE))
        .set(Title(format!(
            "{}: Welch t test",
            gnuplot_escape(id.as_title())
        )))
        .configure(Axis::BottomX, |a| a.set(Label("t score")))
        .configure(Axis::LeftY, |a| a.set(Label("Density")))
        .configure(Key, |k| {
            k.set(Justification::Left)
                .set(Order::SampleText)
                .set(Position::Outside(Vertical::Top, Horizontal::Right))
        })
        .plot(
            FilledCurve {
                x: &*xs,
                y1: &*ys,
                y2: zero,
            },
            |c| {
                c.set(DARK_BLUE)
                    .set(Label("t distribution"))
                    .set(Opacity(0.25))
            },
        )
        .plot(
            Lines {
                x: &[t, t],
                y: &[0, 1],
            },
            |c| {
                c.set(Axes::BottomXRightY)
                    .set(DARK_BLUE)
                    .set(LINEWIDTH)
                    .set(Label("t statistic"))
                    .set(LineType::Solid)
            },
        );

    let path = context.report_path(id, "change/t-test.svg");
    debug_script(&path, &figure);
    figure.set(Output(path)).draw().unwrap()
}

Ripgrep filtered Lines: [0, 30, 60, 81, 111, 148, 181, 214, 242, 285, 333, 378, 386]
File: criterion.rs/src/connection.rs
Start Line: 0
End Line: 29
Chunks:
use crate::report::BenchmarkId as InternalBenchmarkId;
use crate::Throughput;
use std::cell::RefCell;
use std::convert::TryFrom;
use std::io::{Read, Write};
use std::mem::size_of;
use std::net::TcpStream;

#[derive(Debug)]
pub enum MessageError {
    Deserialization(ciborium::de::Error<std::io::Error>),
    Serialization(ciborium::ser::Error<std::io::Error>),
    Io(std::io::Error),
}
impl From<ciborium::de::Error<std::io::Error>> for MessageError {
    fn from(other: ciborium::de::Error<std::io::Error>) -> Self {
        MessageError::Deserialization(other)
    }
}
impl From<ciborium::ser::Error<std::io::Error>> for MessageError {
    fn from(other: ciborium::ser::Error<std::io::Error>) -> Self {
        MessageError::Serialization(other)
    }
}
impl From<std::io::Error> for MessageError {
    fn from(other: std::io::Error) -> Self {
        MessageError::Io(other)
    }
}

File: criterion.rs/src/connection.rs
Start Line: 29
End Line: 59
Chunks:
impl std::fmt::Display for MessageError {
    fn fmt(&self, f: &mut std::fmt::Formatter<'_>) -> std::fmt::Result {
        match self {
            MessageError::Deserialization(error) => write!(
                f,
                "Failed to deserialize message to Criterion.rs benchmark:\n{}",
                error
            ),
            MessageError::Serialization(error) => write!(
                f,
                "Failed to serialize message to Criterion.rs benchmark:\n{}",
                error
            ),
            MessageError::Io(error) => write!(
                f,
                "Failed to read or write message to Criterion.rs benchmark:\n{}",
                error
            ),
        }
    }
}
impl std::error::Error for MessageError {
    fn source(&self) -> Option<&(dyn std::error::Error + 'static)> {
        match self {
            MessageError::Deserialization(err) => Some(err),
            MessageError::Serialization(err) => Some(err),
            MessageError::Io(err) => Some(err),
        }
    }
}

File: criterion.rs/src/connection.rs
Start Line: 59
End Line: 80
Chunks:

// Use str::len as a const fn once we bump MSRV over 1.39.
const RUNNER_MAGIC_NUMBER: &str = "cargo-criterion";
const RUNNER_HELLO_SIZE: usize = 15 //RUNNER_MAGIC_NUMBER.len() // magic number
    + (size_of::<u8>() * 3); // version number

const BENCHMARK_MAGIC_NUMBER: &str = "Criterion";
const BENCHMARK_HELLO_SIZE: usize = 9 //BENCHMARK_MAGIC_NUMBER.len() // magic number
    + (size_of::<u8>() * 3) // version number
    + size_of::<u16>() // protocol version
    + size_of::<u16>(); // protocol format
const PROTOCOL_VERSION: u16 = 1;
const PROTOCOL_FORMAT: u16 = 1;

#[derive(Debug)]
struct InnerConnection {
    socket: TcpStream,
    receive_buffer: Vec<u8>,
    send_buffer: Vec<u8>,
    // runner_version: [u8; 3],
}

File: criterion.rs/src/connection.rs
Start Line: 80
End Line: 110
Chunks:
impl InnerConnection {
    pub fn new(mut socket: TcpStream) -> Result<Self, std::io::Error> {
        // read the runner-hello
        let mut hello_buf = [0u8; RUNNER_HELLO_SIZE];
        socket.read_exact(&mut hello_buf)?;
        assert_eq!(
            &hello_buf[0..RUNNER_MAGIC_NUMBER.len()],
            RUNNER_MAGIC_NUMBER.as_bytes(),
            "Not connected to cargo-criterion."
        );

        let i = RUNNER_MAGIC_NUMBER.len();
        let runner_version = [hello_buf[i], hello_buf[i + 1], hello_buf[i + 2]];

        info!("Runner version: {:?}", runner_version);

        // now send the benchmark-hello
        let mut hello_buf = [0u8; BENCHMARK_HELLO_SIZE];
        hello_buf[0..BENCHMARK_MAGIC_NUMBER.len()]
            .copy_from_slice(BENCHMARK_MAGIC_NUMBER.as_bytes());
        let mut i = BENCHMARK_MAGIC_NUMBER.len();
        hello_buf[i] = env!("CARGO_PKG_VERSION_MAJOR").parse().unwrap();
        hello_buf[i + 1] = env!("CARGO_PKG_VERSION_MINOR").parse().unwrap();
        hello_buf[i + 2] = env!("CARGO_PKG_VERSION_PATCH").parse().unwrap();
        i += 3;
        hello_buf[i..i + 2].clone_from_slice(&PROTOCOL_VERSION.to_be_bytes());
        i += 2;
        hello_buf[i..i + 2].clone_from_slice(&PROTOCOL_FORMAT.to_be_bytes());

        socket.write_all(&hello_buf)?;

File: criterion.rs/src/connection.rs
Start Line: 110
End Line: 147
Chunks:

        Ok(InnerConnection {
            socket,
            receive_buffer: vec![],
            send_buffer: vec![],
            // runner_version,
        })
    }

    #[allow(dead_code)]
    pub fn recv(&mut self) -> Result<IncomingMessage, MessageError> {
        let mut length_buf = [0u8; 4];
        self.socket.read_exact(&mut length_buf)?;
        let length = u32::from_be_bytes(length_buf);
        self.receive_buffer.resize(length as usize, 0u8);
        self.socket.read_exact(&mut self.receive_buffer)?;
        let value = ciborium::de::from_reader(&self.receive_buffer[..])?;
        Ok(value)
    }

    pub fn send(&mut self, message: &OutgoingMessage) -> Result<(), MessageError> {
        self.send_buffer.truncate(0);
        ciborium::ser::into_writer(message, &mut self.send_buffer)?;
        let size = u32::try_from(self.send_buffer.len()).unwrap();
        let length_buf = size.to_be_bytes();
        self.socket.write_all(&length_buf)?;
        self.socket.write_all(&self.send_buffer)?;
        Ok(())
    }
}

/// This is really just a holder to allow us to send messages through a shared reference to the
/// connection.
#[derive(Debug)]
pub struct Connection {
    inner: RefCell<InnerConnection>,
}

File: criterion.rs/src/connection.rs
Start Line: 147
End Line: 180
Chunks:
impl Connection {
    pub fn new(socket: TcpStream) -> Result<Self, std::io::Error> {
        Ok(Connection {
            inner: RefCell::new(InnerConnection::new(socket)?),
        })
    }

    #[allow(dead_code)]
    pub fn recv(&self) -> Result<IncomingMessage, MessageError> {
        self.inner.borrow_mut().recv()
    }

    pub fn send(&self, message: &OutgoingMessage) -> Result<(), MessageError> {
        self.inner.borrow_mut().send(message)
    }

    pub fn serve_value_formatter(
        &self,
        formatter: &dyn crate::measurement::ValueFormatter,
    ) -> Result<(), MessageError> {
        loop {
            let response = match self.recv()? {
                IncomingMessage::FormatValue { value } => OutgoingMessage::FormattedValue {
                    value: formatter.format_value(value),
                },
                IncomingMessage::FormatThroughput { value, throughput } => {
                    OutgoingMessage::FormattedValue {
                        value: formatter.format_throughput(&throughput, value),
                    }
                }
                IncomingMessage::ScaleValues {
                    typical_value,
                    mut values,

File: criterion.rs/src/connection.rs
Start Line: 180
End Line: 213
Chunks:
                } => {
                    let unit = formatter.scale_values(typical_value, &mut values);
                    OutgoingMessage::ScaledValues {
                        unit,
                        scaled_values: values,
                    }
                }
                IncomingMessage::ScaleThroughputs {
                    typical_value,
                    throughput,
                    mut values,
                } => {
                    let unit = formatter.scale_throughputs(typical_value, &throughput, &mut values);
                    OutgoingMessage::ScaledValues {
                        unit,
                        scaled_values: values,
                    }
                }
                IncomingMessage::ScaleForMachines { mut values } => {
                    let unit = formatter.scale_for_machines(&mut values);
                    OutgoingMessage::ScaledValues {
                        unit,
                        scaled_values: values,
                    }
                }
                IncomingMessage::Continue => break,
                _ => panic!(),
            };
            self.send(&response)?;
        }
        Ok(())
    }
}

File: criterion.rs/src/connection.rs
Start Line: 213
End Line: 241
Chunks:

/// Enum defining the messages we can receive
#[derive(Debug, Deserialize)]
pub enum IncomingMessage {
    // Value formatter requests
    FormatValue {
        value: f64,
    },
    FormatThroughput {
        value: f64,
        throughput: Throughput,
    },
    ScaleValues {
        typical_value: f64,
        values: Vec<f64>,
    },
    ScaleThroughputs {
        typical_value: f64,
        values: Vec<f64>,
        throughput: Throughput,
    },
    ScaleForMachines {
        values: Vec<f64>,
    },
    Continue,

    __Other,
}

File: criterion.rs/src/connection.rs
Start Line: 241
End Line: 284
Chunks:

/// Enum defining the messages we can send
#[derive(Debug, Serialize)]
pub enum OutgoingMessage<'a> {
    BeginningBenchmarkGroup {
        group: &'a str,
    },
    FinishedBenchmarkGroup {
        group: &'a str,
    },
    BeginningBenchmark {
        id: RawBenchmarkId,
    },
    SkippingBenchmark {
        id: RawBenchmarkId,
    },
    Warmup {
        id: RawBenchmarkId,
        nanos: f64,
    },
    MeasurementStart {
        id: RawBenchmarkId,
        sample_count: u64,
        estimate_ns: f64,
        iter_count: u64,
    },
    MeasurementComplete {
        id: RawBenchmarkId,
        iters: &'a [f64],
        times: &'a [f64],
        plot_config: PlotConfiguration,
        sampling_method: SamplingMethod,
        benchmark_config: BenchmarkConfig,
    },
    // value formatter responses
    FormattedValue {
        value: String,
    },
    ScaledValues {
        scaled_values: Vec<f64>,
        unit: &'a str,
    },
}

File: criterion.rs/src/connection.rs
Start Line: 284
End Line: 332
Chunks:

// Also define serializable variants of certain things, either to avoid leaking
// serializability into the public interface or because the serialized form
// is a bit different from the regular one.

#[derive(Debug, Serialize)]
pub struct RawBenchmarkId {
    group_id: String,
    function_id: Option<String>,
    value_str: Option<String>,
    throughput: Vec<Throughput>,
}
impl From<&InternalBenchmarkId> for RawBenchmarkId {
    fn from(other: &InternalBenchmarkId) -> RawBenchmarkId {
        RawBenchmarkId {
            group_id: other.group_id.clone(),
            function_id: other.function_id.clone(),
            value_str: other.value_str.clone(),
            throughput: other.throughput.iter().cloned().collect(),
        }
    }
}

#[derive(Debug, Serialize)]
pub enum AxisScale {
    Linear,
    Logarithmic,
}
impl From<crate::AxisScale> for AxisScale {
    fn from(other: crate::AxisScale) -> Self {
        match other {
            crate::AxisScale::Linear => AxisScale::Linear,
            crate::AxisScale::Logarithmic => AxisScale::Logarithmic,
        }
    }
}

#[derive(Debug, Serialize)]
pub struct PlotConfiguration {
    summary_scale: AxisScale,
}
impl From<&crate::PlotConfiguration> for PlotConfiguration {
    fn from(other: &crate::PlotConfiguration) -> Self {
        PlotConfiguration {
            summary_scale: other.summary_scale.into(),
        }
    }
}

File: criterion.rs/src/connection.rs
Start Line: 332
End Line: 377
Chunks:

#[derive(Debug, Serialize)]
struct Duration {
    secs: u64,
    nanos: u32,
}
impl From<std::time::Duration> for Duration {
    fn from(other: std::time::Duration) -> Self {
        Duration {
            secs: other.as_secs(),
            nanos: other.subsec_nanos(),
        }
    }
}

#[derive(Debug, Serialize)]
pub struct BenchmarkConfig {
    confidence_level: f64,
    measurement_time: Duration,
    noise_threshold: f64,
    nresamples: usize,
    sample_size: usize,
    significance_level: f64,
    warm_up_time: Duration,
}
impl From<&crate::benchmark::BenchmarkConfig> for BenchmarkConfig {
    fn from(other: &crate::benchmark::BenchmarkConfig) -> Self {
        BenchmarkConfig {
            confidence_level: other.confidence_level,
            measurement_time: other.measurement_time.into(),
            noise_threshold: other.noise_threshold,
            nresamples: other.nresamples,
            sample_size: other.sample_size,
            significance_level: other.significance_level,
            warm_up_time: other.warm_up_time.into(),
        }
    }
}

/// Currently not used; defined for forwards compatibility with cargo-criterion.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum SamplingMethod {
    Linear,
    Flat,
}

File: criterion.rs/src/connection.rs
Start Line: 377
End Line: 385
Chunks:
impl From<crate::ActualSamplingMode> for SamplingMethod {
    fn from(other: crate::ActualSamplingMode) -> Self {
        match other {
            crate::ActualSamplingMode::Flat => SamplingMethod::Flat,
            crate::ActualSamplingMode::Linear => SamplingMethod::Linear,
        }
    }
}

Ripgrep filtered Lines: [0, 48, 90, 124, 174, 175, 225, 242, 289, 339, 382, 425, 460, 495, 545, 585, 624, 674, 721, 766, 805, 844, 883, 923, 965, 1005, 1053, 1100, 1129, 1165, 1198, 1243, 1276, 1315, 1361, 1368, 1412, 1431, 1469, 1485]
File: criterion.rs/src/lib.rs
Start Line: 0
End Line: 47
Chunks:
//! A statistics-driven micro-benchmarking library written in Rust.
//!
//! This crate is a microbenchmarking library which aims to provide strong
//! statistical confidence in detecting and estimating the size of performance
//! improvements and regressions, while also being easy to use.
//!
//! See
//! [the user guide](https://bheisler.github.io/criterion.rs/book/index.html)
//! for examples as well as details on the measurement and analysis process,
//! and the output.
//!
//! ## Features:
//! * Collects detailed statistics, providing strong confidence that changes
//!   to performance are real, not measurement noise.
//! * Produces detailed charts, providing thorough understanding of your code's
//!   performance behavior.

#![warn(missing_docs)]
#![warn(bare_trait_objects)]
#![cfg_attr(feature = "real_blackbox", feature(test))]
#![cfg_attr(
    feature = "cargo-clippy",
    allow(
        clippy::just_underscores_and_digits, // Used in the stats code
        clippy::transmute_ptr_to_ptr, // Used in the stats code
        clippy::manual_non_exhaustive, // Remove when MSRV bumped above 1.40
    )
)]

#[cfg(all(feature = "rayon", target_arch = "wasm32"))]
compile_error!("Rayon cannot be used when targeting wasi32. Try disabling default features.");

#[cfg(test)]
extern crate approx;

#[cfg(test)]
extern crate quickcheck;

use is_terminal::IsTerminal;
use regex::Regex;

#[cfg(feature = "real_blackbox")]
extern crate test;

#[macro_use]
extern crate serde_derive;


File: criterion.rs/src/lib.rs
Start Line: 47
End Line: 89
Chunks:
// Needs to be declared before other modules
// in order to be usable there.
#[macro_use]
mod macros_private;
#[macro_use]
mod analysis;
mod benchmark;
#[macro_use]
mod benchmark_group;
pub mod async_executor;
mod bencher;
mod connection;
#[cfg(feature = "csv_output")]
mod csv_report;
mod error;
mod estimate;
mod format;
mod fs;
mod html;
mod kde;
mod macros;
pub mod measurement;
mod plot;
pub mod profiler;
mod report;
mod routine;
mod stats;

use std::cell::RefCell;
use std::collections::HashSet;
use std::default::Default;
use std::env;
use std::io::stdout;
use std::net::TcpStream;
use std::path::{Path, PathBuf};
use std::process::Command;
use std::sync::{Mutex, MutexGuard};
use std::time::Duration;

use criterion_plot::{Version, VersionError};
use once_cell::sync::Lazy;


File: criterion.rs/src/lib.rs
Start Line: 89
End Line: 123
Chunks:
use crate::benchmark::BenchmarkConfig;
use crate::connection::Connection;
use crate::connection::OutgoingMessage;
use crate::html::Html;
use crate::measurement::{Measurement, WallTime};
#[cfg(feature = "plotters")]
use crate::plot::PlottersBackend;
use crate::plot::{Gnuplot, Plotter};
use crate::profiler::{ExternalProfiler, Profiler};
use crate::report::{BencherReport, CliReport, CliVerbosity, Report, ReportContext, Reports};

#[cfg(feature = "async")]
pub use crate::bencher::AsyncBencher;
pub use crate::bencher::Bencher;
pub use crate::benchmark_group::{BenchmarkGroup, BenchmarkId};

static DEBUG_ENABLED: Lazy<bool> = Lazy::new(|| std::env::var_os("CRITERION_DEBUG").is_some());
static GNUPLOT_VERSION: Lazy<Result<Version, VersionError>> = Lazy::new(criterion_plot::version);
static DEFAULT_PLOTTING_BACKEND: Lazy<PlottingBackend> = Lazy::new(|| match &*GNUPLOT_VERSION {
    Ok(_) => PlottingBackend::Gnuplot,
    #[cfg(feature = "plotters")]
    Err(e) => {
        match e {
            VersionError::Exec(_) => eprintln!("Gnuplot not found, using plotters backend"),
            e => eprintln!(
                "Gnuplot not found or not usable, using plotters backend\n{}",
                e
            ),
        };
        PlottingBackend::Plotters
    }
    #[cfg(not(feature = "plotters"))]
    Err(_) => PlottingBackend::None,
});

File: criterion.rs/src/lib.rs
Start Line: 123
End Line: 173
Chunks:
static CARGO_CRITERION_CONNECTION: Lazy<Option<Mutex<Connection>>> =
    Lazy::new(|| match std::env::var("CARGO_CRITERION_PORT") {
        Ok(port_str) => {
            let port: u16 = port_str.parse().ok()?;
            let stream = TcpStream::connect(("localhost", port)).ok()?;
            Some(Mutex::new(Connection::new(stream).ok()?))
        }
        Err(_) => None,
    });
static DEFAULT_OUTPUT_DIRECTORY: Lazy<PathBuf> = Lazy::new(|| {
    // Set criterion home to (in descending order of preference):
    // - $CRITERION_HOME (cargo-criterion sets this, but other users could as well)
    // - $CARGO_TARGET_DIR/criterion
    // - the cargo target dir from `cargo metadata`
    // - ./target/criterion
    if let Some(value) = env::var_os("CRITERION_HOME") {
        PathBuf::from(value)
    } else if let Some(path) = cargo_target_directory() {
        path.join("criterion")
    } else {
        PathBuf::from("target/criterion")
    }
});

fn debug_enabled() -> bool {
    *DEBUG_ENABLED
}

/// A function that is opaque to the optimizer, used to prevent the compiler from
/// optimizing away computations in a benchmark.
///
/// This variant is backed by the (unstable) test::black_box function.
#[cfg(feature = "real_blackbox")]
pub fn black_box<T>(dummy: T) -> T {
    test::black_box(dummy)
}

/// A function that is opaque to the optimizer, used to prevent the compiler from
/// optimizing away computations in a benchmark.
///
/// This variant is stable-compatible, but it may cause some performance overhead
/// or fail to prevent code from being eliminated.
#[cfg(not(feature = "real_blackbox"))]
pub fn black_box<T>(dummy: T) -> T {
    unsafe {
        let ret = std::ptr::read_volatile(&dummy);
        std::mem::forget(dummy);
        ret
    }
}

File: criterion.rs/src/lib.rs
Start Line: 173
End Line: 174
Chunks:


File: criterion.rs/src/lib.rs
Start Line: 174
End Line: 224
Chunks:
/// Argument to [`Bencher::iter_batched`](struct.Bencher.html#method.iter_batched) and
/// [`Bencher::iter_batched_ref`](struct.Bencher.html#method.iter_batched_ref) which controls the
/// batch size.
///
/// Generally speaking, almost all benchmarks should use `SmallInput`. If the input or the result
/// of the benchmark routine is large enough that `SmallInput` causes out-of-memory errors,
/// `LargeInput` can be used to reduce memory usage at the cost of increasing the measurement
/// overhead. If the input or the result is extremely large (or if it holds some
/// limited external resource like a file handle), `PerIteration` will set the number of iterations
/// per batch to exactly one. `PerIteration` can increase the measurement overhead substantially
/// and should be avoided wherever possible.
///
/// Each value lists an estimate of the measurement overhead. This is intended as a rough guide
/// to assist in choosing an option, it should not be relied upon. In particular, it is not valid
/// to subtract the listed overhead from the measurement and assume that the result represents the
/// true runtime of a function. The actual measurement overhead for your specific benchmark depends
/// on the details of the function you're benchmarking and the hardware and operating
/// system running the benchmark.
///
/// With that said, if the runtime of your function is small relative to the measurement overhead
/// it will be difficult to take accurate measurements. In this situation, the best option is to use
/// [`Bencher::iter`](struct.Bencher.html#method.iter) which has next-to-zero measurement overhead.
#[derive(Debug, Eq, PartialEq, Copy, Hash, Clone)]
pub enum BatchSize {
    /// `SmallInput` indicates that the input to the benchmark routine (the value returned from
    /// the setup routine) is small enough that millions of values can be safely held in memory.
    /// Always prefer `SmallInput` unless the benchmark is using too much memory.
    ///
    /// In testing, the maximum measurement overhead from benchmarking with `SmallInput` is on the
    /// order of 500 picoseconds. This is presented as a rough guide; your results may vary.
    SmallInput,

    /// `LargeInput` indicates that the input to the benchmark routine or the value returned from
    /// that routine is large. This will reduce the memory usage but increase the measurement
    /// overhead.
    ///
    /// In testing, the maximum measurement overhead from benchmarking with `LargeInput` is on the
    /// order of 750 picoseconds. This is presented as a rough guide; your results may vary.
    LargeInput,

    /// `PerIteration` indicates that the input to the benchmark routine or the value returned from
    /// that routine is extremely large or holds some limited resource, such that holding many values
    /// in memory at once is infeasible. This provides the worst measurement overhead, but the
    /// lowest memory usage.
    ///
    /// In testing, the maximum measurement overhead from benchmarking with `PerIteration` is on the
    /// order of 350 nanoseconds or 350,000 picoseconds. This is presented as a rough guide; your
    /// results may vary.
    PerIteration,


File: criterion.rs/src/lib.rs
Start Line: 224
End Line: 241
Chunks:
    /// `NumBatches` will attempt to divide the iterations up into a given number of batches.
    /// A larger number of batches (and thus smaller batches) will reduce memory usage but increase
    /// measurement overhead. This allows the user to choose their own tradeoff between memory usage
    /// and measurement overhead, but care must be taken in tuning the number of batches. Most
    /// benchmarks should use `SmallInput` or `LargeInput` instead.
    NumBatches(u64),

    /// `NumIterations` fixes the batch size to a constant number, specified by the user. This
    /// allows the user to choose their own tradeoff between overhead and memory usage, but care must
    /// be taken in tuning the batch size. In general, the measurement overhead of `NumIterations`
    /// will be larger than that of `NumBatches`. Most benchmarks should use `SmallInput` or
    /// `LargeInput` instead.
    NumIterations(u64),

    #[doc(hidden)]
    __NonExhaustive,
}

File: criterion.rs/src/lib.rs
Start Line: 241
End Line: 288
Chunks:
impl BatchSize {
    /// Convert to a number of iterations per batch.
    ///
    /// We try to do a constant number of batches regardless of the number of iterations in this
    /// sample. If the measurement overhead is roughly constant regardless of the number of
    /// iterations the analysis of the results later will have an easier time separating the
    /// measurement overhead from the benchmark time.
    fn iters_per_batch(self, iters: u64) -> u64 {
        match self {
            BatchSize::SmallInput => (iters + 10 - 1) / 10,
            BatchSize::LargeInput => (iters + 1000 - 1) / 1000,
            BatchSize::PerIteration => 1,
            BatchSize::NumBatches(batches) => (iters + batches - 1) / batches,
            BatchSize::NumIterations(size) => size,
            BatchSize::__NonExhaustive => panic!("__NonExhaustive is not a valid BatchSize."),
        }
    }
}

/// Baseline describes how the baseline_directory is handled.
#[derive(Debug, Clone, Copy)]
pub enum Baseline {
    /// CompareLenient compares against a previous saved version of the baseline.
    /// If a previous baseline does not exist, the benchmark is run as normal but no comparison occurs.
    CompareLenient,
    /// CompareStrict compares against a previous saved version of the baseline.
    /// If a previous baseline does not exist, a panic occurs.
    CompareStrict,
    /// Save writes the benchmark results to the baseline directory,
    /// overwriting any results that were previously there.
    Save,
    /// Discard benchmark results.
    Discard,
}

/// Enum used to select the plotting backend.
#[derive(Debug, Clone, Copy)]
pub enum PlottingBackend {
    /// Plotting backend which uses the external `gnuplot` command to render plots. This is the
    /// default if the `gnuplot` command is installed.
    Gnuplot,
    /// Plotting backend which uses the rust 'Plotters' library. This is the default if `gnuplot`
    /// is not installed.
    Plotters,
    /// Null plotting backend which outputs nothing,
    None,
}

File: criterion.rs/src/lib.rs
Start Line: 288
End Line: 338
Chunks:
impl PlottingBackend {
    fn create_plotter(&self) -> Option<Box<dyn Plotter>> {
        match self {
            PlottingBackend::Gnuplot => Some(Box::<Gnuplot>::default()),
            #[cfg(feature = "plotters")]
            PlottingBackend::Plotters => Some(Box::<PlottersBackend>::default()),
            #[cfg(not(feature = "plotters"))]
            PlottingBackend::Plotters => panic!("Criterion was built without plotters support."),
            PlottingBackend::None => None,
        }
    }
}

#[derive(Debug, Clone)]
/// Enum representing the execution mode.
pub(crate) enum Mode {
    /// Run benchmarks normally.
    Benchmark,
    /// List all benchmarks but do not run them.
    List(ListFormat),
    /// Run benchmarks once to verify that they work, but otherwise do not measure them.
    Test,
    /// Iterate benchmarks for a given length of time but do not analyze or report on them.
    Profile(Duration),
}
impl Mode {
    pub fn is_benchmark(&self) -> bool {
        matches!(self, Mode::Benchmark)
    }

    pub fn is_terse(&self) -> bool {
        matches!(self, Mode::List(ListFormat::Terse))
    }
}

#[derive(Debug, Clone)]
/// Enum representing the list format.
pub(crate) enum ListFormat {
    /// The regular, default format.
    Pretty,
    /// The terse format, where nothing other than the name of the test and ": benchmark" at the end
    /// is printed out.
    Terse,
}

impl Default for ListFormat {
    fn default() -> Self {
        Self::Pretty
    }
}

File: criterion.rs/src/lib.rs
Start Line: 338
End Line: 381
Chunks:

/// Benchmark filtering support.
#[derive(Clone, Debug)]
pub enum BenchmarkFilter {
    /// Run all benchmarks.
    AcceptAll,
    /// Run benchmarks matching this regex.
    Regex(Regex),
    /// Run the benchmark matching this string exactly.
    Exact(String),
    /// Do not run any benchmarks.
    RejectAll,
}

/// The benchmark manager
///
/// `Criterion` lets you configure and execute benchmarks
///
/// Each benchmark consists of four phases:
///
/// - **Warm-up**: The routine is repeatedly executed, to let the CPU/OS/JIT/interpreter adapt to
/// the new load
/// - **Measurement**: The routine is repeatedly executed, and timing information is collected into
/// a sample
/// - **Analysis**: The sample is analyzed and distilled into meaningful statistics that get
/// reported to stdout, stored in files, and plotted
/// - **Comparison**: The current sample is compared with the sample obtained in the previous
/// benchmark.
pub struct Criterion<M: Measurement = WallTime> {
    config: BenchmarkConfig,
    filter: BenchmarkFilter,
    report: Reports,
    output_directory: PathBuf,
    baseline_directory: String,
    baseline: Baseline,
    load_baseline: Option<String>,
    all_directories: HashSet<String>,
    all_titles: HashSet<String>,
    measurement: M,
    profiler: Box<RefCell<dyn Profiler>>,
    connection: Option<MutexGuard<'static, Connection>>,
    mode: Mode,
}

File: criterion.rs/src/lib.rs
Start Line: 381
End Line: 424
Chunks:

/// Returns the Cargo target directory, possibly calling `cargo metadata` to
/// figure it out.
fn cargo_target_directory() -> Option<PathBuf> {
    #[derive(Deserialize)]
    struct Metadata {
        target_directory: PathBuf,
    }

    env::var_os("CARGO_TARGET_DIR")
        .map(PathBuf::from)
        .or_else(|| {
            let output = Command::new(env::var_os("CARGO")?)
                .args(["metadata", "--format-version", "1"])
                .output()
                .ok()?;
            let metadata: Metadata = serde_json::from_slice(&output.stdout).ok()?;
            Some(metadata.target_directory)
        })
}

impl Default for Criterion {
    /// Creates a benchmark manager with the following default settings:
    ///
    /// - Sample size: 100 measurements
    /// - Warm-up time: 3 s
    /// - Measurement time: 5 s
    /// - Bootstrap size: 100 000 resamples
    /// - Noise threshold: 0.01 (1%)
    /// - Confidence level: 0.95
    /// - Significance level: 0.05
    /// - Plotting: enabled, using gnuplot if available or plotters if gnuplot is not available
    /// - No filter
    fn default() -> Criterion {
        let reports = Reports {
            cli_enabled: true,
            cli: CliReport::new(false, false, CliVerbosity::Normal),
            bencher_enabled: false,
            bencher: BencherReport,
            html: DEFAULT_PLOTTING_BACKEND.create_plotter().map(Html::new),
            csv_enabled: cfg!(feature = "csv_output"),
        };


File: criterion.rs/src/lib.rs
Start Line: 424
End Line: 459
Chunks:
        let mut criterion = Criterion {
            config: BenchmarkConfig {
                confidence_level: 0.95,
                measurement_time: Duration::from_secs(5),
                noise_threshold: 0.01,
                nresamples: 100_000,
                sample_size: 100,
                significance_level: 0.05,
                warm_up_time: Duration::from_secs(3),
                sampling_mode: SamplingMode::Auto,
                quick_mode: false,
            },
            filter: BenchmarkFilter::AcceptAll,
            report: reports,
            baseline_directory: "base".to_owned(),
            baseline: Baseline::Save,
            load_baseline: None,
            output_directory: DEFAULT_OUTPUT_DIRECTORY.clone(),
            all_directories: HashSet::new(),
            all_titles: HashSet::new(),
            measurement: WallTime,
            profiler: Box::new(RefCell::new(ExternalProfiler)),
            connection: CARGO_CRITERION_CONNECTION
                .as_ref()
                .map(|mtx| mtx.lock().unwrap()),
            mode: Mode::Benchmark,
        };

        if criterion.connection.is_some() {
            // disable all reports when connected to cargo-criterion; it will do the reporting.
            criterion.report.cli_enabled = false;
            criterion.report.bencher_enabled = false;
            criterion.report.csv_enabled = false;
            criterion.report.html = None;
        }

File: criterion.rs/src/lib.rs
Start Line: 459
End Line: 494
Chunks:
        criterion
    }
}

impl<M: Measurement> Criterion<M> {
    /// Changes the measurement for the benchmarks run with this runner. See the
    /// Measurement trait for more details
    pub fn with_measurement<M2: Measurement>(self, m: M2) -> Criterion<M2> {
        // Can't use struct update syntax here because they're technically different types.
        Criterion {
            config: self.config,
            filter: self.filter,
            report: self.report,
            baseline_directory: self.baseline_directory,
            baseline: self.baseline,
            load_baseline: self.load_baseline,
            output_directory: self.output_directory,
            all_directories: self.all_directories,
            all_titles: self.all_titles,
            measurement: m,
            profiler: self.profiler,
            connection: self.connection,
            mode: self.mode,
        }
    }

    #[must_use]
    /// Changes the internal profiler for benchmarks run with this runner. See
    /// the Profiler trait for more details.
    pub fn with_profiler<P: Profiler + 'static>(self, p: P) -> Criterion<M> {
        Criterion {
            profiler: Box::new(RefCell::new(p)),
            ..self
        }
    }

File: criterion.rs/src/lib.rs
Start Line: 494
End Line: 544
Chunks:

    #[must_use]
    /// Set the plotting backend. By default, Criterion will use gnuplot if available, or plotters
    /// if not.
    ///
    /// Panics if `backend` is `PlottingBackend::Gnuplot` and gnuplot is not available.
    pub fn plotting_backend(mut self, backend: PlottingBackend) -> Criterion<M> {
        if let PlottingBackend::Gnuplot = backend {
            assert!(
                !GNUPLOT_VERSION.is_err(),
                "Gnuplot plotting backend was requested, but gnuplot is not available. \
                To continue, either install Gnuplot or allow Criterion.rs to fall back \
                to using plotters."
            );
        }

        self.report.html = backend.create_plotter().map(Html::new);
        self
    }

    #[must_use]
    /// Changes the default size of the sample for benchmarks run with this runner.
    ///
    /// A bigger sample should yield more accurate results if paired with a sufficiently large
    /// measurement time.
    ///
    /// Sample size must be at least 10.
    ///
    /// # Panics
    ///
    /// Panics if n < 10
    pub fn sample_size(mut self, n: usize) -> Criterion<M> {
        assert!(n >= 10);

        self.config.sample_size = n;
        self
    }

    #[must_use]
    /// Changes the default warm up time for benchmarks run with this runner.
    ///
    /// # Panics
    ///
    /// Panics if the input duration is zero
    pub fn warm_up_time(mut self, dur: Duration) -> Criterion<M> {
        assert!(dur.as_nanos() > 0);

        self.config.warm_up_time = dur;
        self
    }

File: criterion.rs/src/lib.rs
Start Line: 544
End Line: 584
Chunks:

    #[must_use]
    /// Changes the default measurement time for benchmarks run with this runner.
    ///
    /// With a longer time, the measurement will become more resilient to transitory peak loads
    /// caused by external programs
    ///
    /// **Note**: If the measurement time is too "low", Criterion will automatically increase it
    ///
    /// # Panics
    ///
    /// Panics if the input duration in zero
    pub fn measurement_time(mut self, dur: Duration) -> Criterion<M> {
        assert!(dur.as_nanos() > 0);

        self.config.measurement_time = dur;
        self
    }

    #[must_use]
    /// Changes the default number of resamples for benchmarks run with this runner.
    ///
    /// Number of resamples to use for the
    /// [bootstrap](http://en.wikipedia.org/wiki/Bootstrapping_(statistics)#Case_resampling)
    ///
    /// A larger number of resamples reduces the random sampling errors, which are inherent to the
    /// bootstrap method, but also increases the analysis time
    ///
    /// # Panics
    ///
    /// Panics if the number of resamples is set to zero
    pub fn nresamples(mut self, n: usize) -> Criterion<M> {
        assert!(n > 0);
        if n <= 1000 {
            eprintln!("\nWarning: It is not recommended to reduce nresamples below 1000.");
        }

        self.config.nresamples = n;
        self
    }

File: criterion.rs/src/lib.rs
Start Line: 584
End Line: 623
Chunks:

    #[must_use]
    /// Changes the default noise threshold for benchmarks run with this runner. The noise threshold
    /// is used to filter out small changes in performance, even if they are statistically
    /// significant. Sometimes benchmarking the same code twice will result in small but
    /// statistically significant differences solely because of noise. This provides a way to filter
    /// out some of these false positives at the cost of making it harder to detect small changes
    /// to the true performance of the benchmark.
    ///
    /// The default is 0.01, meaning that changes smaller than 1% will be ignored.
    ///
    /// # Panics
    ///
    /// Panics if the threshold is set to a negative value
    pub fn noise_threshold(mut self, threshold: f64) -> Criterion<M> {
        assert!(threshold >= 0.0);

        self.config.noise_threshold = threshold;
        self
    }

    #[must_use]
    /// Changes the default confidence level for benchmarks run with this runner. The confidence
    /// level is the desired probability that the true runtime lies within the estimated
    /// [confidence interval](https://en.wikipedia.org/wiki/Confidence_interval). The default is
    /// 0.95, meaning that the confidence interval should capture the true value 95% of the time.
    ///
    /// # Panics
    ///
    /// Panics if the confidence level is set to a value outside the `(0, 1)` range
    pub fn confidence_level(mut self, cl: f64) -> Criterion<M> {
        assert!(cl > 0.0 && cl < 1.0);
        if cl < 0.5 {
            eprintln!("\nWarning: It is not recommended to reduce confidence level below 0.5.");
        }

        self.config.confidence_level = cl;
        self
    }

File: criterion.rs/src/lib.rs
Start Line: 623
End Line: 673
Chunks:

    #[must_use]
    /// Changes the default [significance level](https://en.wikipedia.org/wiki/Statistical_significance)
    /// for benchmarks run with this runner. This is used to perform a
    /// [hypothesis test](https://en.wikipedia.org/wiki/Statistical_hypothesis_testing) to see if
    /// the measurements from this run are different from the measured performance of the last run.
    /// The significance level is the desired probability that two measurements of identical code
    /// will be considered 'different' due to noise in the measurements. The default value is 0.05,
    /// meaning that approximately 5% of identical benchmarks will register as different due to
    /// noise.
    ///
    /// This presents a trade-off. By setting the significance level closer to 0.0, you can increase
    /// the statistical robustness against noise, but it also weakens Criterion.rs' ability to
    /// detect small but real changes in the performance. By setting the significance level
    /// closer to 1.0, Criterion.rs will be more able to detect small true changes, but will also
    /// report more spurious differences.
    ///
    /// See also the noise threshold setting.
    ///
    /// # Panics
    ///
    /// Panics if the significance level is set to a value outside the `(0, 1)` range
    pub fn significance_level(mut self, sl: f64) -> Criterion<M> {
        assert!(sl > 0.0 && sl < 1.0);

        self.config.significance_level = sl;
        self
    }

    #[must_use]
    /// Enables plotting
    pub fn with_plots(mut self) -> Criterion<M> {
        // If running under cargo-criterion then don't re-enable the reports; let it do the reporting.
        if self.connection.is_none() && self.report.html.is_none() {
            let default_backend = DEFAULT_PLOTTING_BACKEND.create_plotter();
            if let Some(backend) = default_backend {
                self.report.html = Some(Html::new(backend));
            } else {
                panic!("Cannot find a default plotting backend!");
            }
        }
        self
    }

    #[must_use]
    /// Disables plotting
    pub fn without_plots(mut self) -> Criterion<M> {
        self.report.html = None;
        self
    }

File: criterion.rs/src/lib.rs
Start Line: 673
End Line: 720
Chunks:

    #[must_use]
    /// Names an explicit baseline and enables overwriting the previous results.
    pub fn save_baseline(mut self, baseline: String) -> Criterion<M> {
        self.baseline_directory = baseline;
        self.baseline = Baseline::Save;
        self
    }

    #[must_use]
    /// Names an explicit baseline and disables overwriting the previous results.
    pub fn retain_baseline(mut self, baseline: String, strict: bool) -> Criterion<M> {
        self.baseline_directory = baseline;
        self.baseline = if strict {
            Baseline::CompareStrict
        } else {
            Baseline::CompareLenient
        };
        self
    }

    #[must_use]
    /// Filters the benchmarks. Only benchmarks with names that contain the
    /// given string will be executed.
    ///
    /// This overwrites [`Self::with_benchmark_filter`].
    pub fn with_filter<S: Into<String>>(mut self, filter: S) -> Criterion<M> {
        let filter_text = filter.into();
        let filter = Regex::new(&filter_text).unwrap_or_else(|err| {
            panic!(
                "Unable to parse '{}' as a regular expression: {}",
                filter_text, err
            )
        });
        self.filter = BenchmarkFilter::Regex(filter);

        self
    }

    /// Only run benchmarks specified by the given filter.
    ///
    /// This overwrites [`Self::with_filter`].
    pub fn with_benchmark_filter(mut self, filter: BenchmarkFilter) -> Criterion<M> {
        self.filter = filter;

        self
    }

File: criterion.rs/src/lib.rs
Start Line: 720
End Line: 765
Chunks:

    #[must_use]
    /// Override whether the CLI output will be colored or not. Usually you would use the `--color`
    /// CLI argument, but this is available for programmmatic use as well.
    pub fn with_output_color(mut self, enabled: bool) -> Criterion<M> {
        self.report.cli.enable_text_coloring = enabled;
        self
    }

    /// Set the output directory (currently for testing only)
    #[must_use]
    #[doc(hidden)]
    pub fn output_directory(mut self, path: &Path) -> Criterion<M> {
        self.output_directory = path.to_owned();

        self
    }

    /// Set the profile time (currently for testing only)
    #[must_use]
    #[doc(hidden)]
    pub fn profile_time(mut self, profile_time: Option<Duration>) -> Criterion<M> {
        match profile_time {
            Some(time) => self.mode = Mode::Profile(time),
            None => self.mode = Mode::Benchmark,
        }

        self
    }

    /// Generate the final summary at the end of a run.
    #[doc(hidden)]
    pub fn final_summary(&self) {
        if !self.mode.is_benchmark() {
            return;
        }

        let report_context = ReportContext {
            output_directory: self.output_directory.clone(),
            plot_config: PlotConfiguration::default(),
        };

        self.report.final_summary(&report_context);
    }


File: criterion.rs/src/lib.rs
Start Line: 765
End Line: 804
Chunks:
    /// Configure this criterion struct based on the command-line arguments to
    /// this process.
    #[must_use]
    #[cfg_attr(feature = "cargo-clippy", allow(clippy::cognitive_complexity))]
    pub fn configure_from_args(mut self) -> Criterion<M> {
        use clap::{value_parser, Arg, Command};
        let matches = Command::new("Criterion Benchmark")
            .arg(Arg::new("FILTER")
                .help("Skip benchmarks whose names do not contain FILTER.")
                .index(1))
            .arg(Arg::new("color")
                .short('c')
                .long("color")
                .alias("colour")
                .value_parser(["auto", "always", "never"])
                .default_value("auto")
                .help("Configure coloring of output. always = always colorize output, never = never colorize output, auto = colorize output if output is a tty and compiled for unix."))
            .arg(Arg::new("verbose")
                .short('v')
                .long("verbose")
                .num_args(0)
                .help("Print additional statistical information."))
            .arg(Arg::new("quiet")
                .long("quiet")
                .num_args(0)
                .conflicts_with("verbose")
                .help("Print only the benchmark results."))
            .arg(Arg::new("noplot")
                .short('n')
                .long("noplot")
                .num_args(0)
                .help("Disable plot and HTML generation."))
            .arg(Arg::new("save-baseline")
                .short('s')
                .long("save-baseline")
                .default_value("base")
                .help("Save results under a named baseline."))
            .arg(Arg::new("discard-baseline")
                .long("discard-baseline")

File: criterion.rs/src/lib.rs
Start Line: 804
End Line: 843
Chunks:
                .num_args(0)
                .conflicts_with_all(["save-baseline", "baseline", "baseline-lenient"])
                .help("Discard benchmark results."))
            .arg(Arg::new("baseline")
                .short('b')
                .long("baseline")
                .conflicts_with_all(["save-baseline", "baseline-lenient"])
                .help("Compare to a named baseline. If any benchmarks do not have the specified baseline this command fails."))
            .arg(Arg::new("baseline-lenient")
                .long("baseline-lenient")
                .conflicts_with_all(["save-baseline", "baseline"])
                .help("Compare to a named baseline. If any benchmarks do not have the specified baseline then just those benchmarks are not compared against the baseline while every other benchmark is compared against the baseline."))
            .arg(Arg::new("list")
                .long("list")
                .num_args(0)
                .help("List all benchmarks")
                .conflicts_with_all(["test", "profile-time"]))
            .arg(Arg::new("format")
                .long("format")
                .value_parser(["pretty", "terse"])
                .default_value("pretty")
                // Note that libtest's --format also works during test execution, but criterion
                // doesn't support that at the moment.
                .help("Output formatting"))
            .arg(Arg::new("ignored")
                .long("ignored")
                .num_args(0)
                .help("List or run ignored benchmarks (currently means skip all benchmarks)"))
            .arg(Arg::new("exact")
                .long("exact")
                .num_args(0)
                .help("Run benchmarks that exactly match the provided filter"))
            .arg(Arg::new("profile-time")
                .long("profile-time")
                .value_parser(value_parser!(f64))
                .help("Iterate each benchmark for approximately the given number of seconds, doing no analysis and without storing the results. Useful for running the benchmarks in a profiler.")
                .conflicts_with_all(["test", "list"]))
            .arg(Arg::new("load-baseline")
                 .long("load-baseline")

File: criterion.rs/src/lib.rs
Start Line: 843
End Line: 882
Chunks:
                 .conflicts_with("profile-time")
                 .requires("baseline")
                 .help("Load a previous baseline instead of sampling new data."))
            .arg(Arg::new("sample-size")
                .long("sample-size")
                .value_parser(value_parser!(usize))
                .help(format!("Changes the default size of the sample for this run. [default: {}]", self.config.sample_size)))
            .arg(Arg::new("warm-up-time")
                .long("warm-up-time")
                .value_parser(value_parser!(f64))
                .help(format!("Changes the default warm up time for this run. [default: {}]", self.config.warm_up_time.as_secs())))
            .arg(Arg::new("measurement-time")
                .long("measurement-time")
                .value_parser(value_parser!(f64))
                .help(format!("Changes the default measurement time for this run. [default: {}]", self.config.measurement_time.as_secs())))
            .arg(Arg::new("nresamples")
                .long("nresamples")
                .value_parser(value_parser!(usize))
                .help(format!("Changes the default number of resamples for this run. [default: {}]", self.config.nresamples)))
            .arg(Arg::new("noise-threshold")
                .long("noise-threshold")
                .value_parser(value_parser!(f64))
                .help(format!("Changes the default noise threshold for this run. [default: {}]", self.config.noise_threshold)))
            .arg(Arg::new("confidence-level")
                .long("confidence-level")
                .value_parser(value_parser!(f64))
                .help(format!("Changes the default confidence level for this run. [default: {}]", self.config.confidence_level)))
            .arg(Arg::new("significance-level")
                .long("significance-level")
                .value_parser(value_parser!(f64))
                .help(format!("Changes the default significance level for this run. [default: {}]", self.config.significance_level)))
            .arg(Arg::new("quick")
                .long("quick")
                .num_args(0)
                .conflicts_with("sample-size")
                .help(format!("Benchmark only until the significance level has been reached [default: {}]", self.config.quick_mode)))
            .arg(Arg::new("test")
                .hide(true)
                .long("test")

File: criterion.rs/src/lib.rs
Start Line: 882
End Line: 922
Chunks:
                .num_args(0)
                .help("Run the benchmarks once, to verify that they execute successfully, but do not measure or report the results.")
                .conflicts_with_all(["list", "profile-time"]))
            .arg(Arg::new("bench")
                .hide(true)
                .long("bench")
                .num_args(0))
            .arg(Arg::new("plotting-backend")
                 .long("plotting-backend")
                 .value_parser(["gnuplot", "plotters"])
                 .help("Set the plotting backend. By default, Criterion.rs will use the gnuplot backend if gnuplot is available, or the plotters backend if it isn't."))
            .arg(Arg::new("output-format")
                .long("output-format")
                .value_parser(["criterion", "bencher"])
                .default_value("criterion")
                .help("Change the CLI output format. By default, Criterion.rs will use its own format. If output format is set to 'bencher', Criterion.rs will print output in a format that resembles the 'bencher' crate."))
            .arg(Arg::new("nocapture")
                .long("nocapture")
                .num_args(0)
                .hide(true)
                .help("Ignored, but added for compatibility with libtest."))
            .arg(Arg::new("show-output")
                .long("show-output")
                .num_args(0)
                .hide(true)
                .help("Ignored, but added for compatibility with libtest."))
            .arg(Arg::new("include-ignored")
                .long("include-ignored")
                .num_args(0)
                .hide(true)
                .help("Ignored, but added for compatibility with libtest."))
            .arg(Arg::new("version")
                .hide(true)
                .short('V')
                .long("version")
                .num_args(0))
            .after_help("
This executable is a Criterion.rs benchmark.
See https://github.com/bheisler/criterion.rs for more details.


File: criterion.rs/src/lib.rs
Start Line: 922
End Line: 964
Chunks:
To enable debug output, define the environment variable CRITERION_DEBUG.
Criterion.rs will output more debug information and will save the gnuplot
scripts alongside the generated plots.

To test that the benchmarks work, run `cargo test --benches`

NOTE: If you see an 'unrecognized option' error using any of the options above, see:
https://bheisler.github.io/criterion.rs/book/faq.html
")
            .get_matches();

        if self.connection.is_some() {
            if let Some(color) = matches.get_one::<String>("color") {
                if color != "auto" {
                    eprintln!("Warning: --color will be ignored when running with cargo-criterion. Use `cargo criterion --color {} -- <args>` instead.", color);
                }
            }
            if matches.get_flag("verbose") {
                eprintln!("Warning: --verbose will be ignored when running with cargo-criterion. Use `cargo criterion --output-format verbose -- <args>` instead.");
            }
            if matches.get_flag("noplot") {
                eprintln!("Warning: --noplot will be ignored when running with cargo-criterion. Use `cargo criterion --plotting-backend disabled -- <args>` instead.");
            }
            if let Some(backend) = matches.get_one::<String>("plotting-backend") {
                eprintln!("Warning: --plotting-backend will be ignored when running with cargo-criterion. Use `cargo criterion --plotting-backend {} -- <args>` instead.", backend);
            }
            if let Some(format) = matches.get_one::<String>("output-format") {
                if format != "criterion" {
                    eprintln!("Warning: --output-format will be ignored when running with cargo-criterion. Use `cargo criterion --output-format {} -- <args>` instead.", format);
                }
            }

            if matches.contains_id("baseline")
                || matches
                    .get_one::<String>("save-baseline")
                    .map_or(false, |base| base != "base")
                || matches.contains_id("load-baseline")
            {
                eprintln!("Error: baselines are not supported when running with cargo-criterion.");
                std::process::exit(1);
            }
        }

File: criterion.rs/src/lib.rs
Start Line: 964
End Line: 1004
Chunks:

        let bench = matches.get_flag("bench");
        let test = matches.get_flag("test");
        let test_mode = match (bench, test) {
            (true, true) => true,   // cargo bench -- --test should run tests
            (true, false) => false, // cargo bench should run benchmarks
            (false, _) => true,     // cargo test --benches should run tests
        };

        self.mode = if matches.get_flag("list") {
            let list_format = match matches
                .get_one::<String>("format")
                .expect("a default value was provided for this")
                .as_str()
            {
                "pretty" => ListFormat::Pretty,
                "terse" => ListFormat::Terse,
                other => unreachable!(
                    "unrecognized value for --format that isn't part of possible-values: {}",
                    other
                ),
            };
            Mode::List(list_format)
        } else if test_mode {
            Mode::Test
        } else if let Some(&num_seconds) = matches.get_one("profile-time") {
            if num_seconds < 1.0 {
                eprintln!("Profile time must be at least one second.");
                std::process::exit(1);
            }

            Mode::Profile(Duration::from_secs_f64(num_seconds))
        } else {
            Mode::Benchmark
        };

        // This is kind of a hack, but disable the connection to the runner if we're not benchmarking.
        if !self.mode.is_benchmark() {
            self.connection = None;
        }

File: criterion.rs/src/lib.rs
Start Line: 1004
End Line: 1052
Chunks:

        let filter = if matches.get_flag("ignored") {
            // --ignored overwrites any name-based filters passed in.
            BenchmarkFilter::RejectAll
        } else if let Some(filter) = matches.get_one::<String>("FILTER") {
            if matches.get_flag("exact") {
                BenchmarkFilter::Exact(filter.to_owned())
            } else {
                let regex = Regex::new(filter).unwrap_or_else(|err| {
                    panic!(
                        "Unable to parse '{}' as a regular expression: {}",
                        filter, err
                    )
                });
                BenchmarkFilter::Regex(regex)
            }
        } else {
            BenchmarkFilter::AcceptAll
        };
        self = self.with_benchmark_filter(filter);

        match matches.get_one("plotting-backend").map(String::as_str) {
            // Use plotting_backend() here to re-use the panic behavior if Gnuplot is not available.
            Some("gnuplot") => self = self.plotting_backend(PlottingBackend::Gnuplot),
            Some("plotters") => self = self.plotting_backend(PlottingBackend::Plotters),
            Some(val) => panic!("Unexpected plotting backend '{}'", val),
            None => {}
        }

        if matches.get_flag("noplot") {
            self = self.without_plots();
        }

        if let Some(dir) = matches.get_one::<String>("save-baseline") {
            self.baseline = Baseline::Save;
            self.baseline_directory = dir.to_owned()
        }
        if matches.get_flag("discard-baseline") {
            self.baseline = Baseline::Discard;
        }
        if let Some(dir) = matches.get_one::<String>("baseline") {
            self.baseline = Baseline::CompareStrict;
            self.baseline_directory = dir.to_owned();
        }
        if let Some(dir) = matches.get_one::<String>("baseline-lenient") {
            self.baseline = Baseline::CompareLenient;
            self.baseline_directory = dir.to_owned();
        }

File: criterion.rs/src/lib.rs
Start Line: 1052
End Line: 1099
Chunks:

        if self.connection.is_some() {
            // disable all reports when connected to cargo-criterion; it will do the reporting.
            self.report.cli_enabled = false;
            self.report.bencher_enabled = false;
            self.report.csv_enabled = false;
            self.report.html = None;
        } else {
            match matches.get_one("output-format").map(String::as_str) {
                Some("bencher") => {
                    self.report.bencher_enabled = true;
                    self.report.cli_enabled = false;
                }
                _ => {
                    let verbose = matches.get_flag("verbose");
                    let verbosity = if verbose {
                        CliVerbosity::Verbose
                    } else if matches.get_flag("quiet") {
                        CliVerbosity::Quiet
                    } else {
                        CliVerbosity::Normal
                    };
                    let stdout_isatty = stdout().is_terminal();
                    let mut enable_text_overwrite = stdout_isatty && !verbose && !debug_enabled();
                    let enable_text_coloring;
                    match matches.get_one("color").map(String::as_str) {
                        Some("always") => {
                            enable_text_coloring = true;
                        }
                        Some("never") => {
                            enable_text_coloring = false;
                            enable_text_overwrite = false;
                        }
                        _ => enable_text_coloring = stdout_isatty,
                    };
                    self.report.bencher_enabled = false;
                    self.report.cli_enabled = true;
                    self.report.cli =
                        CliReport::new(enable_text_overwrite, enable_text_coloring, verbosity);
                }
            };
        }
        if let Some(&num_confidence_level) = matches.get_one("confidence-level") {
            assert!(num_confidence_level > 0.0 && num_confidence_level < 1.0);

            self.config.confidence_level = num_confidence_level;
        }

File: criterion.rs/src/lib.rs
Start Line: 1099
End Line: 1128
Chunks:
        if let Some(&num_significance_level) = matches.get_one("significance-level") {
            assert!(num_significance_level > 0.0 && num_significance_level < 1.0);

            self.config.significance_level = num_significance_level;
        }

        if matches.get_flag("quick") {
            self.config.quick_mode = true;
        }

        self
    }

    fn filter_matches(&self, id: &str) -> bool {
        match &self.filter {
            BenchmarkFilter::AcceptAll => true,
            BenchmarkFilter::Regex(regex) => regex.is_match(id),
            BenchmarkFilter::Exact(exact) => id == exact,
            BenchmarkFilter::RejectAll => false,
        }
    }

    /// Returns true iff we should save the benchmark results in
    /// json files on the local disk.
    fn should_save_baseline(&self) -> bool {
        self.connection.is_none()
            && self.load_baseline.is_none()
            && !matches!(self.baseline, Baseline::Discard)
    }

File: criterion.rs/src/lib.rs
Start Line: 1128
End Line: 1164
Chunks:

    /// Return a benchmark group. All benchmarks performed using a benchmark group will be
    /// grouped together in the final report.
    ///
    /// # Examples:
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    /// use self::criterion::*;
    ///
    /// fn bench_simple(c: &mut Criterion) {
    ///     let mut group = c.benchmark_group("My Group");
    ///
    ///     // Now we can perform benchmarks with this group
    ///     group.bench_function("Bench 1", |b| b.iter(|| 1 ));
    ///     group.bench_function("Bench 2", |b| b.iter(|| 2 ));
    ///
    ///     group.finish();
    /// }
    /// criterion_group!(benches, bench_simple);
    /// criterion_main!(benches);
    /// ```
    /// # Panics:
    /// Panics if the group name is empty
    pub fn benchmark_group<S: Into<String>>(&mut self, group_name: S) -> BenchmarkGroup<'_, M> {
        let group_name = group_name.into();
        assert!(!group_name.is_empty(), "Group name must not be empty.");

        if let Some(conn) = &self.connection {
            conn.send(&OutgoingMessage::BeginningBenchmarkGroup { group: &group_name })
                .unwrap();
        }

        BenchmarkGroup::new(self, group_name)
    }
}

File: criterion.rs/src/lib.rs
Start Line: 1164
End Line: 1197
Chunks:
impl<M> Criterion<M>
where
    M: Measurement + 'static,
{
    /// Benchmarks a function. For comparing multiple functions, see `benchmark_group`.
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    /// use self::criterion::*;
    ///
    /// fn bench(c: &mut Criterion) {
    ///     // Setup (construct data, allocate memory, etc)
    ///     c.bench_function(
    ///         "function_name",
    ///         |b| b.iter(|| {
    ///             // Code to benchmark goes here
    ///         }),
    ///     );
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    pub fn bench_function<F>(&mut self, id: &str, f: F) -> &mut Criterion<M>
    where
        F: FnMut(&mut Bencher<'_, M>),
    {
        self.benchmark_group(id)
            .bench_function(BenchmarkId::no_function(), f);
        self
    }

File: criterion.rs/src/lib.rs
Start Line: 1197
End Line: 1242
Chunks:

    /// Benchmarks a function with an input. For comparing multiple functions or multiple inputs,
    /// see `benchmark_group`.
    ///
    /// # Example
    ///
    /// ```rust
    /// #[macro_use] extern crate criterion;
    /// use self::criterion::*;
    ///
    /// fn bench(c: &mut Criterion) {
    ///     // Setup (construct data, allocate memory, etc)
    ///     let input = 5u64;
    ///     c.bench_with_input(
    ///         BenchmarkId::new("function_name", input), &input,
    ///         |b, i| b.iter(|| {
    ///             // Code to benchmark using input `i` goes here
    ///         }),
    ///     );
    /// }
    ///
    /// criterion_group!(benches, bench);
    /// criterion_main!(benches);
    /// ```
    pub fn bench_with_input<F, I>(&mut self, id: BenchmarkId, input: &I, f: F) -> &mut Criterion<M>
    where
        F: FnMut(&mut Bencher<'_, M>, &I),
    {
        // It's possible to use BenchmarkId::from_parameter to create a benchmark ID with no function
        // name. That's intended for use with BenchmarkGroups where the function name isn't necessary,
        // but here it is.
        let group_name = id.function_name.expect(
            "Cannot use BenchmarkId::from_parameter with Criterion::bench_with_input. \
                 Consider using a BenchmarkGroup or BenchmarkId::new instead.",
        );
        // Guaranteed safe because external callers can't create benchmark IDs without a parameter
        let parameter = id.parameter.unwrap();
        self.benchmark_group(group_name).bench_with_input(
            BenchmarkId::no_function_with_input(parameter),
            input,
            f,
        );
        self
    }
}

File: criterion.rs/src/lib.rs
Start Line: 1242
End Line: 1275
Chunks:

/// Enum representing different ways of measuring the throughput of benchmarked code.
/// If the throughput setting is configured for a benchmark then the estimated throughput will
/// be reported as well as the time per iteration.
// TODO: Remove serialize/deserialize from the public API.
#[derive(Debug, Clone, Serialize, Deserialize, PartialEq, Eq)]
pub enum Throughput {
    /// Measure throughput in terms of bytes/second. The value should be the number of bytes
    /// processed by one iteration of the benchmarked code. Typically, this would be the length of
    /// an input string or `&[u8]`.
    Bytes(u64),

    /// Equivalent to Bytes, but the value will be reported in terms of
    /// kilobytes (1000 bytes) per second instead of kibibytes (1024 bytes) per
    /// second, megabytes instead of mibibytes, and gigabytes instead of gibibytes.
    BytesDecimal(u64),

    /// Measure throughput in terms of elements/second. The value should be the number of elements
    /// processed by one iteration of the benchmarked code. Typically, this would be the size of a
    /// collection, but could also be the number of lines of input text or the number of values to
    /// parse.
    Elements(u64),
}

/// Axis scaling type
#[derive(Debug, Clone, Copy)]
pub enum AxisScale {
    /// Axes scale linearly
    Linear,

    /// Axes scale logarithmically
    Logarithmic,
}

File: criterion.rs/src/lib.rs
Start Line: 1275
End Line: 1314
Chunks:

/// Contains the configuration options for the plots generated by a particular benchmark
/// or benchmark group.
///
/// ```rust
/// use self::criterion::{Bencher, Criterion, PlotConfiguration, AxisScale};
///
/// let plot_config = PlotConfiguration::default()
///     .summary_scale(AxisScale::Logarithmic);
///
/// // Using Criterion::default() for simplicity; normally you'd use the macros.
/// let mut criterion = Criterion::default();
/// let mut benchmark_group = criterion.benchmark_group("Group name");
/// benchmark_group.plot_config(plot_config);
/// // Use benchmark group
/// ```
#[derive(Debug, Clone)]
pub struct PlotConfiguration {
    summary_scale: AxisScale,
}

impl Default for PlotConfiguration {
    fn default() -> PlotConfiguration {
        PlotConfiguration {
            summary_scale: AxisScale::Linear,
        }
    }
}

impl PlotConfiguration {
    #[must_use]
    /// Set the axis scale (linear or logarithmic) for the summary plots. Typically, you would
    /// set this to logarithmic if benchmarking over a range of inputs which scale exponentially.
    /// Defaults to linear.
    pub fn summary_scale(mut self, new_scale: AxisScale) -> PlotConfiguration {
        self.summary_scale = new_scale;
        self
    }
}

File: criterion.rs/src/lib.rs
Start Line: 1314
End Line: 1360
Chunks:

/// This enum allows the user to control how Criterion.rs chooses the iteration count when sampling.
/// The default is Auto, which will choose a method automatically based on the iteration time during
/// the warm-up phase.
#[derive(Debug, Clone, Copy)]
pub enum SamplingMode {
    /// Criterion.rs should choose a sampling method automatically. This is the default, and is
    /// recommended for most users and most benchmarks.
    Auto,

    /// Scale the iteration count in each sample linearly. This is suitable for most benchmarks,
    /// but it tends to require many iterations which can make it very slow for very long benchmarks.
    Linear,

    /// Keep the iteration count the same for all samples. This is not recommended, as it affects
    /// the statistics that Criterion.rs can compute. However, it requires fewer iterations than
    /// the Linear method and therefore is more suitable for very long-running benchmarks where
    /// benchmark execution time is more of a problem and statistical precision is less important.
    Flat,
}
impl SamplingMode {
    pub(crate) fn choose_sampling_mode(
        &self,
        warmup_mean_execution_time: f64,
        sample_count: u64,
        target_time: f64,
    ) -> ActualSamplingMode {
        match self {
            SamplingMode::Linear => ActualSamplingMode::Linear,
            SamplingMode::Flat => ActualSamplingMode::Flat,
            SamplingMode::Auto => {
                // Estimate execution time with linear sampling
                let total_runs = sample_count * (sample_count + 1) / 2;
                let d =
                    (target_time / warmup_mean_execution_time / total_runs as f64).ceil() as u64;
                let expected_ns = total_runs as f64 * d as f64 * warmup_mean_execution_time;

                if expected_ns > (2.0 * target_time) {
                    ActualSamplingMode::Flat
                } else {
                    ActualSamplingMode::Linear
                }
            }
        }
    }
}

File: criterion.rs/src/lib.rs
Start Line: 1360
End Line: 1367
Chunks:

/// Enum to represent the sampling mode without Auto.
#[derive(Debug, Clone, Copy, Serialize, Deserialize)]
pub(crate) enum ActualSamplingMode {
    Linear,
    Flat,
}

File: criterion.rs/src/lib.rs
Start Line: 1367
End Line: 1411
Chunks:
impl ActualSamplingMode {
    pub(crate) fn iteration_counts(
        &self,
        warmup_mean_execution_time: f64,
        sample_count: u64,
        target_time: &Duration,
    ) -> Vec<u64> {
        match self {
            ActualSamplingMode::Linear => {
                let n = sample_count;
                let met = warmup_mean_execution_time;
                let m_ns = target_time.as_nanos();
                // Solve: [d + 2*d + 3*d + ... + n*d] * met = m_ns
                let total_runs = n * (n + 1) / 2;
                let d = ((m_ns as f64 / met / total_runs as f64).ceil() as u64).max(1);
                let expected_ns = total_runs as f64 * d as f64 * met;

                if d == 1 {
                    let recommended_sample_size =
                        ActualSamplingMode::recommend_linear_sample_size(m_ns as f64, met);
                    let actual_time = Duration::from_nanos(expected_ns as u64);
                    eprint!("\nWarning: Unable to complete {} samples in {:.1?}. You may wish to increase target time to {:.1?}",
                            n, target_time, actual_time);

                    if recommended_sample_size != n {
                        eprintln!(
                            ", enable flat sampling, or reduce sample count to {}.",
                            recommended_sample_size
                        );
                    } else {
                        eprintln!(" or enable flat sampling.");
                    }
                }

                (1..(n + 1)).map(|a| a * d).collect::<Vec<u64>>()
            }
            ActualSamplingMode::Flat => {
                let n = sample_count;
                let met = warmup_mean_execution_time;
                let m_ns = target_time.as_nanos() as f64;
                let time_per_sample = m_ns / (n as f64);
                // This is pretty simplistic; we could do something smarter to fit into the allotted time.
                let iterations_per_sample = ((time_per_sample / met).ceil() as u64).max(1);


File: criterion.rs/src/lib.rs
Start Line: 1411
End Line: 1430
Chunks:
                let expected_ns = met * (iterations_per_sample * n) as f64;

                if iterations_per_sample == 1 {
                    let recommended_sample_size =
                        ActualSamplingMode::recommend_flat_sample_size(m_ns, met);
                    let actual_time = Duration::from_nanos(expected_ns as u64);
                    eprint!("\nWarning: Unable to complete {} samples in {:.1?}. You may wish to increase target time to {:.1?}",
                            n, target_time, actual_time);

                    if recommended_sample_size != n {
                        eprintln!(", or reduce sample count to {}.", recommended_sample_size);
                    } else {
                        eprintln!(".");
                    }
                }

                vec![iterations_per_sample; n as usize]
            }
        }

File: criterion.rs/src/lib.rs
Start Line: 1430
End Line: 1468
Chunks:
    }
    fn recommend_linear_sample_size(target_time: f64, met: f64) -> u64 {
        // Some math shows that n(n+1)/2 * d * met = target_time. d = 1, so it can be ignored.
        // This leaves n(n+1) = (2*target_time)/met, or n^2 + n - (2*target_time)/met = 0
        // Which can be solved with the quadratic formula. Since A and B are constant 1,
        // this simplifies to sample_size = (-1 +- sqrt(1 - 4C))/2, where C = (2*target_time)/met.
        // We don't care about the negative solution. Experimentation shows that this actually tends to
        // result in twice the desired execution time (probably because of the ceil used to calculate
        // d) so instead I use c = target_time/met.
        let c = target_time / met;
        let sample_size = (-1.0 + (4.0 * c).sqrt()) / 2.0;
        let sample_size = sample_size as u64;

        // Round down to the nearest 10 to give a margin and avoid excessive precision
        let sample_size = (sample_size / 10) * 10;

        // Clamp it to be at least 10, since criterion.rs doesn't allow sample sizes smaller than 10.
        if sample_size < 10 {
            10
        } else {
            sample_size
        }
    }

    fn recommend_flat_sample_size(target_time: f64, met: f64) -> u64 {
        let sample_size = (target_time / met) as u64;

        // Round down to the nearest 10 to give a margin and avoid excessive precision
        let sample_size = (sample_size / 10) * 10;

        // Clamp it to be at least 10, since criterion.rs doesn't allow sample sizes smaller than 10.
        if sample_size < 10 {
            10
        } else {
            sample_size
        }
    }
}

File: criterion.rs/src/lib.rs
Start Line: 1468
End Line: 1484
Chunks:

#[derive(Debug, Serialize, Deserialize)]
pub(crate) struct SavedSample {
    sampling_mode: ActualSamplingMode,
    iters: Vec<f64>,
    times: Vec<f64>,
}

/// Custom-test-framework runner. Should not be called directly.
#[doc(hidden)]
pub fn runner(benches: &[&dyn Fn()]) {
    for bench in benches {
        bench();
    }
    Criterion::default().configure_from_args().final_summary();
}

Ripgrep filtered Lines: [0, 46, 82, 130, 161, 198, 231, 269, 315, 334, 383, 395, 440, 489, 521, 545, 595, 636, 684, 728, 778, 818, 852]
File: criterion.rs/src/report.rs
Start Line: 0
End Line: 45
Chunks:
#[cfg(feature = "csv_output")]
use crate::csv_report::FileCsvReport;
use crate::stats::bivariate::regression::Slope;
use crate::stats::univariate::outliers::tukey::LabeledSample;
use crate::{html::Html, stats::bivariate::Data};

use crate::estimate::{ChangeDistributions, ChangeEstimates, Distributions, Estimate, Estimates};
use crate::format;
use crate::measurement::ValueFormatter;
use crate::stats::univariate::Sample;
use crate::stats::Distribution;
use crate::{PlotConfiguration, Throughput};
use anes::{Attribute, ClearLine, Color, ResetAttributes, SetAttribute, SetForegroundColor};
use std::cmp;
use std::collections::HashSet;
use std::fmt;
use std::io::stderr;
use std::io::Write;
use std::path::{Path, PathBuf};

const MAX_DIRECTORY_NAME_LEN: usize = 64;
const MAX_TITLE_LEN: usize = 100;

pub(crate) struct ComparisonData {
    pub p_value: f64,
    pub t_distribution: Distribution<f64>,
    pub t_value: f64,
    pub relative_estimates: ChangeEstimates,
    pub relative_distributions: ChangeDistributions,
    pub significance_threshold: f64,
    pub noise_threshold: f64,
    pub base_iter_counts: Vec<f64>,
    pub base_sample_times: Vec<f64>,
    pub base_avg_times: Vec<f64>,
    pub base_estimates: Estimates,
}

pub(crate) struct MeasurementData<'a> {
    pub data: Data<'a, f64, f64>,
    pub avg_times: LabeledSample<'a, f64>,
    pub absolute_estimates: Estimates,
    pub distributions: Distributions,
    pub comparison: Option<ComparisonData>,
    pub throughput: Option<Throughput>,
}

File: criterion.rs/src/report.rs
Start Line: 45
End Line: 81
Chunks:
impl<'a> MeasurementData<'a> {
    pub fn iter_counts(&self) -> &Sample<f64> {
        self.data.x()
    }

    #[cfg(feature = "csv_output")]
    pub fn sample_times(&self) -> &Sample<f64> {
        self.data.y()
    }
}

#[derive(Debug, Clone, Copy, Eq, PartialEq)]
pub enum ValueType {
    Bytes,
    Elements,
    Value,
}

#[derive(Clone, Serialize, Deserialize, PartialEq, Eq)]
pub struct BenchmarkId {
    pub group_id: String,
    pub function_id: Option<String>,
    pub value_str: Option<String>,
    pub throughput: Option<Throughput>,
    full_id: String,
    directory_name: String,
    title: String,
}

fn truncate_to_character_boundary(s: &mut String, max_len: usize) {
    let mut boundary = cmp::min(max_len, s.len());
    while !s.is_char_boundary(boundary) {
        boundary -= 1;
    }
    s.truncate(boundary);
}

File: criterion.rs/src/report.rs
Start Line: 81
End Line: 129
Chunks:

pub fn make_filename_safe(string: &str) -> String {
    let mut string = string.replace(
        &['?', '"', '/', '\\', '*', '<', '>', ':', '|', '^'][..],
        "_",
    );

    // Truncate to last character boundary before max length...
    truncate_to_character_boundary(&mut string, MAX_DIRECTORY_NAME_LEN);

    if cfg!(target_os = "windows") {
        {
            string = string
                // On Windows, spaces in the end of the filename are ignored and will be trimmed.
                //
                // Without trimming ourselves, creating a directory `dir ` will silently create
                // `dir` instead, but then operations on files like `dir /file` will fail.
                //
                // Also note that it's important to do this *after* trimming to MAX_DIRECTORY_NAME_LEN,
                // otherwise it can trim again to a name with a trailing space.
                .trim_end()
                // On Windows, file names are not case-sensitive, so lowercase everything.
                .to_lowercase();
        }
    }

    string
}

impl BenchmarkId {
    pub fn new(
        group_id: String,
        function_id: Option<String>,
        value_str: Option<String>,
        throughput: Option<Throughput>,
    ) -> BenchmarkId {
        let full_id = match (&function_id, &value_str) {
            (Some(func), Some(val)) => format!("{}/{}/{}", group_id, func, val),
            (Some(func), &None) => format!("{}/{}", group_id, func),
            (&None, Some(val)) => format!("{}/{}", group_id, val),
            (&None, &None) => group_id.clone(),
        };

        let mut title = full_id.clone();
        truncate_to_character_boundary(&mut title, MAX_TITLE_LEN);
        if title != full_id {
            title.push_str("...");
        }

File: criterion.rs/src/report.rs
Start Line: 129
End Line: 160
Chunks:

        let directory_name = match (&function_id, &value_str) {
            (Some(func), Some(val)) => format!(
                "{}/{}/{}",
                make_filename_safe(&group_id),
                make_filename_safe(func),
                make_filename_safe(val)
            ),
            (Some(func), &None) => format!(
                "{}/{}",
                make_filename_safe(&group_id),
                make_filename_safe(func)
            ),
            (&None, Some(val)) => format!(
                "{}/{}",
                make_filename_safe(&group_id),
                make_filename_safe(val)
            ),
            (&None, &None) => make_filename_safe(&group_id),
        };

        BenchmarkId {
            group_id,
            function_id,
            value_str,
            throughput,
            full_id,
            directory_name,
            title,
        }
    }

File: criterion.rs/src/report.rs
Start Line: 160
End Line: 197
Chunks:

    pub fn id(&self) -> &str {
        &self.full_id
    }

    pub fn as_title(&self) -> &str {
        &self.title
    }

    pub fn as_directory_name(&self) -> &str {
        &self.directory_name
    }

    pub fn as_number(&self) -> Option<f64> {
        match self.throughput {
            Some(Throughput::Bytes(n))
            | Some(Throughput::Elements(n))
            | Some(Throughput::BytesDecimal(n)) => Some(n as f64),
            None => self
                .value_str
                .as_ref()
                .and_then(|string| string.parse::<f64>().ok()),
        }
    }

    pub fn value_type(&self) -> Option<ValueType> {
        match self.throughput {
            Some(Throughput::Bytes(_)) => Some(ValueType::Bytes),
            Some(Throughput::BytesDecimal(_)) => Some(ValueType::Bytes),
            Some(Throughput::Elements(_)) => Some(ValueType::Elements),
            None => self
                .value_str
                .as_ref()
                .and_then(|string| string.parse::<f64>().ok())
                .map(|_| ValueType::Value),
        }
    }

File: criterion.rs/src/report.rs
Start Line: 197
End Line: 230
Chunks:

    pub fn ensure_directory_name_unique(&mut self, existing_directories: &HashSet<String>) {
        if !existing_directories.contains(self.as_directory_name()) {
            return;
        }

        let mut counter = 2;
        loop {
            let new_dir_name = format!("{}_{}", self.as_directory_name(), counter);
            if !existing_directories.contains(&new_dir_name) {
                self.directory_name = new_dir_name;
                return;
            }
            counter += 1;
        }
    }

    pub fn ensure_title_unique(&mut self, existing_titles: &HashSet<String>) {
        if !existing_titles.contains(self.as_title()) {
            return;
        }

        let mut counter = 2;
        loop {
            let new_title = format!("{} #{}", self.as_title(), counter);
            if !existing_titles.contains(&new_title) {
                self.title = new_title;
                return;
            }
            counter += 1;
        }
    }
}

File: criterion.rs/src/report.rs
Start Line: 230
End Line: 268
Chunks:
impl fmt::Display for BenchmarkId {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        f.write_str(self.as_title())
    }
}
impl fmt::Debug for BenchmarkId {
    fn fmt(&self, f: &mut fmt::Formatter<'_>) -> fmt::Result {
        fn format_opt(opt: &Option<String>) -> String {
            match *opt {
                Some(ref string) => format!("\"{}\"", string),
                None => "None".to_owned(),
            }
        }

        write!(
            f,
            "BenchmarkId {{ group_id: \"{}\", function_id: {}, value_str: {}, throughput: {:?} }}",
            self.group_id,
            format_opt(&self.function_id),
            format_opt(&self.value_str),
            self.throughput,
        )
    }
}

pub struct ReportContext {
    pub output_directory: PathBuf,
    pub plot_config: PlotConfiguration,
}
impl ReportContext {
    pub fn report_path<P: AsRef<Path> + ?Sized>(&self, id: &BenchmarkId, file_name: &P) -> PathBuf {
        let mut path = self.output_directory.clone();
        path.push(id.as_directory_name());
        path.push("report");
        path.push(file_name);
        path
    }
}

File: criterion.rs/src/report.rs
Start Line: 268
End Line: 314
Chunks:

pub(crate) trait Report {
    fn test_start(&self, _id: &BenchmarkId, _context: &ReportContext) {}
    fn test_pass(&self, _id: &BenchmarkId, _context: &ReportContext) {}

    fn benchmark_start(&self, _id: &BenchmarkId, _context: &ReportContext) {}
    fn profile(&self, _id: &BenchmarkId, _context: &ReportContext, _profile_ns: f64) {}
    fn warmup(&self, _id: &BenchmarkId, _context: &ReportContext, _warmup_ns: f64) {}
    fn terminated(&self, _id: &BenchmarkId, _context: &ReportContext) {}
    fn analysis(&self, _id: &BenchmarkId, _context: &ReportContext) {}
    fn measurement_start(
        &self,
        _id: &BenchmarkId,
        _context: &ReportContext,
        _sample_count: u64,
        _estimate_ns: f64,
        _iter_count: u64,
    ) {
    }
    fn measurement_complete(
        &self,
        _id: &BenchmarkId,
        _context: &ReportContext,
        _measurements: &MeasurementData<'_>,
        _formatter: &dyn ValueFormatter,
    ) {
    }
    fn summarize(
        &self,
        _context: &ReportContext,
        _all_ids: &[BenchmarkId],
        _formatter: &dyn ValueFormatter,
    ) {
    }
    fn final_summary(&self, _context: &ReportContext) {}
    fn group_separator(&self) {}
}

pub(crate) struct Reports {
    pub(crate) cli_enabled: bool,
    pub(crate) cli: CliReport,
    pub(crate) bencher_enabled: bool,
    pub(crate) bencher: BencherReport,
    pub(crate) csv_enabled: bool,
    pub(crate) html: Option<Html>,
}

File: criterion.rs/src/report.rs
Start Line: 314
End Line: 333
Chunks:
macro_rules! reports_impl {
    (fn $name:ident(&self, $($argn:ident: $argt:ty),*)) => {
        fn $name(&self, $($argn: $argt),* ) {
            if self.cli_enabled {
                self.cli.$name($($argn),*);
            }
            if self.bencher_enabled {
                self.bencher.$name($($argn),*);
            }
            #[cfg(feature = "csv_output")]
            if self.csv_enabled {
                FileCsvReport.$name($($argn),*);
            }
            if let Some(reporter) = &self.html {
                reporter.$name($($argn),*);
            }
        }
    };
}

File: criterion.rs/src/report.rs
Start Line: 333
End Line: 382
Chunks:

impl Report for Reports {
    reports_impl!(fn test_start(&self, id: &BenchmarkId, context: &ReportContext));
    reports_impl!(fn test_pass(&self, id: &BenchmarkId, context: &ReportContext));
    reports_impl!(fn benchmark_start(&self, id: &BenchmarkId, context: &ReportContext));
    reports_impl!(fn profile(&self, id: &BenchmarkId, context: &ReportContext, profile_ns: f64));
    reports_impl!(fn warmup(&self, id: &BenchmarkId, context: &ReportContext, warmup_ns: f64));
    reports_impl!(fn terminated(&self, id: &BenchmarkId, context: &ReportContext));
    reports_impl!(fn analysis(&self, id: &BenchmarkId, context: &ReportContext));
    reports_impl!(fn measurement_start(
        &self,
        id: &BenchmarkId,
        context: &ReportContext,
        sample_count: u64,
        estimate_ns: f64,
        iter_count: u64
    ));
    reports_impl!(
    fn measurement_complete(
        &self,
        id: &BenchmarkId,
        context: &ReportContext,
        measurements: &MeasurementData<'_>,
        formatter: &dyn ValueFormatter
    ));
    reports_impl!(
    fn summarize(
        &self,
        context: &ReportContext,
        all_ids: &[BenchmarkId],
        formatter: &dyn ValueFormatter
    ));

    reports_impl!(fn final_summary(&self, context: &ReportContext));
    reports_impl!(fn group_separator(&self, ));
}

#[derive(Debug, Clone, Copy, Eq, PartialEq)]
pub(crate) enum CliVerbosity {
    Quiet,
    Normal,
    Verbose,
}

pub(crate) struct CliReport {
    pub enable_text_overwrite: bool,
    pub enable_text_coloring: bool,
    pub verbosity: CliVerbosity,
}

File: criterion.rs/src/report.rs
Start Line: 382
End Line: 394
Chunks:
impl CliReport {
    pub fn new(
        enable_text_overwrite: bool,
        enable_text_coloring: bool,
        verbosity: CliVerbosity,
    ) -> CliReport {
        CliReport {
            enable_text_overwrite,
            enable_text_coloring,
            verbosity,
        }
    }

File: criterion.rs/src/report.rs
Start Line: 394
End Line: 439
Chunks:

    fn text_overwrite(&self) {
        if self.enable_text_overwrite {
            eprint!("\r{}", ClearLine::All)
        }
    }

    // Passing a String is the common case here.
    #[cfg_attr(feature = "cargo-clippy", allow(clippy::needless_pass_by_value))]
    fn print_overwritable(&self, s: String) {
        if self.enable_text_overwrite {
            eprint!("{}", s);
            stderr().flush().unwrap();
        } else {
            eprintln!("{}", s);
        }
    }

    fn with_color(&self, color: Color, s: &str) -> String {
        if self.enable_text_coloring {
            format!("{}{}{}", SetForegroundColor(color), s, ResetAttributes)
        } else {
            String::from(s)
        }
    }

    fn green(&self, s: &str) -> String {
        self.with_color(Color::DarkGreen, s)
    }

    fn yellow(&self, s: &str) -> String {
        self.with_color(Color::DarkYellow, s)
    }

    fn red(&self, s: &str) -> String {
        self.with_color(Color::DarkRed, s)
    }

    fn bold(&self, s: String) -> String {
        if self.enable_text_coloring {
            format!("{}{}{}", SetAttribute(Attribute::Bold), s, ResetAttributes)
        } else {
            s
        }
    }

File: criterion.rs/src/report.rs
Start Line: 439
End Line: 488
Chunks:

    fn faint(&self, s: String) -> String {
        if self.enable_text_coloring {
            format!("{}{}{}", SetAttribute(Attribute::Faint), s, ResetAttributes)
        } else {
            s
        }
    }

    pub fn outliers(&self, sample: &LabeledSample<'_, f64>) {
        let (los, lom, _, him, his) = sample.count();
        let noutliers = los + lom + him + his;
        let sample_size = sample.len();

        if noutliers == 0 {
            return;
        }

        let percent = |n: usize| 100. * n as f64 / sample_size as f64;

        println!(
            "{}",
            self.yellow(&format!(
                "Found {} outliers among {} measurements ({:.2}%)",
                noutliers,
                sample_size,
                percent(noutliers)
            ))
        );

        let print = |n, label| {
            if n != 0 {
                println!("  {} ({:.2}%) {}", n, percent(n), label);
            }
        };

        print(los, "low severe");
        print(lom, "low mild");
        print(him, "high mild");
        print(his, "high severe");
    }
}
impl Report for CliReport {
    fn test_start(&self, id: &BenchmarkId, _: &ReportContext) {
        println!("Testing {}", id);
    }
    fn test_pass(&self, _: &BenchmarkId, _: &ReportContext) {
        println!("Success");
    }

File: criterion.rs/src/report.rs
Start Line: 488
End Line: 520
Chunks:

    fn benchmark_start(&self, id: &BenchmarkId, _: &ReportContext) {
        self.print_overwritable(format!("Benchmarking {}", id));
    }

    fn profile(&self, id: &BenchmarkId, _: &ReportContext, warmup_ns: f64) {
        self.text_overwrite();
        self.print_overwritable(format!(
            "Benchmarking {}: Profiling for {}",
            id,
            format::time(warmup_ns)
        ));
    }

    fn warmup(&self, id: &BenchmarkId, _: &ReportContext, warmup_ns: f64) {
        self.text_overwrite();
        self.print_overwritable(format!(
            "Benchmarking {}: Warming up for {}",
            id,
            format::time(warmup_ns)
        ));
    }

    fn terminated(&self, id: &BenchmarkId, _: &ReportContext) {
        self.text_overwrite();
        println!("Benchmarking {}: Complete (Analysis Disabled)", id);
    }

    fn analysis(&self, id: &BenchmarkId, _: &ReportContext) {
        self.text_overwrite();
        self.print_overwritable(format!("Benchmarking {}: Analyzing", id));
    }

File: criterion.rs/src/report.rs
Start Line: 520
End Line: 544
Chunks:

    fn measurement_start(
        &self,
        id: &BenchmarkId,
        _: &ReportContext,
        sample_count: u64,
        estimate_ns: f64,
        iter_count: u64,
    ) {
        self.text_overwrite();
        let iter_string = if matches!(self.verbosity, CliVerbosity::Verbose) {
            format!("{} iterations", iter_count)
        } else {
            format::iter_count(iter_count)
        };

        self.print_overwritable(format!(
            "Benchmarking {}: Collecting {} samples in estimated {} ({})",
            id,
            sample_count,
            format::time(estimate_ns),
            iter_string
        ));
    }

File: criterion.rs/src/report.rs
Start Line: 544
End Line: 594
Chunks:

    fn measurement_complete(
        &self,
        id: &BenchmarkId,
        _: &ReportContext,
        meas: &MeasurementData<'_>,
        formatter: &dyn ValueFormatter,
    ) {
        self.text_overwrite();

        let typical_estimate = &meas.absolute_estimates.typical();

        {
            let mut id = id.as_title().to_owned();

            if id.len() > 23 {
                println!("{}", self.green(&id));
                id.clear();
            }
            let id_len = id.len();

            println!(
                "{}{}time:   [{} {} {}]",
                self.green(&id),
                " ".repeat(24 - id_len),
                self.faint(
                    formatter.format_value(typical_estimate.confidence_interval.lower_bound)
                ),
                self.bold(formatter.format_value(typical_estimate.point_estimate)),
                self.faint(
                    formatter.format_value(typical_estimate.confidence_interval.upper_bound)
                )
            );
        }

        if let Some(ref throughput) = meas.throughput {
            println!(
                "{}thrpt:  [{} {} {}]",
                " ".repeat(24),
                self.faint(formatter.format_throughput(
                    throughput,
                    typical_estimate.confidence_interval.upper_bound
                )),
                self.bold(formatter.format_throughput(throughput, typical_estimate.point_estimate)),
                self.faint(formatter.format_throughput(
                    throughput,
                    typical_estimate.confidence_interval.lower_bound
                )),
            )
        }

File: criterion.rs/src/report.rs
Start Line: 594
End Line: 635
Chunks:

        if !matches!(self.verbosity, CliVerbosity::Quiet) {
            if let Some(ref comp) = meas.comparison {
                let different_mean = comp.p_value < comp.significance_threshold;
                let mean_est = &comp.relative_estimates.mean;
                let point_estimate = mean_est.point_estimate;
                let mut point_estimate_str = format::change(point_estimate, true);
                // The change in throughput is related to the change in timing. Reducing the timing by
                // 50% increases the throughput by 100%.
                let to_thrpt_estimate = |ratio: f64| 1.0 / (1.0 + ratio) - 1.0;
                let mut thrpt_point_estimate_str =
                    format::change(to_thrpt_estimate(point_estimate), true);
                let explanation_str: String;

                if !different_mean {
                    explanation_str = "No change in performance detected.".to_owned();
                } else {
                    let comparison = compare_to_threshold(mean_est, comp.noise_threshold);
                    match comparison {
                        ComparisonResult::Improved => {
                            point_estimate_str = self.green(&self.bold(point_estimate_str));
                            thrpt_point_estimate_str =
                                self.green(&self.bold(thrpt_point_estimate_str));
                            explanation_str =
                                format!("Performance has {}.", self.green("improved"));
                        }
                        ComparisonResult::Regressed => {
                            point_estimate_str = self.red(&self.bold(point_estimate_str));
                            thrpt_point_estimate_str =
                                self.red(&self.bold(thrpt_point_estimate_str));
                            explanation_str = format!("Performance has {}.", self.red("regressed"));
                        }
                        ComparisonResult::NonSignificant => {
                            explanation_str = "Change within noise threshold.".to_owned();
                        }
                    }
                }

                if meas.throughput.is_some() {
                    println!("{}change:", " ".repeat(17));


File: criterion.rs/src/report.rs
Start Line: 635
End Line: 683
Chunks:
                    println!(
                        "{}time:   [{} {} {}] (p = {:.2} {} {:.2})",
                        " ".repeat(24),
                        self.faint(format::change(
                            mean_est.confidence_interval.lower_bound,
                            true
                        )),
                        point_estimate_str,
                        self.faint(format::change(
                            mean_est.confidence_interval.upper_bound,
                            true
                        )),
                        comp.p_value,
                        if different_mean { "<" } else { ">" },
                        comp.significance_threshold
                    );
                    println!(
                        "{}thrpt:  [{} {} {}]",
                        " ".repeat(24),
                        self.faint(format::change(
                            to_thrpt_estimate(mean_est.confidence_interval.upper_bound),
                            true
                        )),
                        thrpt_point_estimate_str,
                        self.faint(format::change(
                            to_thrpt_estimate(mean_est.confidence_interval.lower_bound),
                            true
                        )),
                    );
                } else {
                    println!(
                        "{}change: [{} {} {}] (p = {:.2} {} {:.2})",
                        " ".repeat(24),
                        self.faint(format::change(
                            mean_est.confidence_interval.lower_bound,
                            true
                        )),
                        point_estimate_str,
                        self.faint(format::change(
                            mean_est.confidence_interval.upper_bound,
                            true
                        )),
                        comp.p_value,
                        if different_mean { "<" } else { ">" },
                        comp.significance_threshold
                    );
                }


File: criterion.rs/src/report.rs
Start Line: 683
End Line: 727
Chunks:
                println!("{}{}", " ".repeat(24), explanation_str);
            }
        }

        if !matches!(self.verbosity, CliVerbosity::Quiet) {
            self.outliers(&meas.avg_times);
        }

        if matches!(self.verbosity, CliVerbosity::Verbose) {
            let format_short_estimate = |estimate: &Estimate| -> String {
                format!(
                    "[{} {}]",
                    formatter.format_value(estimate.confidence_interval.lower_bound),
                    formatter.format_value(estimate.confidence_interval.upper_bound)
                )
            };

            let data = &meas.data;
            if let Some(slope_estimate) = meas.absolute_estimates.slope.as_ref() {
                println!(
                    "{:<7}{} {:<15}[{:0.7} {:0.7}]",
                    "slope",
                    format_short_estimate(slope_estimate),
                    "R^2",
                    Slope(slope_estimate.confidence_interval.lower_bound).r_squared(data),
                    Slope(slope_estimate.confidence_interval.upper_bound).r_squared(data),
                );
            }
            println!(
                "{:<7}{} {:<15}{}",
                "mean",
                format_short_estimate(&meas.absolute_estimates.mean),
                "std. dev.",
                format_short_estimate(&meas.absolute_estimates.std_dev),
            );
            println!(
                "{:<7}{} {:<15}{}",
                "median",
                format_short_estimate(&meas.absolute_estimates.median),
                "med. abs. dev.",
                format_short_estimate(&meas.absolute_estimates.median_abs_dev),
            );
        }
    }

File: criterion.rs/src/report.rs
Start Line: 727
End Line: 777
Chunks:

    fn group_separator(&self) {
        println!();
    }
}

pub struct BencherReport;
impl Report for BencherReport {
    fn measurement_start(
        &self,
        id: &BenchmarkId,
        _context: &ReportContext,
        _sample_count: u64,
        _estimate_ns: f64,
        _iter_count: u64,
    ) {
        print!("test {} ... ", id);
    }

    fn measurement_complete(
        &self,
        _id: &BenchmarkId,
        _: &ReportContext,
        meas: &MeasurementData<'_>,
        formatter: &dyn ValueFormatter,
    ) {
        let mut values = [
            meas.absolute_estimates.median.point_estimate,
            meas.absolute_estimates.std_dev.point_estimate,
        ];
        let unit = formatter.scale_for_machines(&mut values);

        println!(
            "bench: {:>11} {}/iter (+/- {})",
            format::integer(values[0]),
            unit,
            format::integer(values[1])
        );
    }

    fn group_separator(&self) {
        println!();
    }
}

enum ComparisonResult {
    Improved,
    Regressed,
    NonSignificant,
}

File: criterion.rs/src/report.rs
Start Line: 777
End Line: 817
Chunks:

fn compare_to_threshold(estimate: &Estimate, noise: f64) -> ComparisonResult {
    let ci = &estimate.confidence_interval;
    let lb = ci.lower_bound;
    let ub = ci.upper_bound;

    if lb < -noise && ub < -noise {
        ComparisonResult::Improved
    } else if lb > noise && ub > noise {
        ComparisonResult::Regressed
    } else {
        ComparisonResult::NonSignificant
    }
}

#[cfg(test)]
mod test {
    use super::*;

    #[test]
    fn test_make_filename_safe_replaces_characters() {
        let input = "?/\\*\"";
        let safe = make_filename_safe(input);
        assert_eq!("_____", &safe);
    }

    #[test]
    fn test_make_filename_safe_truncates_long_strings() {
        let input = "this is a very long string. it is too long to be safe as a directory name, and so it needs to be truncated. what a long string this is.";
        let safe = make_filename_safe(input);
        assert!(input.len() > MAX_DIRECTORY_NAME_LEN);
        assert_eq!(&input[0..MAX_DIRECTORY_NAME_LEN], &safe);
    }

    #[test]
    fn test_make_filename_safe_respects_character_boundaries() {
        let input = "";
        let safe = make_filename_safe(input);
        assert!(safe.len() < MAX_DIRECTORY_NAME_LEN);
    }

File: criterion.rs/src/report.rs
Start Line: 817
End Line: 851
Chunks:

    #[test]
    fn test_benchmark_id_make_directory_name_unique() {
        let existing_id = BenchmarkId::new(
            "group".to_owned(),
            Some("function".to_owned()),
            Some("value".to_owned()),
            None,
        );
        let mut directories = HashSet::new();
        directories.insert(existing_id.as_directory_name().to_owned());

        let mut new_id = existing_id.clone();
        new_id.ensure_directory_name_unique(&directories);
        assert_eq!("group/function/value_2", new_id.as_directory_name());
        directories.insert(new_id.as_directory_name().to_owned());

        new_id = existing_id;
        new_id.ensure_directory_name_unique(&directories);
        assert_eq!("group/function/value_3", new_id.as_directory_name());
        directories.insert(new_id.as_directory_name().to_owned());
    }
    #[test]
    fn test_benchmark_id_make_long_directory_name_unique() {
        let long_name = (0..MAX_DIRECTORY_NAME_LEN).map(|_| 'a').collect::<String>();
        let existing_id = BenchmarkId::new(long_name, None, None, None);
        let mut directories = HashSet::new();
        directories.insert(existing_id.as_directory_name().to_owned());

        let mut new_id = existing_id.clone();
        new_id.ensure_directory_name_unique(&directories);
        assert_ne!(existing_id.as_directory_name(), new_id.as_directory_name());
    }
}

Ripgrep filtered Lines: [0, 47, 95, 139, 189, 232, 271, 317, 332, 378, 388, 436, 483, 527, 560]
File: criterion.rs/tests/criterion_tests.rs
Start Line: 0
End Line: 46
Chunks:
#[cfg(feature = "plotters")]
use criterion::SamplingMode;
use criterion::{
    criterion_group, criterion_main, profiler::Profiler, BatchSize, BenchmarkId, Criterion,
};
use serde_json::value::Value;
use std::cell::{Cell, RefCell};
use std::cmp::max;
use std::fs::File;
use std::path::{Path, PathBuf};
use std::rc::Rc;
use std::time::{Duration, SystemTime};
use tempfile::{tempdir, TempDir};
use walkdir::WalkDir;

/*
 * Please note that these tests are not complete examples of how to use
 * Criterion.rs. See the benches folder for actual examples.
 */
fn temp_dir() -> TempDir {
    tempdir().unwrap()
}

// Configure a Criterion struct to perform really fast benchmarks. This is not
// recommended for real benchmarking, only for testing.
fn short_benchmark(dir: &TempDir) -> Criterion {
    Criterion::default()
        .output_directory(dir.path())
        .warm_up_time(Duration::from_millis(250))
        .measurement_time(Duration::from_millis(500))
        .nresamples(2000)
}

#[derive(Clone)]
struct Counter {
    counter: Rc<RefCell<usize>>,
}
impl Counter {
    fn count(&self) {
        *(*self.counter).borrow_mut() += 1;
    }

    fn read(&self) -> usize {
        *(*self.counter).borrow()
    }
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 46
End Line: 94
Chunks:
impl Default for Counter {
    fn default() -> Counter {
        Counter {
            counter: Rc::new(RefCell::new(0)),
        }
    }
}

fn verify_file(dir: &Path, path: &str) -> PathBuf {
    let full_path = dir.join(path);
    assert!(
        full_path.is_file(),
        "File {:?} does not exist or is not a file",
        full_path
    );
    let metadata = full_path.metadata().unwrap();
    assert!(metadata.len() > 0);
    full_path
}

fn verify_json(dir: &Path, path: &str) {
    let full_path = verify_file(dir, path);
    let f = File::open(full_path).unwrap();
    serde_json::from_reader::<File, Value>(f).unwrap();
}

#[cfg(feature = "html_reports")]
fn verify_svg(dir: &Path, path: &str) {
    verify_file(dir, path);
}

#[cfg(feature = "html_reports")]
fn verify_html(dir: &Path, path: &str) {
    verify_file(dir, path);
}

fn verify_stats(dir: &Path, baseline: &str) {
    verify_json(dir, &format!("{}/estimates.json", baseline));
    verify_json(dir, &format!("{}/sample.json", baseline));
    verify_json(dir, &format!("{}/tukey.json", baseline));
    verify_json(dir, &format!("{}/benchmark.json", baseline));
    #[cfg(feature = "csv_output")]
    verify_file(dir, &format!("{}/raw.csv", baseline));
}

fn verify_not_exists(dir: &Path, path: &str) {
    assert!(!dir.join(path).exists());
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 94
End Line: 138
Chunks:

fn latest_modified(dir: &Path) -> SystemTime {
    let mut newest_update: Option<SystemTime> = None;
    for entry in WalkDir::new(dir) {
        let entry = entry.unwrap();
        let modified = entry.metadata().unwrap().modified().unwrap();
        newest_update = match newest_update {
            Some(latest) => Some(max(latest, modified)),
            None => Some(modified),
        };
    }

    newest_update.expect("failed to find a single time in directory")
}

#[test]
fn test_creates_directory() {
    let dir = temp_dir();
    short_benchmark(&dir).bench_function("test_creates_directory", |b| b.iter(|| 10));
    assert!(dir.path().join("test_creates_directory").is_dir());
}

#[test]
fn test_without_plots() {
    let dir = temp_dir();
    short_benchmark(&dir)
        .without_plots()
        .bench_function("test_without_plots", |b| b.iter(|| 10));

    for entry in WalkDir::new(dir.path().join("test_without_plots")) {
        let entry = entry.ok();
        let is_svg = entry
            .as_ref()
            .and_then(|entry| entry.path().extension())
            .and_then(|ext| ext.to_str())
            .map(|ext| ext == "svg")
            .unwrap_or(false);
        assert!(
            !is_svg,
            "Found SVG file ({:?}) in output directory with plots disabled",
            entry.unwrap().file_name()
        );
    }
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 138
End Line: 188
Chunks:

#[test]
fn test_save_baseline() {
    let dir = temp_dir();
    println!("tmp directory is {:?}", dir.path());
    short_benchmark(&dir)
        .save_baseline("some-baseline".to_owned())
        .bench_function("test_save_baseline", |b| b.iter(|| 10));

    let dir = dir.path().join("test_save_baseline");
    verify_stats(&dir, "some-baseline");

    verify_not_exists(&dir, "base");
}

#[test]
fn test_retain_baseline() {
    // Initial benchmark to populate
    let dir = temp_dir();
    short_benchmark(&dir)
        .save_baseline("some-baseline".to_owned())
        .bench_function("test_retain_baseline", |b| b.iter(|| 10));

    let pre_modified = latest_modified(&dir.path().join("test_retain_baseline/some-baseline"));

    short_benchmark(&dir)
        .retain_baseline("some-baseline".to_owned(), true)
        .bench_function("test_retain_baseline", |b| b.iter(|| 10));

    let post_modified = latest_modified(&dir.path().join("test_retain_baseline/some-baseline"));

    assert_eq!(pre_modified, post_modified, "baseline modified by retain");
}

#[test]
#[should_panic(expected = "Baseline 'some-baseline' must exist before comparison is allowed")]
fn test_compare_baseline_strict_panics_when_missing_baseline() {
    let dir = temp_dir();
    short_benchmark(&dir)
        .retain_baseline("some-baseline".to_owned(), true)
        .bench_function("test_compare_baseline", |b| b.iter(|| 10));
}

#[test]
fn test_compare_baseline_lenient_when_missing_baseline() {
    let dir = temp_dir();
    short_benchmark(&dir)
        .retain_baseline("some-baseline".to_owned(), false)
        .bench_function("test_compare_baseline", |b| b.iter(|| 10));
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 188
End Line: 231
Chunks:

#[test]
fn test_sample_size() {
    let dir = temp_dir();
    let counter = Counter::default();

    let clone = counter.clone();
    short_benchmark(&dir)
        .sample_size(50)
        .bench_function("test_sample_size", move |b| {
            clone.count();
            b.iter(|| 10)
        });

    // This function will be called more than sample_size times because of the
    // warmup.
    assert!(counter.read() > 50);
}

#[test]
fn test_warmup_time() {
    let dir = temp_dir();
    let counter1 = Counter::default();

    let clone = counter1.clone();
    short_benchmark(&dir)
        .warm_up_time(Duration::from_millis(100))
        .bench_function("test_warmup_time_1", move |b| {
            clone.count();
            b.iter(|| 10)
        });

    let counter2 = Counter::default();
    let clone = counter2.clone();
    short_benchmark(&dir)
        .warm_up_time(Duration::from_millis(2000))
        .bench_function("test_warmup_time_2", move |b| {
            clone.count();
            b.iter(|| 10)
        });

    assert!(counter1.read() < counter2.read());
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 231
End Line: 270
Chunks:

#[test]
fn test_measurement_time() {
    let dir = temp_dir();
    let counter1 = Counter::default();

    let clone = counter1.clone();
    short_benchmark(&dir)
        .measurement_time(Duration::from_millis(100))
        .bench_function("test_meas_time_1", move |b| b.iter(|| clone.count()));

    let counter2 = Counter::default();
    let clone = counter2.clone();
    short_benchmark(&dir)
        .measurement_time(Duration::from_millis(2000))
        .bench_function("test_meas_time_2", move |b| b.iter(|| clone.count()));

    assert!(counter1.read() < counter2.read());
}

#[test]
fn test_bench_function() {
    let dir = temp_dir();
    short_benchmark(&dir).bench_function("test_bench_function", move |b| b.iter(|| 10));
}

#[test]
fn test_filtering() {
    let dir = temp_dir();
    let counter = Counter::default();
    let clone = counter.clone();

    short_benchmark(&dir)
        .with_filter("Foo")
        .bench_function("test_filtering", move |b| b.iter(|| clone.count()));

    assert_eq!(counter.read(), 0);
    assert!(!dir.path().join("test_filtering").is_dir());
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 270
End Line: 316
Chunks:

#[test]
fn test_timing_loops() {
    let dir = temp_dir();
    let mut c = short_benchmark(&dir);
    let mut group = c.benchmark_group("test_timing_loops");
    group.bench_function("iter_with_setup", |b| {
        b.iter_with_setup(|| vec![10], |v| v[0])
    });
    group.bench_function("iter_with_large_setup", |b| {
        b.iter_batched(|| vec![10], |v| v[0], BatchSize::NumBatches(1))
    });
    group.bench_function("iter_with_large_drop", |b| {
        b.iter_with_large_drop(|| vec![10; 100])
    });
    group.bench_function("iter_batched_small", |b| {
        b.iter_batched(|| vec![10], |v| v[0], BatchSize::SmallInput)
    });
    group.bench_function("iter_batched_large", |b| {
        b.iter_batched(|| vec![10], |v| v[0], BatchSize::LargeInput)
    });
    group.bench_function("iter_batched_per_iteration", |b| {
        b.iter_batched(|| vec![10], |v| v[0], BatchSize::PerIteration)
    });
    group.bench_function("iter_batched_one_batch", |b| {
        b.iter_batched(|| vec![10], |v| v[0], BatchSize::NumBatches(1))
    });
    group.bench_function("iter_batched_10_iterations", |b| {
        b.iter_batched(|| vec![10], |v| v[0], BatchSize::NumIterations(10))
    });
    group.bench_function("iter_batched_ref_small", |b| {
        b.iter_batched_ref(|| vec![10], |v| v[0], BatchSize::SmallInput)
    });
    group.bench_function("iter_batched_ref_large", |b| {
        b.iter_batched_ref(|| vec![10], |v| v[0], BatchSize::LargeInput)
    });
    group.bench_function("iter_batched_ref_per_iteration", |b| {
        b.iter_batched_ref(|| vec![10], |v| v[0], BatchSize::PerIteration)
    });
    group.bench_function("iter_batched_ref_one_batch", |b| {
        b.iter_batched_ref(|| vec![10], |v| v[0], BatchSize::NumBatches(1))
    });
    group.bench_function("iter_batched_ref_10_iterations", |b| {
        b.iter_batched_ref(|| vec![10], |v| v[0], BatchSize::NumIterations(10))
    });
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 316
End Line: 331
Chunks:

// Verify that all expected output files are present
#[cfg(feature = "plotters")]
#[test]
fn test_output_files() {
    let tempdir = temp_dir();
    // Run benchmarks twice to produce comparisons
    for _ in 0..2 {
        let mut c = short_benchmark(&tempdir);
        let mut group = c.benchmark_group("test_output");
        group.sampling_mode(SamplingMode::Linear);
        group.bench_function("output_1", |b| b.iter(|| 10));
        group.bench_function("output_2", |b| b.iter(|| 20));
        group.bench_function("output_\\/*\"?", |b| b.iter(|| 30));
    }

File: criterion.rs/tests/criterion_tests.rs
Start Line: 331
End Line: 377
Chunks:

    // For each benchmark, assert that the expected files are present.
    for x in 0..3 {
        let dir = if x == 2 {
            // Check that certain special characters are replaced with underscores
            tempdir.path().join("test_output/output______")
        } else {
            tempdir.path().join(format!("test_output/output_{}", x + 1))
        };

        verify_stats(&dir, "new");
        verify_stats(&dir, "base");
        verify_json(&dir, "change/estimates.json");

        #[cfg(feature = "html_reports")]
        {
            verify_svg(&dir, "report/MAD.svg");
            verify_svg(&dir, "report/mean.svg");
            verify_svg(&dir, "report/median.svg");
            verify_svg(&dir, "report/pdf.svg");
            verify_svg(&dir, "report/regression.svg");
            verify_svg(&dir, "report/SD.svg");
            verify_svg(&dir, "report/slope.svg");
            verify_svg(&dir, "report/typical.svg");
            verify_svg(&dir, "report/both/pdf.svg");
            verify_svg(&dir, "report/both/regression.svg");
            verify_svg(&dir, "report/change/mean.svg");
            verify_svg(&dir, "report/change/median.svg");
            verify_svg(&dir, "report/change/t-test.svg");

            verify_svg(&dir, "report/pdf_small.svg");
            verify_svg(&dir, "report/regression_small.svg");
            verify_svg(&dir, "report/relative_pdf_small.svg");
            verify_svg(&dir, "report/relative_regression_small.svg");
            verify_html(&dir, "report/index.html");
        }
    }

    #[cfg(feature = "html_reports")]
    {
        // Check for overall report files
        let dir = tempdir.path().join("test_output");

        verify_svg(&dir, "report/violin.svg");
        verify_html(&dir, "report/index.html");
    }

File: criterion.rs/tests/criterion_tests.rs
Start Line: 377
End Line: 387
Chunks:

    // Run the final summary process and check for the report that produces
    short_benchmark(&tempdir).final_summary();

    #[cfg(feature = "html_reports")]
    {
        let dir = tempdir.path().to_owned();
        verify_html(&dir, "report/index.html");
    }
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 387
End Line: 435
Chunks:

#[cfg(feature = "plotters")]
#[test]
fn test_output_files_flat_sampling() {
    let tempdir = temp_dir();
    // Run benchmark twice to produce comparisons
    for _ in 0..2 {
        let mut c = short_benchmark(&tempdir);
        let mut group = c.benchmark_group("test_output");
        group.sampling_mode(SamplingMode::Flat);
        group.bench_function("output_flat", |b| b.iter(|| 10));
    }

    let dir = tempdir.path().join("test_output/output_flat");

    verify_stats(&dir, "new");
    verify_stats(&dir, "base");
    verify_json(&dir, "change/estimates.json");

    #[cfg(feature = "html_reports")]
    {
        verify_svg(&dir, "report/MAD.svg");
        verify_svg(&dir, "report/mean.svg");
        verify_svg(&dir, "report/median.svg");
        verify_svg(&dir, "report/pdf.svg");
        verify_svg(&dir, "report/iteration_times.svg");
        verify_svg(&dir, "report/SD.svg");
        verify_svg(&dir, "report/typical.svg");
        verify_svg(&dir, "report/both/pdf.svg");
        verify_svg(&dir, "report/both/iteration_times.svg");
        verify_svg(&dir, "report/change/mean.svg");
        verify_svg(&dir, "report/change/median.svg");
        verify_svg(&dir, "report/change/t-test.svg");

        verify_svg(&dir, "report/pdf_small.svg");
        verify_svg(&dir, "report/iteration_times_small.svg");
        verify_svg(&dir, "report/relative_pdf_small.svg");
        verify_svg(&dir, "report/relative_iteration_times_small.svg");
        verify_html(&dir, "report/index.html");
    }
}

#[test]
#[should_panic(expected = "Benchmark function must call Bencher::iter or related method.")]
fn test_bench_with_no_iteration_panics() {
    let dir = temp_dir();
    short_benchmark(&dir).bench_function("no_iter", |_b| {});
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 435
End Line: 482
Chunks:

#[test]
fn test_benchmark_group_with_input() {
    let dir = temp_dir();
    let mut c = short_benchmark(&dir);
    let mut group = c.benchmark_group("Test Group");
    for x in 0..2 {
        group.bench_with_input(BenchmarkId::new("Test 1", x), &x, |b, i| b.iter(|| i));
        group.bench_with_input(BenchmarkId::new("Test 2", x), &x, |b, i| b.iter(|| i));
    }
    group.finish();
}

#[test]
fn test_benchmark_group_without_input() {
    let dir = temp_dir();
    let mut c = short_benchmark(&dir);
    let mut group = c.benchmark_group("Test Group 2");
    group.bench_function("Test 1", |b| b.iter(|| 30));
    group.bench_function("Test 2", |b| b.iter(|| 20));
    group.finish();
}

#[test]
fn test_criterion_doesnt_panic_if_measured_time_is_zero() {
    let dir = temp_dir();
    let mut c = short_benchmark(&dir);
    c.bench_function("zero_time", |bencher| {
        bencher.iter_custom(|_iters| Duration::new(0, 0))
    });
}

mod macros {
    use super::{criterion_group, criterion_main, Criterion};

    #[test]
    #[should_panic(expected = "group executed")]
    fn criterion_main() {
        fn group() {}
        fn group2() {
            panic!("group executed");
        }

        criterion_main!(group, group2);

        main();
    }

File: criterion.rs/tests/criterion_tests.rs
Start Line: 482
End Line: 526
Chunks:

    #[test]
    fn criterion_main_trailing_comma() {
        // make this a compile-only check
        // as the second logger initialization causes panic
        #[allow(dead_code)]
        fn group() {}
        #[allow(dead_code)]
        fn group2() {}

        criterion_main!(group, group2,);

        // silence dead_code warning
        if false {
            main()
        }
    }

    #[test]
    #[should_panic(expected = "group executed")]
    fn criterion_group() {
        fn group(_crit: &mut Criterion) {}
        fn group2(_crit: &mut Criterion) {
            panic!("group executed");
        }

        criterion_group!(test_group, group, group2);

        test_group();
    }

    #[test]
    #[should_panic(expected = "group executed")]
    fn criterion_group_trailing_comma() {
        fn group(_crit: &mut Criterion) {}
        fn group2(_crit: &mut Criterion) {
            panic!("group executed");
        }

        criterion_group!(test_group, group, group2,);

        test_group();
    }
}

File: criterion.rs/tests/criterion_tests.rs
Start Line: 526
End Line: 559
Chunks:

struct TestProfiler {
    started: Rc<Cell<u32>>,
    stopped: Rc<Cell<u32>>,
}
impl Profiler for TestProfiler {
    fn start_profiling(&mut self, benchmark_id: &str, _benchmark_path: &Path) {
        assert!(benchmark_id.contains("profile_test"));
        self.started.set(self.started.get() + 1);
    }
    fn stop_profiling(&mut self, benchmark_id: &str, _benchmark_path: &Path) {
        assert!(benchmark_id.contains("profile_test"));
        self.stopped.set(self.stopped.get() + 1);
    }
}

// Verify that profilers are started and stopped as expected
#[test]
fn test_profiler_called() {
    let started = Rc::new(Cell::new(0u32));
    let stopped = Rc::new(Cell::new(0u32));
    let profiler = TestProfiler {
        started: started.clone(),
        stopped: stopped.clone(),
    };
    let dir = temp_dir();
    let mut criterion = short_benchmark(&dir)
        .with_profiler(profiler)
        .profile_time(Some(Duration::from_secs(1)));
    criterion.bench_function("profile_test", |b| b.iter(|| 10));
    assert_eq!(1, started.get());
    assert_eq!(1, stopped.get());
}

